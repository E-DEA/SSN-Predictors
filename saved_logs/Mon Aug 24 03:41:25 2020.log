----------------------------------------------------------------
Usage: python3 SSN_predictor.py <path_to_ssn_datafile> <path_to_aa_datafile>
----------------------------------------------------------------
Code running on device: cuda
----------------------------------------------------------------
Data loaded from file locations :
    SSN - /home/extern/Documents/Research/scripts/data/SILSO/TSN/SN_m_tot_V2.0.txt
    AA - /home/extern/Documents/Research/scripts/data/ISGI/aa_1869-01-01_2018-12-31_D.dat
----------------------------------------------------------------
Solar cycle data loaded/saved as: cycle_data.pickle
----------------------------------------------------------------
SC Number     Start Date       End Date      Solar Max   Length(in months)
         0      [1749, 1]      [1755, 1]         154.27                  72
         1      [1755, 2]      [1766, 5]         144.12                 135
         2      [1766, 6]      [1775, 5]         192.98                 107
         3      [1775, 6]      [1784, 8]         264.25                 110
         4      [1784, 9]      [1798, 3]         235.28                 162
         5      [1798, 4]     [1810, 11]          67.93                 151
         6     [1810, 12]      [1823, 4]          81.99                 148
         7      [1823, 5]     [1833, 10]          81.16                 125
         8     [1833, 11]      [1843, 6]         119.24                 115
         9      [1843, 7]     [1855, 11]         244.87                 148
        10     [1855, 12]      [1867, 2]         219.94                 134
        11      [1867, 3]     [1878, 11]         186.15                 140
        12     [1878, 12]      [1890, 2]         234.02                 134
        13      [1890, 3]      [1902, 0]         124.41                 141
        14      [1902, 1]      [1913, 6]         146.55                 137
        15      [1913, 7]      [1923, 7]         107.08                 120
        16      [1923, 8]      [1933, 8]         175.67                 120
        17      [1933, 9]      [1944, 1]         130.23                 124
        18      [1944, 2]      [1954, 3]         198.64                 121
        19      [1954, 4]      [1964, 9]         218.73                 125
        20     [1964, 10]      [1976, 2]          285.0                 136
        21      [1976, 3]      [1986, 8]         156.63                 125
        22      [1986, 9]      [1996, 4]         232.92                 115
        23      [1996, 5]     [2008, 11]         212.48                 150
        24     [2008, 12]     [2019, 11]         180.28                 131
----------------------------------------------------------------
Selected model: FFNN(
  (model): Sequential(
    (0): Linear(in_features=6, out_features=6, bias=True)
    (1): LeakyReLU(negative_slope=0.01, inplace=True)
    (2): Linear(in_features=6, out_features=3, bias=True)
    (3): LeakyReLU(negative_slope=0.01, inplace=True)
    (4): Linear(in_features=3, out_features=1, bias=True)
  )
)    Training mode: True    Testing mode: False
----------------------------------------------------------------
No pre-trained models available, initializing model weights
----------------------------------------------------------------
Training model with solar cycle 12 to 22 data: num_epochs=1200, start_lr=0.0001
Epoch [   5/1200] -> Loss: 38.0573
Epoch [  10/1200] -> Loss: 34.7436
Epoch [  15/1200] -> Loss: 34.4403
Epoch [  20/1200] -> Loss: 34.2276
Epoch [  25/1200] -> Loss: 34.0685
Epoch [  30/1200] -> Loss: 33.9457
Epoch [  35/1200] -> Loss: 33.8305
Epoch [  40/1200] -> Loss: 33.7343
Epoch [  45/1200] -> Loss: 33.6662
Epoch [  50/1200] -> Loss: 33.6016
Epoch [  55/1200] -> Loss: 33.5513
Epoch [  60/1200] -> Loss: 33.4885
Epoch [  65/1200] -> Loss: 33.4451
Epoch [  70/1200] -> Loss: 33.4168
Epoch [  75/1200] -> Loss: 33.3752
Epoch [  80/1200] -> Loss: 33.3391
Epoch [  85/1200] -> Loss: 33.3066
Epoch [  90/1200] -> Loss: 33.2788
Epoch [  95/1200] -> Loss: 33.2364
----------------------------------------------------------------
Model checkpoint saved as FFNN_100.pth
----------------------------------------------------------------
Epoch [ 100/1200] -> Loss: 33.2003
Epoch [ 105/1200] -> Loss: 33.1741
Epoch [ 110/1200] -> Loss: 33.1415
Epoch [ 115/1200] -> Loss: 33.1067
Epoch [ 120/1200] -> Loss: 33.0713
Epoch [ 125/1200] -> Loss: 33.0300
Epoch [ 130/1200] -> Loss: 32.9900
Epoch [ 135/1200] -> Loss: 32.9652
Epoch [ 140/1200] -> Loss: 32.9307
Epoch [ 145/1200] -> Loss: 32.8890
Epoch [ 150/1200] -> Loss: 32.8583
Epoch [ 155/1200] -> Loss: 32.8184
Epoch [ 160/1200] -> Loss: 32.7827
Epoch [ 165/1200] -> Loss: 32.7449
Epoch [ 170/1200] -> Loss: 32.7045
Epoch [ 175/1200] -> Loss: 32.6731
Epoch [ 180/1200] -> Loss: 32.6295
Epoch [ 185/1200] -> Loss: 32.5991
Epoch [ 190/1200] -> Loss: 32.5553
Epoch [ 195/1200] -> Loss: 32.5151
----------------------------------------------------------------
Model checkpoint saved as FFNN_200.pth
----------------------------------------------------------------
Epoch [ 200/1200] -> Loss: 32.4887
Epoch [ 205/1200] -> Loss: 32.4485
Epoch [ 210/1200] -> Loss: 32.4158
Epoch [ 215/1200] -> Loss: 32.3761
Epoch [ 220/1200] -> Loss: 32.3370
Epoch [ 225/1200] -> Loss: 32.3019
Epoch [ 230/1200] -> Loss: 32.2624
Epoch [ 235/1200] -> Loss: 32.2193
Epoch [ 240/1200] -> Loss: 32.1801
Epoch [ 245/1200] -> Loss: 32.1402
Epoch [ 250/1200] -> Loss: 32.1041
Epoch [ 255/1200] -> Loss: 32.0576
Epoch [ 260/1200] -> Loss: 32.0092
Epoch [ 265/1200] -> Loss: 31.9708
Epoch [ 270/1200] -> Loss: 31.9256
Epoch [ 275/1200] -> Loss: 31.8836
Epoch [ 280/1200] -> Loss: 31.8352
Epoch [ 285/1200] -> Loss: 31.7907
Epoch [ 290/1200] -> Loss: 31.7414
Epoch [ 295/1200] -> Loss: 31.6903
----------------------------------------------------------------
Model checkpoint saved as FFNN_300.pth
----------------------------------------------------------------
Epoch [ 300/1200] -> Loss: 31.6436
Epoch [ 305/1200] -> Loss: 31.5952
Epoch [ 310/1200] -> Loss: 31.5514
Epoch [ 315/1200] -> Loss: 31.4927
Epoch [ 320/1200] -> Loss: 31.4423
Epoch [ 325/1200] -> Loss: 31.3769
Epoch [ 330/1200] -> Loss: 31.3296
Epoch [ 335/1200] -> Loss: 31.2761
Epoch [ 340/1200] -> Loss: 31.2149
Epoch [ 345/1200] -> Loss: 31.1565
Epoch [ 350/1200] -> Loss: 31.1000
Epoch [ 355/1200] -> Loss: 31.0265
Epoch [ 360/1200] -> Loss: 30.9704
Epoch [ 365/1200] -> Loss: 30.9099
Epoch [ 370/1200] -> Loss: 30.8414
Epoch [ 375/1200] -> Loss: 30.7742
Epoch [ 380/1200] -> Loss: 30.7123
Epoch [ 385/1200] -> Loss: 30.6653
Epoch [ 390/1200] -> Loss: 30.5974
Epoch [ 395/1200] -> Loss: 30.5256
----------------------------------------------------------------
Model checkpoint saved as FFNN_400.pth
----------------------------------------------------------------
Epoch [ 400/1200] -> Loss: 30.4669
Epoch [ 405/1200] -> Loss: 30.4057
Epoch [ 410/1200] -> Loss: 30.3424
Epoch [ 415/1200] -> Loss: 30.2811
Epoch [ 420/1200] -> Loss: 30.2265
Epoch [ 425/1200] -> Loss: 30.1549
Epoch [ 430/1200] -> Loss: 30.0978
Epoch [ 435/1200] -> Loss: 30.0372
Epoch [ 440/1200] -> Loss: 29.9780
Epoch [ 445/1200] -> Loss: 29.9093
Epoch [ 450/1200] -> Loss: 29.8467
Epoch [ 455/1200] -> Loss: 29.7787
Epoch [ 460/1200] -> Loss: 29.7207
Epoch [ 465/1200] -> Loss: 29.6722
Epoch [ 470/1200] -> Loss: 29.6054
Epoch [ 475/1200] -> Loss: 29.5461
Epoch [ 480/1200] -> Loss: 29.4862
Epoch [ 485/1200] -> Loss: 29.4320
Epoch [ 490/1200] -> Loss: 29.3862
Epoch [ 495/1200] -> Loss: 29.3119
----------------------------------------------------------------
Model checkpoint saved as FFNN_500.pth
----------------------------------------------------------------
Epoch [ 500/1200] -> Loss: 29.2711
Epoch [ 505/1200] -> Loss: 29.2389
Epoch [ 510/1200] -> Loss: 29.1910
Epoch [ 515/1200] -> Loss: 29.1491
Epoch [ 520/1200] -> Loss: 29.1003
Epoch [ 525/1200] -> Loss: 29.0761
Epoch [ 530/1200] -> Loss: 29.0392
Epoch [ 535/1200] -> Loss: 29.0037
Epoch [ 540/1200] -> Loss: 28.9692
Epoch [ 545/1200] -> Loss: 28.9491
Epoch [ 550/1200] -> Loss: 28.9146
Epoch [ 555/1200] -> Loss: 28.8901
Epoch [ 560/1200] -> Loss: 28.8761
Epoch [ 565/1200] -> Loss: 28.8499
Epoch [ 570/1200] -> Loss: 28.7915
Epoch [ 575/1200] -> Loss: 28.7863
Epoch [ 580/1200] -> Loss: 28.7875
Epoch [ 585/1200] -> Loss: 28.7566
Epoch [ 590/1200] -> Loss: 28.7416
Epoch [ 595/1200] -> Loss: 28.7212
----------------------------------------------------------------
Model checkpoint saved as FFNN_600.pth
----------------------------------------------------------------
Epoch [ 600/1200] -> Loss: 28.7130
Epoch [ 605/1200] -> Loss: 28.6744
Epoch [ 610/1200] -> Loss: 28.6468
Epoch [ 615/1200] -> Loss: 28.6235
Epoch [ 620/1200] -> Loss: 28.5979
Epoch [ 625/1200] -> Loss: 28.5715
Epoch [ 630/1200] -> Loss: 28.5356
Epoch [ 635/1200] -> Loss: 28.5513
Epoch [ 640/1200] -> Loss: 28.5117
Epoch [ 645/1200] -> Loss: 28.4897
Epoch [ 650/1200] -> Loss: 28.4750
Epoch   653: reducing learning rate of group 0 to 9.0000e-05.
Epoch [ 655/1200] -> Loss: 28.4680
Epoch [ 660/1200] -> Loss: 28.4487
Epoch [ 665/1200] -> Loss: 28.4399
Epoch [ 670/1200] -> Loss: 28.4288
Epoch [ 675/1200] -> Loss: 28.4230
Epoch [ 680/1200] -> Loss: 28.4131
Epoch [ 685/1200] -> Loss: 28.3972
Epoch [ 690/1200] -> Loss: 28.3760
Epoch [ 695/1200] -> Loss: 28.3696
----------------------------------------------------------------
Model checkpoint saved as FFNN_700.pth
----------------------------------------------------------------
Epoch [ 700/1200] -> Loss: 28.3656
Epoch [ 705/1200] -> Loss: 28.3610
Epoch   709: reducing learning rate of group 0 to 8.1000e-05.
Epoch [ 710/1200] -> Loss: 28.3376
Epoch [ 715/1200] -> Loss: 28.3030
Epoch [ 720/1200] -> Loss: 28.3135
Epoch [ 725/1200] -> Loss: 28.3159
Epoch [ 730/1200] -> Loss: 28.3074
Epoch [ 735/1200] -> Loss: 28.3013
Epoch [ 740/1200] -> Loss: 28.3033
Epoch [ 745/1200] -> Loss: 28.2846
Epoch   750: reducing learning rate of group 0 to 7.2900e-05.
Epoch [ 750/1200] -> Loss: 28.2942
Epoch [ 755/1200] -> Loss: 28.2682
Epoch [ 760/1200] -> Loss: 28.2707
Epoch [ 765/1200] -> Loss: 28.2730
Epoch [ 770/1200] -> Loss: 28.2623
Epoch [ 775/1200] -> Loss: 28.2588
Epoch [ 780/1200] -> Loss: 28.2599
Epoch   784: reducing learning rate of group 0 to 6.5610e-05.
Epoch [ 785/1200] -> Loss: 28.2449
Epoch [ 790/1200] -> Loss: 28.2373
Epoch [ 795/1200] -> Loss: 28.2320
Epoch   798: reducing learning rate of group 0 to 5.9049e-05.
----------------------------------------------------------------
Model checkpoint saved as FFNN_800.pth
----------------------------------------------------------------
Epoch [ 800/1200] -> Loss: 28.2255
Epoch [ 805/1200] -> Loss: 28.2271
Epoch [ 810/1200] -> Loss: 28.1862
Epoch [ 815/1200] -> Loss: 28.2218
Epoch [ 820/1200] -> Loss: 28.2090
Epoch   821: reducing learning rate of group 0 to 5.3144e-05.
Epoch [ 825/1200] -> Loss: 28.2135
Epoch [ 830/1200] -> Loss: 28.2000
Epoch   832: reducing learning rate of group 0 to 4.7830e-05.
Epoch [ 835/1200] -> Loss: 28.1921
Epoch [ 840/1200] -> Loss: 28.1833
Epoch [ 845/1200] -> Loss: 28.1897
Epoch [ 850/1200] -> Loss: 28.1708
Epoch [ 855/1200] -> Loss: 28.1830
Epoch [ 860/1200] -> Loss: 28.1754
Epoch [ 865/1200] -> Loss: 28.1717
Epoch [ 870/1200] -> Loss: 28.1804
Epoch [ 875/1200] -> Loss: 28.1754
Epoch [ 880/1200] -> Loss: 28.1586
Epoch [ 885/1200] -> Loss: 28.1592
Epoch [ 890/1200] -> Loss: 28.1436
Epoch   893: reducing learning rate of group 0 to 4.3047e-05.
Epoch [ 895/1200] -> Loss: 28.1506
----------------------------------------------------------------
Model checkpoint saved as FFNN_900.pth
----------------------------------------------------------------
Epoch [ 900/1200] -> Loss: 28.1475
Epoch [ 905/1200] -> Loss: 28.1487
Epoch [ 910/1200] -> Loss: 28.1469
Epoch [ 915/1200] -> Loss: 28.1322
Epoch   919: reducing learning rate of group 0 to 3.8742e-05.
Epoch [ 920/1200] -> Loss: 28.1331
Epoch [ 925/1200] -> Loss: 28.1304
Epoch   930: reducing learning rate of group 0 to 3.4868e-05.
Epoch [ 930/1200] -> Loss: 28.1342
Epoch [ 935/1200] -> Loss: 28.1191
Epoch [ 940/1200] -> Loss: 28.1115
Epoch [ 945/1200] -> Loss: 28.1209
Epoch [ 950/1200] -> Loss: 28.1219
Epoch   951: reducing learning rate of group 0 to 3.1381e-05.
Epoch [ 955/1200] -> Loss: 28.1162
Epoch [ 960/1200] -> Loss: 28.1123
Epoch   962: reducing learning rate of group 0 to 2.8243e-05.
Epoch [ 965/1200] -> Loss: 28.1044
Epoch [ 970/1200] -> Loss: 28.1047
Epoch [ 975/1200] -> Loss: 28.1087
Epoch   976: reducing learning rate of group 0 to 2.5419e-05.
Epoch [ 980/1200] -> Loss: 28.1078
Epoch [ 985/1200] -> Loss: 28.1020
Epoch [ 990/1200] -> Loss: 28.1004
Epoch [ 995/1200] -> Loss: 28.1011
Epoch   999: reducing learning rate of group 0 to 2.2877e-05.
----------------------------------------------------------------
Model checkpoint saved as FFNN_1000.pth
----------------------------------------------------------------
Epoch [1000/1200] -> Loss: 28.0974
Epoch [1005/1200] -> Loss: 28.0956
Epoch [1010/1200] -> Loss: 28.0982
Epoch [1015/1200] -> Loss: 28.0945
Epoch [1020/1200] -> Loss: 28.0941
Epoch [1025/1200] -> Loss: 28.0897
Epoch  1028: reducing learning rate of group 0 to 2.0589e-05.
Epoch [1030/1200] -> Loss: 28.0893
Epoch [1035/1200] -> Loss: 28.0841
Epoch [1040/1200] -> Loss: 28.0848
Epoch  1045: reducing learning rate of group 0 to 1.8530e-05.
Epoch [1045/1200] -> Loss: 28.0839
Epoch [1050/1200] -> Loss: 28.0774
Epoch [1055/1200] -> Loss: 28.0807
Epoch [1060/1200] -> Loss: 28.0792
Epoch  1061: reducing learning rate of group 0 to 1.6677e-05.
Epoch [1065/1200] -> Loss: 28.0760
Epoch [1070/1200] -> Loss: 28.0775
Epoch  1072: reducing learning rate of group 0 to 1.5009e-05.
Epoch [1075/1200] -> Loss: 28.0756
Epoch [1080/1200] -> Loss: 28.0744
Epoch [1085/1200] -> Loss: 28.0729
Epoch  1087: reducing learning rate of group 0 to 1.3509e-05.
Epoch [1090/1200] -> Loss: 28.0712
Epoch [1095/1200] -> Loss: 28.0695
Epoch  1098: reducing learning rate of group 0 to 1.2158e-05.
----------------------------------------------------------------
Model checkpoint saved as FFNN_1100.pth
----------------------------------------------------------------
Epoch [1100/1200] -> Loss: 28.0688
Epoch [1105/1200] -> Loss: 28.0680
Epoch [1110/1200] -> Loss: 28.0669
Epoch  1112: reducing learning rate of group 0 to 1.0942e-05.
Epoch [1115/1200] -> Loss: 28.0653
Epoch [1120/1200] -> Loss: 28.0649
Epoch  1125: reducing learning rate of group 0 to 9.8477e-06.
Epoch [1125/1200] -> Loss: 28.0643
Epoch [1130/1200] -> Loss: 28.0631
Epoch [1135/1200] -> Loss: 28.0643
Epoch  1136: reducing learning rate of group 0 to 8.8629e-06.
Epoch [1140/1200] -> Loss: 28.0616
Epoch [1145/1200] -> Loss: 28.0598
Epoch [1150/1200] -> Loss: 28.0605
Epoch  1151: reducing learning rate of group 0 to 7.9766e-06.
Epoch [1155/1200] -> Loss: 28.0599
Epoch [1160/1200] -> Loss: 28.0584
Epoch [1165/1200] -> Loss: 28.0585
Epoch [1170/1200] -> Loss: 28.0590
Epoch  1171: reducing learning rate of group 0 to 7.1790e-06.
Epoch [1175/1200] -> Loss: 28.0567
Epoch [1180/1200] -> Loss: 28.0573
Epoch  1182: reducing learning rate of group 0 to 6.4611e-06.
Epoch [1185/1200] -> Loss: 28.0558
Epoch [1190/1200] -> Loss: 28.0550
Epoch [1195/1200] -> Loss: 28.0554
----------------------------------------------------------------
Model checkpoint saved as FFNN_1200.pth
----------------------------------------------------------------
Epoch [1200/1200] -> Loss: 28.0556
----------------------------------------------------------------
Plotting loss data...
----------------------------------------------------------------
Training finished successfully.
        Saved model checkpoints can be found in: /home/extern/Documents/Research/scripts/models/
        Saved data/loss graphs can be found in: /home/extern/Documents/Research/scripts/graphs/
----------------------------------------------------------------
Validating model with solar cycle 23 data
Step [   1/151] -> Target: tensor([158.1000], device='cuda:0', dtype=torch.float64), Prediction: tensor([[184.0417]], device='cuda:0')

--------------------------------------------------
Code running on device: cuda
--------------------------------------------------
File location :
    SSN - /home/extern/Documents/Research/scripts/data/SILSO/TSN/SN_m_tot_V2.0.txt
    AA - /home/extern/Documents/Research/scripts/data/ISGI/aa_1869-01-01_2018-12-31_D.dat
--------------------------------------------------
Selected model: FFNN(
  (model): Sequential(
    (0): Linear(in_features=6, out_features=6, bias=True)
    (1): LeakyReLU(negative_slope=0.01, inplace=True)
    (2): Linear(in_features=6, out_features=1, bias=True)
  )
)    Training mode: True    Testing mode: False
--------------------------------------------------
No pre-trained models available, initializing model weights
--------------------------------------------------
Training model with: num_epochs=1800, start_lr=5e-05
Epoch [   1/1800] -> Loss: 14234.1140
Epoch [   2/1800] -> Loss: 12293.1971
Epoch [   3/1800] -> Loss: 10466.6890
Epoch [   4/1800] -> Loss: 8784.4219
Epoch [   5/1800] -> Loss: 7302.1873
Epoch [   6/1800] -> Loss: 6067.1482
Epoch [   7/1800] -> Loss: 5093.3738
Epoch [   8/1800] -> Loss: 4351.4592
Epoch [   9/1800] -> Loss: 3827.9624
Epoch [  10/1800] -> Loss: 3494.3623
Epoch [  11/1800] -> Loss: 3301.5721
Epoch [  12/1800] -> Loss: 3197.8344
Epoch [  13/1800] -> Loss: 3143.9321
Epoch [  14/1800] -> Loss: 3115.8643
Epoch [  15/1800] -> Loss: 3100.6184
Epoch [  16/1800] -> Loss: 3091.5615
Epoch [  17/1800] -> Loss: 3085.0411
Epoch [  18/1800] -> Loss: 3079.5654
Epoch [  19/1800] -> Loss: 3073.7785
Epoch [  20/1800] -> Loss: 3068.8503
Epoch [  21/1800] -> Loss: 3064.3259
Epoch [  22/1800] -> Loss: 3060.1320
Epoch [  23/1800] -> Loss: 3056.2032
Epoch [  24/1800] -> Loss: 3052.5817
Epoch [  25/1800] -> Loss: 3049.0996
Epoch [  26/1800] -> Loss: 3045.8810
Epoch [  27/1800] -> Loss: 3042.7224
Epoch [  28/1800] -> Loss: 3039.5685
Epoch [  29/1800] -> Loss: 3036.4964
Epoch [  30/1800] -> Loss: 3033.4175
Epoch [  31/1800] -> Loss: 3030.2564
Epoch [  32/1800] -> Loss: 3027.2030
Epoch [  33/1800] -> Loss: 3024.1797
Epoch [  34/1800] -> Loss: 3021.1426
Epoch [  35/1800] -> Loss: 3018.1855
Epoch [  36/1800] -> Loss: 3015.3406
Epoch [  37/1800] -> Loss: 3012.3784
Epoch [  38/1800] -> Loss: 3009.3915
Epoch [  39/1800] -> Loss: 3006.4002
Epoch [  40/1800] -> Loss: 3003.3921
Epoch [  41/1800] -> Loss: 3000.3670
Epoch [  42/1800] -> Loss: 2997.3451
Epoch [  43/1800] -> Loss: 2994.3371
Epoch [  44/1800] -> Loss: 2991.3024
Epoch [  45/1800] -> Loss: 2988.1791
Epoch [  46/1800] -> Loss: 2985.0520
Epoch [  47/1800] -> Loss: 2981.9777
Epoch [  48/1800] -> Loss: 2978.8935
Epoch [  49/1800] -> Loss: 2975.9169
Epoch [  50/1800] -> Loss: 2972.9235
Epoch [  51/1800] -> Loss: 2969.8800
Epoch [  52/1800] -> Loss: 2966.9137
Epoch [  53/1800] -> Loss: 2963.9698
Epoch [  54/1800] -> Loss: 2960.9556
Epoch [  55/1800] -> Loss: 2957.9606
Epoch [  56/1800] -> Loss: 2954.9491
Epoch [  57/1800] -> Loss: 2951.9937
Epoch [  58/1800] -> Loss: 2949.0094
Epoch [  59/1800] -> Loss: 2946.0041
Epoch [  60/1800] -> Loss: 2942.9940
Epoch [  61/1800] -> Loss: 2939.9848
Epoch [  62/1800] -> Loss: 2936.9737
Epoch [  63/1800] -> Loss: 2933.9539
Epoch [  64/1800] -> Loss: 2930.9383
Epoch [  65/1800] -> Loss: 2927.9053
Epoch [  66/1800] -> Loss: 2924.8735
Epoch [  67/1800] -> Loss: 2921.8242
Epoch [  68/1800] -> Loss: 2918.7784
Epoch [  69/1800] -> Loss: 2915.7237
Epoch [  70/1800] -> Loss: 2912.7279
Epoch [  71/1800] -> Loss: 2909.6853
Epoch [  72/1800] -> Loss: 2906.6055
Epoch [  73/1800] -> Loss: 2903.5206
Epoch [  74/1800] -> Loss: 2900.4100
Epoch [  75/1800] -> Loss: 2897.3144
Epoch [  76/1800] -> Loss: 2894.1855
Epoch [  77/1800] -> Loss: 2891.0592
Epoch [  78/1800] -> Loss: 2887.9223
Epoch [  79/1800] -> Loss: 2884.7654
Epoch [  80/1800] -> Loss: 2881.5965
Epoch [  81/1800] -> Loss: 2878.4156
Epoch [  82/1800] -> Loss: 2875.2224
Epoch [  83/1800] -> Loss: 2872.0228
Epoch [  84/1800] -> Loss: 2868.8121
Epoch [  85/1800] -> Loss: 2865.6061
Epoch [  86/1800] -> Loss: 2862.4046
Epoch [  87/1800] -> Loss: 2859.2038
Epoch [  88/1800] -> Loss: 2855.9840
Epoch [  89/1800] -> Loss: 2852.7621
Epoch [  90/1800] -> Loss: 2849.5248
Epoch [  91/1800] -> Loss: 2846.2835
Epoch [  92/1800] -> Loss: 2843.0334
Epoch [  93/1800] -> Loss: 2839.7752
Epoch [  94/1800] -> Loss: 2836.5119
Epoch [  95/1800] -> Loss: 2833.2598
Epoch [  96/1800] -> Loss: 2829.9855
Epoch [  97/1800] -> Loss: 2826.7062
Epoch [  98/1800] -> Loss: 2823.4126
Epoch [  99/1800] -> Loss: 2820.1263
Epoch [ 100/1800] -> Loss: 2816.8305
Epoch [ 101/1800] -> Loss: 2813.5256
Epoch [ 102/1800] -> Loss: 2810.2121
Epoch [ 103/1800] -> Loss: 2806.9113
Epoch [ 104/1800] -> Loss: 2803.5936
Epoch [ 105/1800] -> Loss: 2800.3124
Epoch [ 106/1800] -> Loss: 2797.0314
Epoch [ 107/1800] -> Loss: 2793.7536
Epoch [ 108/1800] -> Loss: 2790.4891
Epoch [ 109/1800] -> Loss: 2787.2159
Epoch [ 110/1800] -> Loss: 2783.9397
Epoch [ 111/1800] -> Loss: 2780.6561
Epoch [ 112/1800] -> Loss: 2777.3712
Epoch [ 113/1800] -> Loss: 2774.0899
Epoch [ 114/1800] -> Loss: 2770.7953
Epoch [ 115/1800] -> Loss: 2767.4977
Epoch [ 116/1800] -> Loss: 2764.2059
Epoch [ 117/1800] -> Loss: 2760.9119
Epoch [ 118/1800] -> Loss: 2757.6043
Epoch [ 119/1800] -> Loss: 2754.2930
Epoch [ 120/1800] -> Loss: 2750.9848
Epoch [ 121/1800] -> Loss: 2747.6728
Epoch [ 122/1800] -> Loss: 2744.3401
Epoch [ 123/1800] -> Loss: 2741.0002
Epoch [ 124/1800] -> Loss: 2737.6531
Epoch [ 125/1800] -> Loss: 2734.2980
Epoch [ 126/1800] -> Loss: 2730.9375
Epoch [ 127/1800] -> Loss: 2727.5822
Epoch [ 128/1800] -> Loss: 2724.2116
Epoch [ 129/1800] -> Loss: 2720.8418
Epoch [ 130/1800] -> Loss: 2717.4658
Epoch [ 131/1800] -> Loss: 2714.0919
Epoch [ 132/1800] -> Loss: 2710.7100
Epoch [ 133/1800] -> Loss: 2707.3370
Epoch [ 134/1800] -> Loss: 2703.9602
Epoch [ 135/1800] -> Loss: 2700.5820
Epoch [ 136/1800] -> Loss: 2697.2020
Epoch [ 137/1800] -> Loss: 2693.8241
Epoch [ 138/1800] -> Loss: 2690.4263
Epoch [ 139/1800] -> Loss: 2687.0272
Epoch [ 140/1800] -> Loss: 2683.6136
Epoch [ 141/1800] -> Loss: 2680.2052
Epoch [ 142/1800] -> Loss: 2676.7989
Epoch [ 143/1800] -> Loss: 2673.3899
Epoch [ 144/1800] -> Loss: 2669.9815
Epoch [ 145/1800] -> Loss: 2666.6363
Epoch [ 146/1800] -> Loss: 2663.2459
Epoch [ 147/1800] -> Loss: 2659.8587
Epoch [ 148/1800] -> Loss: 2656.4690
Epoch [ 149/1800] -> Loss: 2653.1124
Epoch [ 150/1800] -> Loss: 2649.7339
Epoch [ 151/1800] -> Loss: 2646.3569
Epoch [ 152/1800] -> Loss: 2642.9824
Epoch [ 153/1800] -> Loss: 2639.6098
Epoch [ 154/1800] -> Loss: 2636.2369
Epoch [ 155/1800] -> Loss: 2632.8658
Epoch [ 156/1800] -> Loss: 2629.5177
Epoch [ 157/1800] -> Loss: 2626.1616
Epoch [ 158/1800] -> Loss: 2622.7929
Epoch [ 159/1800] -> Loss: 2619.4251
Epoch [ 160/1800] -> Loss: 2616.0591
Epoch [ 161/1800] -> Loss: 2612.7089
Epoch [ 162/1800] -> Loss: 2609.3642
Epoch [ 163/1800] -> Loss: 2606.0222
Epoch [ 164/1800] -> Loss: 2602.6768
Epoch [ 165/1800] -> Loss: 2599.3293
Epoch [ 166/1800] -> Loss: 2595.9886
Epoch [ 167/1800] -> Loss: 2592.6607
Epoch [ 168/1800] -> Loss: 2589.3161
Epoch [ 169/1800] -> Loss: 2585.9824
Epoch [ 170/1800] -> Loss: 2582.6481
Epoch [ 171/1800] -> Loss: 2579.3161
Epoch [ 172/1800] -> Loss: 2575.9985
Epoch [ 173/1800] -> Loss: 2572.6776
Epoch [ 174/1800] -> Loss: 2569.3600
Epoch [ 175/1800] -> Loss: 2566.0448
Epoch [ 176/1800] -> Loss: 2562.7366
Epoch [ 177/1800] -> Loss: 2559.4219
Epoch [ 178/1800] -> Loss: 2556.1100
Epoch [ 179/1800] -> Loss: 2552.8018
Epoch [ 180/1800] -> Loss: 2549.4980
Epoch [ 181/1800] -> Loss: 2546.1932
Epoch [ 182/1800] -> Loss: 2542.8908
Epoch [ 183/1800] -> Loss: 2539.5903
Epoch [ 184/1800] -> Loss: 2536.3068
Epoch [ 185/1800] -> Loss: 2533.0178
Epoch [ 186/1800] -> Loss: 2529.7343
Epoch [ 187/1800] -> Loss: 2526.4561
Epoch [ 188/1800] -> Loss: 2523.1845
Epoch [ 189/1800] -> Loss: 2519.9157
Epoch [ 190/1800] -> Loss: 2516.6774
Epoch [ 191/1800] -> Loss: 2513.4274
Epoch [ 192/1800] -> Loss: 2510.1847
Epoch [ 193/1800] -> Loss: 2506.9467
Epoch [ 194/1800] -> Loss: 2503.7021
Epoch [ 195/1800] -> Loss: 2500.4707
Epoch [ 196/1800] -> Loss: 2497.2424
Epoch [ 197/1800] -> Loss: 2494.0198
Epoch [ 198/1800] -> Loss: 2490.8321
Epoch [ 199/1800] -> Loss: 2487.6285
--------------------------------------------------
Model checkpoint saved as FFNN_200.pth
--------------------------------------------------
Epoch [ 200/1800] -> Loss: 2484.4279
Epoch [ 201/1800] -> Loss: 2481.2341
Epoch [ 202/1800] -> Loss: 2478.0457
Epoch [ 203/1800] -> Loss: 2474.8639
Epoch [ 204/1800] -> Loss: 2471.6846
Epoch [ 205/1800] -> Loss: 2468.5114
Epoch [ 206/1800] -> Loss: 2465.3472
Epoch [ 207/1800] -> Loss: 2462.1927
Epoch [ 208/1800] -> Loss: 2459.0460
Epoch [ 209/1800] -> Loss: 2455.9052
Epoch [ 210/1800] -> Loss: 2452.7638
Epoch [ 211/1800] -> Loss: 2449.6224
Epoch [ 212/1800] -> Loss: 2446.4918
Epoch [ 213/1800] -> Loss: 2443.3688
Epoch [ 214/1800] -> Loss: 2440.2500
Epoch [ 215/1800] -> Loss: 2437.1406
Epoch [ 216/1800] -> Loss: 2434.0375
Epoch [ 217/1800] -> Loss: 2430.9421
Epoch [ 218/1800] -> Loss: 2427.8489
Epoch [ 219/1800] -> Loss: 2424.7612
Epoch [ 220/1800] -> Loss: 2421.6808
Epoch [ 221/1800] -> Loss: 2418.6066
Epoch [ 222/1800] -> Loss: 2415.5438
Epoch [ 223/1800] -> Loss: 2412.4903
Epoch [ 224/1800] -> Loss: 2409.4426
Epoch [ 225/1800] -> Loss: 2406.4040
Epoch [ 226/1800] -> Loss: 2403.3720
Epoch [ 227/1800] -> Loss: 2400.3484
Epoch [ 228/1800] -> Loss: 2397.3324
Epoch [ 229/1800] -> Loss: 2394.3264
Epoch [ 230/1800] -> Loss: 2391.3255
Epoch [ 231/1800] -> Loss: 2388.3392
Epoch [ 232/1800] -> Loss: 2385.3582
Epoch [ 233/1800] -> Loss: 2382.3866
Epoch [ 234/1800] -> Loss: 2379.4235
Epoch [ 235/1800] -> Loss: 2376.4672
Epoch [ 236/1800] -> Loss: 2373.5199
Epoch [ 237/1800] -> Loss: 2370.5805
Epoch [ 238/1800] -> Loss: 2367.6505
Epoch [ 239/1800] -> Loss: 2364.7281
Epoch [ 240/1800] -> Loss: 2361.8147
Epoch [ 241/1800] -> Loss: 2358.9086
Epoch [ 242/1800] -> Loss: 2356.0107
Epoch [ 243/1800] -> Loss: 2353.1191
Epoch [ 244/1800] -> Loss: 2350.2363
Epoch [ 245/1800] -> Loss: 2347.3623
Epoch [ 246/1800] -> Loss: 2344.4968
Epoch [ 247/1800] -> Loss: 2341.6380
Epoch [ 248/1800] -> Loss: 2338.7835
Epoch [ 249/1800] -> Loss: 2335.9407
Epoch [ 250/1800] -> Loss: 2333.1078
Epoch [ 251/1800] -> Loss: 2330.2823
Epoch [ 252/1800] -> Loss: 2327.4654
Epoch [ 253/1800] -> Loss: 2324.6581
Epoch [ 254/1800] -> Loss: 2321.8594
Epoch [ 255/1800] -> Loss: 2319.0941
Epoch [ 256/1800] -> Loss: 2316.3215
Epoch [ 257/1800] -> Loss: 2313.5571
Epoch [ 258/1800] -> Loss: 2310.8036
Epoch [ 259/1800] -> Loss: 2308.0588
Epoch [ 260/1800] -> Loss: 2305.3212
Epoch [ 261/1800] -> Loss: 2302.5952
Epoch [ 262/1800] -> Loss: 2299.8772
Epoch [ 263/1800] -> Loss: 2297.1681
Epoch [ 264/1800] -> Loss: 2294.4679
Epoch [ 265/1800] -> Loss: 2291.7772
Epoch [ 266/1800] -> Loss: 2289.0930
Epoch [ 267/1800] -> Loss: 2286.4181
Epoch [ 268/1800] -> Loss: 2283.7417
Epoch [ 269/1800] -> Loss: 2281.0868
Epoch [ 270/1800] -> Loss: 2278.4422
Epoch [ 271/1800] -> Loss: 2275.8069
Epoch [ 272/1800] -> Loss: 2273.1812
Epoch [ 273/1800] -> Loss: 2270.5648
Epoch [ 274/1800] -> Loss: 2267.9878
Epoch [ 275/1800] -> Loss: 2265.3945
Epoch [ 276/1800] -> Loss: 2262.8108
Epoch [ 277/1800] -> Loss: 2260.2389
Epoch [ 278/1800] -> Loss: 2257.6746
Epoch [ 279/1800] -> Loss: 2255.1305
Epoch [ 280/1800] -> Loss: 2252.5890
Epoch [ 281/1800] -> Loss: 2250.0743
Epoch [ 282/1800] -> Loss: 2247.5562
Epoch [ 283/1800] -> Loss: 2245.0471
Epoch [ 284/1800] -> Loss: 2242.5458
Epoch [ 285/1800] -> Loss: 2240.0547
Epoch [ 286/1800] -> Loss: 2237.5730
Epoch [ 287/1800] -> Loss: 2235.1004
Epoch [ 288/1800] -> Loss: 2232.6380
Epoch [ 289/1800] -> Loss: 2230.1848

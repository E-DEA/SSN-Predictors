--------------------------------------------------
Code running on device: cuda
--------------------------------------------------
File location :
    SSN - /home/extern/Documents/Research/scripts/data/SILSO/TSN/SN_m_tot_V2.0.txt
    AA - /home/extern/Documents/Research/scripts/data/ISGI/aa_1869-01-01_2018-12-31_D.dat
--------------------------------------------------
Selected model: FFNN(
  (model): Sequential(
    (0): Linear(in_features=6, out_features=6, bias=True)
    (1): Linear(in_features=6, out_features=6, bias=True)
    (2): Linear(in_features=6, out_features=1, bias=True)
  )
)    Training mode: True    Testing mode: False
--------------------------------------------------
No pre-trained models available, initializing model weights
--------------------------------------------------
Training model with: num_epochs=2600, start_lr=0.005
Epoch [   1/2600] -> Loss: 10380.0395
Epoch [   2/2600] -> Loss: 3558.7780
Epoch [   3/2600] -> Loss: 3382.3822
Epoch [   4/2600] -> Loss: 3115.3021
Epoch [   5/2600] -> Loss: 2974.4195
Epoch [   6/2600] -> Loss: 2988.0152
Epoch [   7/2600] -> Loss: 2957.6415
Epoch [   8/2600] -> Loss: 2955.8368
Epoch [   9/2600] -> Loss: 2934.8024
Epoch [  10/2600] -> Loss: 2964.0852
Epoch [  11/2600] -> Loss: 2919.2470
Epoch [  12/2600] -> Loss: 2904.1437
Epoch [  13/2600] -> Loss: 2931.4666
Epoch [  14/2600] -> Loss: 2895.5609
Epoch [  15/2600] -> Loss: 2893.0953
Epoch [  16/2600] -> Loss: 2859.4820
Epoch [  17/2600] -> Loss: 2854.8012
Epoch [  18/2600] -> Loss: 2835.1812
Epoch [  19/2600] -> Loss: 2821.6263
Epoch [  20/2600] -> Loss: 2802.8427
Epoch [  21/2600] -> Loss: 2803.7663
Epoch [  22/2600] -> Loss: 2787.4692
Epoch [  23/2600] -> Loss: 2771.1139
Epoch [  24/2600] -> Loss: 2740.1720
Epoch [  25/2600] -> Loss: 2734.0609
Epoch [  26/2600] -> Loss: 2717.6298
Epoch [  27/2600] -> Loss: 2683.2519
Epoch [  28/2600] -> Loss: 2682.3570
Epoch [  29/2600] -> Loss: 2641.9649
Epoch [  30/2600] -> Loss: 2615.4116
Epoch [  31/2600] -> Loss: 2591.1244
Epoch [  32/2600] -> Loss: 2586.3228
Epoch [  33/2600] -> Loss: 2543.6084
Epoch [  34/2600] -> Loss: 2527.1322
Epoch [  35/2600] -> Loss: 2512.8193
Epoch [  36/2600] -> Loss: 2455.5456
Epoch [  37/2600] -> Loss: 2433.7229
Epoch [  38/2600] -> Loss: 2400.1087
Epoch [  39/2600] -> Loss: 2367.8909
Epoch [  40/2600] -> Loss: 2351.3874
Epoch [  41/2600] -> Loss: 2293.5104
Epoch [  42/2600] -> Loss: 2274.7166
Epoch [  43/2600] -> Loss: 2235.2635
Epoch [  44/2600] -> Loss: 2200.3639
Epoch [  45/2600] -> Loss: 2168.7320
Epoch [  46/2600] -> Loss: 2142.7872
Epoch [  47/2600] -> Loss: 2103.4402
Epoch [  48/2600] -> Loss: 2089.7658
Epoch [  49/2600] -> Loss: 2047.2183
Epoch [  50/2600] -> Loss: 2024.5296
Epoch [  51/2600] -> Loss: 1999.1999
Epoch [  52/2600] -> Loss: 1980.0339
Epoch [  53/2600] -> Loss: 1956.1029
Epoch [  54/2600] -> Loss: 1930.7837
Epoch [  55/2600] -> Loss: 1931.0649
Epoch [  56/2600] -> Loss: 1920.3383
Epoch [  57/2600] -> Loss: 1905.2537
Epoch [  58/2600] -> Loss: 1886.1423
Epoch [  59/2600] -> Loss: 1870.8203
Epoch [  60/2600] -> Loss: 1864.3311
Epoch [  61/2600] -> Loss: 1833.0413
Epoch [  62/2600] -> Loss: 1805.3665
Epoch [  63/2600] -> Loss: 1810.8051
Epoch [  64/2600] -> Loss: 1793.9130
Epoch [  65/2600] -> Loss: 1766.8184
Epoch [  66/2600] -> Loss: 1755.5068
Epoch [  67/2600] -> Loss: 1739.3641
Epoch [  68/2600] -> Loss: 1726.1024
Epoch [  69/2600] -> Loss: 1731.2248
Epoch [  70/2600] -> Loss: 1713.2074
Epoch [  71/2600] -> Loss: 1727.1169
Epoch [  72/2600] -> Loss: 1731.2230
Epoch [  73/2600] -> Loss: 1693.8217
Epoch [  74/2600] -> Loss: 1680.4241
Epoch [  75/2600] -> Loss: 1709.2236
Epoch [  76/2600] -> Loss: 1675.4334
Epoch [  77/2600] -> Loss: 1668.1845
Epoch [  78/2600] -> Loss: 1669.5844
Epoch [  79/2600] -> Loss: 1667.7098
Epoch [  80/2600] -> Loss: 1699.9836
Epoch [  81/2600] -> Loss: 1679.6528
Epoch [  82/2600] -> Loss: 1676.8394
Epoch [  83/2600] -> Loss: 1681.2569
Epoch [  84/2600] -> Loss: 1672.2837
Epoch [  85/2600] -> Loss: 1665.6440
Epoch [  86/2600] -> Loss: 1634.9742
Epoch [  87/2600] -> Loss: 1650.2102
Epoch [  88/2600] -> Loss: 1672.9850
Epoch [  89/2600] -> Loss: 1636.3569
Epoch [  90/2600] -> Loss: 1658.8241
Epoch [  91/2600] -> Loss: 1632.7022
Epoch [  92/2600] -> Loss: 1677.7481
Epoch [  93/2600] -> Loss: 1698.9558
Epoch [  94/2600] -> Loss: 1651.3470
Epoch [  95/2600] -> Loss: 1639.9812
Epoch [  96/2600] -> Loss: 1713.0899
Epoch [  97/2600] -> Loss: 1676.4462
Epoch [  98/2600] -> Loss: 1645.4940
Epoch [  99/2600] -> Loss: 1630.1397
Epoch [ 100/2600] -> Loss: 1642.7544
Epoch [ 101/2600] -> Loss: 1666.3529
Epoch [ 102/2600] -> Loss: 1623.5461
Epoch [ 103/2600] -> Loss: 1624.8658
Epoch [ 104/2600] -> Loss: 1652.2337
Epoch [ 105/2600] -> Loss: 1644.3312
Epoch [ 106/2600] -> Loss: 1616.3312
Epoch [ 107/2600] -> Loss: 1626.8377
Epoch [ 108/2600] -> Loss: 1643.1812
Epoch [ 109/2600] -> Loss: 1631.7838
Epoch [ 110/2600] -> Loss: 1621.4462
Epoch [ 111/2600] -> Loss: 1628.8504
Epoch [ 112/2600] -> Loss: 1667.9022
Epoch [ 113/2600] -> Loss: 1673.7736
Epoch [ 114/2600] -> Loss: 1634.1615
Epoch [ 115/2600] -> Loss: 1644.2427
Epoch [ 116/2600] -> Loss: 1650.2264
Epoch   117: reducing learning rate of group 0 to 2.5000e-03.
Epoch [ 117/2600] -> Loss: 1635.0960
Epoch [ 118/2600] -> Loss: 1661.4656
Epoch [ 119/2600] -> Loss: 1642.9428
Epoch [ 120/2600] -> Loss: 1616.2618
Epoch [ 121/2600] -> Loss: 1620.0012
Epoch [ 122/2600] -> Loss: 1629.1116
Epoch [ 123/2600] -> Loss: 1642.0825
Epoch [ 124/2600] -> Loss: 1642.8144
Epoch [ 125/2600] -> Loss: 1644.7310
Epoch [ 126/2600] -> Loss: 1617.3405
Epoch [ 127/2600] -> Loss: 1633.7202
Epoch   128: reducing learning rate of group 0 to 1.2500e-03.
Epoch [ 128/2600] -> Loss: 1616.6733
Epoch [ 129/2600] -> Loss: 1625.7538
Epoch [ 130/2600] -> Loss: 1620.7526
Epoch [ 131/2600] -> Loss: 1615.3112
Epoch [ 132/2600] -> Loss: 1620.2209
Epoch [ 133/2600] -> Loss: 1609.2671
Epoch [ 134/2600] -> Loss: 1616.8142
Epoch [ 135/2600] -> Loss: 1617.6447
Epoch [ 136/2600] -> Loss: 1617.6532
Epoch [ 137/2600] -> Loss: 1606.6241
Epoch [ 138/2600] -> Loss: 1622.5983
Epoch [ 139/2600] -> Loss: 1620.5091
Epoch [ 140/2600] -> Loss: 1624.3582
Epoch [ 141/2600] -> Loss: 1611.6947
Epoch [ 142/2600] -> Loss: 1621.6198
Epoch [ 143/2600] -> Loss: 1618.8318
Epoch [ 144/2600] -> Loss: 1615.4594
Epoch [ 145/2600] -> Loss: 1610.7467
Epoch [ 146/2600] -> Loss: 1613.0642
Epoch [ 147/2600] -> Loss: 1614.1968
Epoch   148: reducing learning rate of group 0 to 6.2500e-04.
Epoch [ 148/2600] -> Loss: 1621.8247
Epoch [ 149/2600] -> Loss: 1620.8721
Epoch [ 150/2600] -> Loss: 1610.3267
Epoch [ 151/2600] -> Loss: 1613.1647
Epoch [ 152/2600] -> Loss: 1610.2388
Epoch [ 153/2600] -> Loss: 1621.6688
Epoch [ 154/2600] -> Loss: 1617.7840
Epoch [ 155/2600] -> Loss: 1617.6271
Epoch [ 156/2600] -> Loss: 1612.1171
Epoch [ 157/2600] -> Loss: 1615.1203
Epoch [ 158/2600] -> Loss: 1609.1246
Epoch   159: reducing learning rate of group 0 to 3.1250e-04.
Epoch [ 159/2600] -> Loss: 1607.6003
Epoch [ 160/2600] -> Loss: 1610.7804
Epoch [ 161/2600] -> Loss: 1611.7547
Epoch [ 162/2600] -> Loss: 1617.5328
Epoch [ 163/2600] -> Loss: 1610.5363
Epoch [ 164/2600] -> Loss: 1610.9455
Epoch [ 165/2600] -> Loss: 1617.6486
Epoch [ 166/2600] -> Loss: 1627.3369
Epoch [ 167/2600] -> Loss: 1609.2502
Epoch [ 168/2600] -> Loss: 1609.8654
Epoch [ 169/2600] -> Loss: 1609.3884
Epoch   170: reducing learning rate of group 0 to 1.5625e-04.
Epoch [ 170/2600] -> Loss: 1614.7011
Epoch [ 171/2600] -> Loss: 1621.7513
Epoch [ 172/2600] -> Loss: 1615.8004
Epoch [ 173/2600] -> Loss: 1610.9751
Epoch [ 174/2600] -> Loss: 1609.5543
Epoch [ 175/2600] -> Loss: 1615.1322
Epoch [ 176/2600] -> Loss: 1612.7681
Epoch [ 177/2600] -> Loss: 1616.2023
Epoch [ 178/2600] -> Loss: 1617.8282
Epoch [ 179/2600] -> Loss: 1611.2449
Epoch [ 180/2600] -> Loss: 1628.7755
Epoch   181: reducing learning rate of group 0 to 7.8125e-05.
Epoch [ 181/2600] -> Loss: 1607.4512
Epoch [ 182/2600] -> Loss: 1610.5234
Epoch [ 183/2600] -> Loss: 1615.4588
Epoch [ 184/2600] -> Loss: 1608.2690
Epoch [ 185/2600] -> Loss: 1608.5568
Epoch [ 186/2600] -> Loss: 1625.2628
Epoch [ 187/2600] -> Loss: 1612.0297
Epoch [ 188/2600] -> Loss: 1619.0904
Epoch [ 189/2600] -> Loss: 1623.0858
Epoch [ 190/2600] -> Loss: 1619.0975
Epoch [ 191/2600] -> Loss: 1614.1121
Epoch   192: reducing learning rate of group 0 to 3.9063e-05.
Epoch [ 192/2600] -> Loss: 1607.5648
Epoch [ 193/2600] -> Loss: 1609.0455
Epoch [ 194/2600] -> Loss: 1622.8309
Epoch [ 195/2600] -> Loss: 1617.0329
Epoch [ 196/2600] -> Loss: 1613.7188
Epoch [ 197/2600] -> Loss: 1616.9130
Epoch [ 198/2600] -> Loss: 1611.2249
Epoch [ 199/2600] -> Loss: 1606.9573
--------------------------------------------------
Model checkpoint saved as FFNN_200.pth
--------------------------------------------------
Epoch [ 200/2600] -> Loss: 1625.4275
Epoch [ 201/2600] -> Loss: 1618.9816
Epoch [ 202/2600] -> Loss: 1615.8412
Epoch [ 203/2600] -> Loss: 1602.7044
Epoch [ 204/2600] -> Loss: 1617.3935
Epoch [ 205/2600] -> Loss: 1613.3447
Epoch [ 206/2600] -> Loss: 1603.6263
Epoch [ 207/2600] -> Loss: 1613.2650
Epoch [ 208/2600] -> Loss: 1614.3515
Epoch [ 209/2600] -> Loss: 1608.7724
Epoch [ 210/2600] -> Loss: 1608.2084
Epoch [ 211/2600] -> Loss: 1623.2113
Epoch [ 212/2600] -> Loss: 1602.1669
Epoch [ 213/2600] -> Loss: 1620.3263
Epoch [ 214/2600] -> Loss: 1612.8182
Epoch [ 215/2600] -> Loss: 1608.9008
Epoch [ 216/2600] -> Loss: 1608.3868
Epoch [ 217/2600] -> Loss: 1607.9235
Epoch [ 218/2600] -> Loss: 1618.6003
Epoch [ 219/2600] -> Loss: 1614.4069
Epoch [ 220/2600] -> Loss: 1615.8393
Epoch [ 221/2600] -> Loss: 1608.0486
Epoch [ 222/2600] -> Loss: 1603.2124
Epoch   223: reducing learning rate of group 0 to 1.9531e-05.
Epoch [ 223/2600] -> Loss: 1610.2472
Epoch [ 224/2600] -> Loss: 1615.8416
Epoch [ 225/2600] -> Loss: 1603.2541
Epoch [ 226/2600] -> Loss: 1624.6328
Epoch [ 227/2600] -> Loss: 1618.8431
Epoch [ 228/2600] -> Loss: 1618.7618
Epoch [ 229/2600] -> Loss: 1612.2189
Epoch [ 230/2600] -> Loss: 1626.5839
Epoch [ 231/2600] -> Loss: 1609.7918
Epoch [ 232/2600] -> Loss: 1609.6266
Epoch [ 233/2600] -> Loss: 1620.7742
Epoch   234: reducing learning rate of group 0 to 9.7656e-06.
Epoch [ 234/2600] -> Loss: 1617.9149
Epoch [ 235/2600] -> Loss: 1618.0932
Epoch [ 236/2600] -> Loss: 1601.3931
Epoch [ 237/2600] -> Loss: 1613.3652
Epoch [ 238/2600] -> Loss: 1609.7728
Epoch [ 239/2600] -> Loss: 1617.8100
Epoch [ 240/2600] -> Loss: 1604.5310
Epoch [ 241/2600] -> Loss: 1607.7128
Epoch [ 242/2600] -> Loss: 1610.1712
Epoch [ 243/2600] -> Loss: 1609.5563
Epoch [ 244/2600] -> Loss: 1612.8062
Epoch [ 245/2600] -> Loss: 1620.8795
Epoch [ 246/2600] -> Loss: 1605.1153
Epoch   247: reducing learning rate of group 0 to 4.8828e-06.
Epoch [ 247/2600] -> Loss: 1615.1339
Epoch [ 248/2600] -> Loss: 1616.9834
Epoch [ 249/2600] -> Loss: 1612.2820
Epoch [ 250/2600] -> Loss: 1606.3414
Epoch [ 251/2600] -> Loss: 1614.7940
Epoch [ 252/2600] -> Loss: 1612.2782
Epoch [ 253/2600] -> Loss: 1609.9900
Epoch [ 254/2600] -> Loss: 1613.5629
Epoch [ 255/2600] -> Loss: 1614.6472
Epoch [ 256/2600] -> Loss: 1617.4720
Epoch [ 257/2600] -> Loss: 1615.9748
Epoch   258: reducing learning rate of group 0 to 2.4414e-06.
Epoch [ 258/2600] -> Loss: 1616.0793
Epoch [ 259/2600] -> Loss: 1619.1906
Epoch [ 260/2600] -> Loss: 1611.7773
Epoch [ 261/2600] -> Loss: 1608.8135
Epoch [ 262/2600] -> Loss: 1607.0678
Epoch [ 263/2600] -> Loss: 1612.0252
Epoch [ 264/2600] -> Loss: 1615.7607
Epoch [ 265/2600] -> Loss: 1614.5689
Epoch [ 266/2600] -> Loss: 1623.2140
Epoch [ 267/2600] -> Loss: 1614.4107
Epoch [ 268/2600] -> Loss: 1617.8189
Epoch   269: reducing learning rate of group 0 to 1.2207e-06.
Epoch [ 269/2600] -> Loss: 1626.1655
Epoch [ 270/2600] -> Loss: 1626.0853
Epoch [ 271/2600] -> Loss: 1609.0756
Epoch [ 272/2600] -> Loss: 1616.9221
Epoch [ 273/2600] -> Loss: 1612.4844
Epoch [ 274/2600] -> Loss: 1613.3881
Epoch [ 275/2600] -> Loss: 1607.2405
Epoch [ 276/2600] -> Loss: 1609.3340
Epoch [ 277/2600] -> Loss: 1622.0055
Epoch [ 278/2600] -> Loss: 1606.3117
Epoch [ 279/2600] -> Loss: 1614.1029
Epoch   280: reducing learning rate of group 0 to 6.1035e-07.
Epoch [ 280/2600] -> Loss: 1612.0325
Epoch [ 281/2600] -> Loss: 1608.5704
Epoch [ 282/2600] -> Loss: 1617.7349
Epoch [ 283/2600] -> Loss: 1612.6361
Epoch [ 284/2600] -> Loss: 1620.9131
Epoch [ 285/2600] -> Loss: 1608.9718
Epoch [ 286/2600] -> Loss: 1619.8643
Epoch [ 287/2600] -> Loss: 1617.0032
Epoch [ 288/2600] -> Loss: 1617.2811
Epoch [ 289/2600] -> Loss: 1617.3572
Epoch [ 290/2600] -> Loss: 1608.2439
Epoch   291: reducing learning rate of group 0 to 3.0518e-07.
Epoch [ 291/2600] -> Loss: 1613.5852
Epoch [ 292/2600] -> Loss: 1618.5862
Epoch [ 293/2600] -> Loss: 1619.0783
Epoch [ 294/2600] -> Loss: 1627.6625
Epoch [ 295/2600] -> Loss: 1610.6659
Epoch [ 296/2600] -> Loss: 1609.7903
Epoch [ 297/2600] -> Loss: 1620.6517
Epoch [ 298/2600] -> Loss: 1610.6482
Epoch [ 299/2600] -> Loss: 1615.3959
Epoch [ 300/2600] -> Loss: 1609.8037
Epoch [ 301/2600] -> Loss: 1610.4454
Epoch   302: reducing learning rate of group 0 to 1.5259e-07.
Epoch [ 302/2600] -> Loss: 1613.3507
Epoch [ 303/2600] -> Loss: 1615.2799
Epoch [ 304/2600] -> Loss: 1615.8335
Epoch [ 305/2600] -> Loss: 1624.3864
Epoch [ 306/2600] -> Loss: 1607.1609
Epoch [ 307/2600] -> Loss: 1611.4470
Epoch [ 308/2600] -> Loss: 1618.6732
Epoch [ 309/2600] -> Loss: 1617.7489
Epoch [ 310/2600] -> Loss: 1617.1013
Epoch [ 311/2600] -> Loss: 1612.3707
Epoch [ 312/2600] -> Loss: 1602.0334
Epoch   313: reducing learning rate of group 0 to 7.6294e-08.
Epoch [ 313/2600] -> Loss: 1619.1792
Epoch [ 314/2600] -> Loss: 1612.2159
Epoch [ 315/2600] -> Loss: 1611.5683
Epoch [ 316/2600] -> Loss: 1612.5817
Epoch [ 317/2600] -> Loss: 1615.0253
Epoch [ 318/2600] -> Loss: 1608.9286
Epoch [ 319/2600] -> Loss: 1610.6290
Epoch [ 320/2600] -> Loss: 1620.8106
Epoch [ 321/2600] -> Loss: 1609.6927
Epoch [ 322/2600] -> Loss: 1619.7762
Epoch [ 323/2600] -> Loss: 1604.3765
Epoch   324: reducing learning rate of group 0 to 3.8147e-08.
Epoch [ 324/2600] -> Loss: 1619.8912
Epoch [ 325/2600] -> Loss: 1608.1368
Epoch [ 326/2600] -> Loss: 1623.4782
Epoch [ 327/2600] -> Loss: 1614.9771
Epoch [ 328/2600] -> Loss: 1615.1452
Epoch [ 329/2600] -> Loss: 1603.8985
Epoch [ 330/2600] -> Loss: 1610.8911
Epoch [ 331/2600] -> Loss: 1617.2457
Epoch [ 332/2600] -> Loss: 1612.8750
Epoch [ 333/2600] -> Loss: 1613.8693
Epoch [ 334/2600] -> Loss: 1620.0547
Epoch   335: reducing learning rate of group 0 to 1.9073e-08.
Epoch [ 335/2600] -> Loss: 1618.3474
Epoch [ 336/2600] -> Loss: 1611.3328
Epoch [ 337/2600] -> Loss: 1614.8241
Epoch [ 338/2600] -> Loss: 1607.0904
Epoch [ 339/2600] -> Loss: 1622.3605
Epoch [ 340/2600] -> Loss: 1609.6524
Epoch [ 341/2600] -> Loss: 1612.7149
Epoch [ 342/2600] -> Loss: 1627.9909
Epoch [ 343/2600] -> Loss: 1614.6307
Epoch [ 344/2600] -> Loss: 1610.5839
Epoch [ 345/2600] -> Loss: 1612.1796
Epoch [ 346/2600] -> Loss: 1613.8924
Epoch [ 347/2600] -> Loss: 1617.4000
Epoch [ 348/2600] -> Loss: 1620.1413
Epoch [ 349/2600] -> Loss: 1615.8242
Epoch [ 350/2600] -> Loss: 1614.0330
Epoch [ 351/2600] -> Loss: 1608.8903
Epoch [ 352/2600] -> Loss: 1606.6075
Epoch [ 353/2600] -> Loss: 1611.3503
Epoch [ 354/2600] -> Loss: 1623.0096
Epoch [ 355/2600] -> Loss: 1609.5400
Epoch [ 356/2600] -> Loss: 1611.2736
Epoch [ 357/2600] -> Loss: 1612.1164
Epoch [ 358/2600] -> Loss: 1613.2879
Epoch [ 359/2600] -> Loss: 1613.3246
Epoch [ 360/2600] -> Loss: 1612.5035
Epoch [ 361/2600] -> Loss: 1613.1476
Epoch [ 362/2600] -> Loss: 1609.8022
Epoch [ 363/2600] -> Loss: 1624.1199
Epoch [ 364/2600] -> Loss: 1613.1368
Epoch [ 365/2600] -> Loss: 1603.0481
Epoch [ 366/2600] -> Loss: 1601.9812
Epoch [ 367/2600] -> Loss: 1613.3263
Epoch [ 368/2600] -> Loss: 1614.4086
Epoch [ 369/2600] -> Loss: 1608.2948
Epoch [ 370/2600] -> Loss: 1612.2927
Epoch [ 371/2600] -> Loss: 1616.1561
Epoch [ 372/2600] -> Loss: 1620.5724
Epoch [ 373/2600] -> Loss: 1622.3336
Epoch [ 374/2600] -> Loss: 1611.4912
Epoch [ 375/2600] -> Loss: 1606.1507
Epoch [ 376/2600] -> Loss: 1622.0575
Epoch [ 377/2600] -> Loss: 1610.3085
Epoch [ 378/2600] -> Loss: 1614.9405
Epoch [ 379/2600] -> Loss: 1619.0055
Epoch [ 380/2600] -> Loss: 1614.1271
Epoch [ 381/2600] -> Loss: 1613.6726
Epoch [ 382/2600] -> Loss: 1609.3740
Epoch [ 383/2600] -> Loss: 1611.1055
Epoch [ 384/2600] -> Loss: 1610.3328
Epoch [ 385/2600] -> Loss: 1611.6104
Epoch [ 386/2600] -> Loss: 1612.5685
Epoch [ 387/2600] -> Loss: 1622.7417
Epoch [ 388/2600] -> Loss: 1617.8108
Epoch [ 389/2600] -> Loss: 1608.4260
Epoch [ 390/2600] -> Loss: 1611.7127
Epoch [ 391/2600] -> Loss: 1609.7514
Epoch [ 392/2600] -> Loss: 1618.3679
Epoch [ 393/2600] -> Loss: 1610.2937
Epoch [ 394/2600] -> Loss: 1616.8104
Epoch [ 395/2600] -> Loss: 1618.2587
Epoch [ 396/2600] -> Loss: 1611.8317
Epoch [ 397/2600] -> Loss: 1619.0706
Epoch [ 398/2600] -> Loss: 1625.9847
Epoch [ 399/2600] -> Loss: 1618.5463
--------------------------------------------------
Model checkpoint saved as FFNN_400.pth
--------------------------------------------------
Epoch [ 400/2600] -> Loss: 1612.9675
Epoch [ 401/2600] -> Loss: 1613.5625
Epoch [ 402/2600] -> Loss: 1621.1988
Epoch [ 403/2600] -> Loss: 1612.7263
Epoch [ 404/2600] -> Loss: 1628.3044
Epoch [ 405/2600] -> Loss: 1610.8086
Epoch [ 406/2600] -> Loss: 1620.4845
Epoch [ 407/2600] -> Loss: 1615.7673
Epoch [ 408/2600] -> Loss: 1624.6096
Epoch [ 409/2600] -> Loss: 1610.2033
Epoch [ 410/2600] -> Loss: 1616.3135
Epoch [ 411/2600] -> Loss: 1611.1588
Epoch [ 412/2600] -> Loss: 1621.6073
Epoch [ 413/2600] -> Loss: 1613.6475
Epoch [ 414/2600] -> Loss: 1609.9894
Epoch [ 415/2600] -> Loss: 1615.1453
Epoch [ 416/2600] -> Loss: 1615.2393
Epoch [ 417/2600] -> Loss: 1612.2443
Epoch [ 418/2600] -> Loss: 1610.9607
Epoch [ 419/2600] -> Loss: 1621.5426
Epoch [ 420/2600] -> Loss: 1613.8570
Epoch [ 421/2600] -> Loss: 1606.6587
Epoch [ 422/2600] -> Loss: 1610.4054
Epoch [ 423/2600] -> Loss: 1609.1366
Epoch [ 424/2600] -> Loss: 1614.7514
Epoch [ 425/2600] -> Loss: 1617.6010
Epoch [ 426/2600] -> Loss: 1608.6515
Epoch [ 427/2600] -> Loss: 1617.8110
Epoch [ 428/2600] -> Loss: 1621.6411
Epoch [ 429/2600] -> Loss: 1615.3408
Epoch [ 430/2600] -> Loss: 1611.0540
Epoch [ 431/2600] -> Loss: 1607.7416
Epoch [ 432/2600] -> Loss: 1608.1328
Epoch [ 433/2600] -> Loss: 1617.1917
Epoch [ 434/2600] -> Loss: 1611.1254
Epoch [ 435/2600] -> Loss: 1610.1680
Epoch [ 436/2600] -> Loss: 1606.6486
Epoch [ 437/2600] -> Loss: 1610.9940
Epoch [ 438/2600] -> Loss: 1615.2623
Epoch [ 439/2600] -> Loss: 1615.9981
Epoch [ 440/2600] -> Loss: 1608.0746
Epoch [ 441/2600] -> Loss: 1611.4371
Epoch [ 442/2600] -> Loss: 1608.8557
Epoch [ 443/2600] -> Loss: 1616.3974
Epoch [ 444/2600] -> Loss: 1615.6578
Epoch [ 445/2600] -> Loss: 1611.1404
Epoch [ 446/2600] -> Loss: 1613.9142
Epoch [ 447/2600] -> Loss: 1614.8645
Epoch [ 448/2600] -> Loss: 1623.3087
Epoch [ 449/2600] -> Loss: 1617.6700
Epoch [ 450/2600] -> Loss: 1617.4307
Epoch [ 451/2600] -> Loss: 1624.0902
Epoch [ 452/2600] -> Loss: 1614.4945
Epoch [ 453/2600] -> Loss: 1613.2232
Epoch [ 454/2600] -> Loss: 1632.3208
Epoch [ 455/2600] -> Loss: 1604.7379
Epoch [ 456/2600] -> Loss: 1611.2927
Epoch [ 457/2600] -> Loss: 1609.0728
Epoch [ 458/2600] -> Loss: 1612.3520
Epoch [ 459/2600] -> Loss: 1615.5132
Epoch [ 460/2600] -> Loss: 1608.6334
Epoch [ 461/2600] -> Loss: 1607.6691
Epoch [ 462/2600] -> Loss: 1614.6018
Epoch [ 463/2600] -> Loss: 1614.4808
Epoch [ 464/2600] -> Loss: 1610.7643
Epoch [ 465/2600] -> Loss: 1624.6494
Epoch [ 466/2600] -> Loss: 1610.2924
Epoch [ 467/2600] -> Loss: 1606.2589
Epoch [ 468/2600] -> Loss: 1612.5131
Epoch [ 469/2600] -> Loss: 1611.8474
Epoch [ 470/2600] -> Loss: 1608.9226
Epoch [ 471/2600] -> Loss: 1615.7575
Epoch [ 472/2600] -> Loss: 1616.8540
Epoch [ 473/2600] -> Loss: 1620.5585
Epoch [ 474/2600] -> Loss: 1618.2675
Epoch [ 475/2600] -> Loss: 1623.3043
Epoch [ 476/2600] -> Loss: 1620.9590
Epoch [ 477/2600] -> Loss: 1612.0150
Epoch [ 478/2600] -> Loss: 1612.2173
Epoch [ 479/2600] -> Loss: 1614.3522
Epoch [ 480/2600] -> Loss: 1616.9020
Epoch [ 481/2600] -> Loss: 1613.1093
Epoch [ 482/2600] -> Loss: 1612.1585
Epoch [ 483/2600] -> Loss: 1604.1740
Epoch [ 484/2600] -> Loss: 1615.4132
Epoch [ 485/2600] -> Loss: 1609.2924
Epoch [ 486/2600] -> Loss: 1607.5107
Epoch [ 487/2600] -> Loss: 1612.1687
Epoch [ 488/2600] -> Loss: 1606.9362
Epoch [ 489/2600] -> Loss: 1608.1280
Epoch [ 490/2600] -> Loss: 1619.4783
Epoch [ 491/2600] -> Loss: 1618.4038
Epoch [ 492/2600] -> Loss: 1614.5358
Epoch [ 493/2600] -> Loss: 1611.7364
Epoch [ 494/2600] -> Loss: 1612.0843
Epoch [ 495/2600] -> Loss: 1614.1982
Epoch [ 496/2600] -> Loss: 1616.9136
Epoch [ 497/2600] -> Loss: 1606.0966
Epoch [ 498/2600] -> Loss: 1614.5356
Epoch [ 499/2600] -> Loss: 1611.9038
Epoch [ 500/2600] -> Loss: 1618.3678
Epoch [ 501/2600] -> Loss: 1620.1822
Epoch [ 502/2600] -> Loss: 1610.6384
Epoch [ 503/2600] -> Loss: 1607.0147
Epoch [ 504/2600] -> Loss: 1607.2806
Epoch [ 505/2600] -> Loss: 1624.7358
Epoch [ 506/2600] -> Loss: 1610.7863
Epoch [ 507/2600] -> Loss: 1617.8117
Epoch [ 508/2600] -> Loss: 1615.5647
Epoch [ 509/2600] -> Loss: 1615.3082
Epoch [ 510/2600] -> Loss: 1615.7999
Epoch [ 511/2600] -> Loss: 1629.5989
Epoch [ 512/2600] -> Loss: 1619.5601
Epoch [ 513/2600] -> Loss: 1609.6074
Epoch [ 514/2600] -> Loss: 1608.1130
Epoch [ 515/2600] -> Loss: 1609.4613
Epoch [ 516/2600] -> Loss: 1603.8858
Epoch [ 517/2600] -> Loss: 1605.1678
Epoch [ 518/2600] -> Loss: 1609.6458
Epoch [ 519/2600] -> Loss: 1616.3687
Epoch [ 520/2600] -> Loss: 1607.5643
Epoch [ 521/2600] -> Loss: 1606.1390
Epoch [ 522/2600] -> Loss: 1604.1832
Epoch [ 523/2600] -> Loss: 1613.4396
Epoch [ 524/2600] -> Loss: 1612.4739
Epoch [ 525/2600] -> Loss: 1611.3911
Epoch [ 526/2600] -> Loss: 1620.7768
Epoch [ 527/2600] -> Loss: 1618.0663
Epoch [ 528/2600] -> Loss: 1618.5275
Epoch [ 529/2600] -> Loss: 1611.3390
Epoch [ 530/2600] -> Loss: 1618.4680
Epoch [ 531/2600] -> Loss: 1613.8818
Epoch [ 532/2600] -> Loss: 1613.6764
Epoch [ 533/2600] -> Loss: 1615.6708
Epoch [ 534/2600] -> Loss: 1626.9895
Epoch [ 535/2600] -> Loss: 1608.5959
Epoch [ 536/2600] -> Loss: 1610.1256
Epoch [ 537/2600] -> Loss: 1613.9291
Epoch [ 538/2600] -> Loss: 1608.8385
Epoch [ 539/2600] -> Loss: 1627.9416
Epoch [ 540/2600] -> Loss: 1614.0194
Epoch [ 541/2600] -> Loss: 1607.1559
Epoch [ 542/2600] -> Loss: 1610.2324
Epoch [ 543/2600] -> Loss: 1608.4798
Epoch [ 544/2600] -> Loss: 1620.1792
Epoch [ 545/2600] -> Loss: 1610.5309
Epoch [ 546/2600] -> Loss: 1612.9904
Epoch [ 547/2600] -> Loss: 1607.9391
Epoch [ 548/2600] -> Loss: 1614.5769
Epoch [ 549/2600] -> Loss: 1617.6478
Epoch [ 550/2600] -> Loss: 1607.6601
Epoch [ 551/2600] -> Loss: 1618.7303
Epoch [ 552/2600] -> Loss: 1617.6726
Epoch [ 553/2600] -> Loss: 1615.2068
Epoch [ 554/2600] -> Loss: 1615.9757
Epoch [ 555/2600] -> Loss: 1623.3546
Epoch [ 556/2600] -> Loss: 1601.7460
Epoch [ 557/2600] -> Loss: 1618.4060
Epoch [ 558/2600] -> Loss: 1612.7525
Epoch [ 559/2600] -> Loss: 1612.5740
Epoch [ 560/2600] -> Loss: 1613.7982
Epoch [ 561/2600] -> Loss: 1616.6440
Epoch [ 562/2600] -> Loss: 1613.4903
Epoch [ 563/2600] -> Loss: 1624.2363
Epoch [ 564/2600] -> Loss: 1604.1655
Epoch [ 565/2600] -> Loss: 1605.3258
Epoch [ 566/2600] -> Loss: 1606.7820
Epoch [ 567/2600] -> Loss: 1623.4725
Epoch [ 568/2600] -> Loss: 1613.5840
Epoch [ 569/2600] -> Loss: 1617.0000
Epoch [ 570/2600] -> Loss: 1615.7368
Epoch [ 571/2600] -> Loss: 1614.2811
Epoch [ 572/2600] -> Loss: 1609.3622
Epoch [ 573/2600] -> Loss: 1613.0657
Epoch [ 574/2600] -> Loss: 1606.7040
Epoch [ 575/2600] -> Loss: 1611.8348
Epoch [ 576/2600] -> Loss: 1619.9270
Epoch [ 577/2600] -> Loss: 1629.2113
Epoch [ 578/2600] -> Loss: 1613.9850
Epoch [ 579/2600] -> Loss: 1611.2532
Epoch [ 580/2600] -> Loss: 1608.1665
Epoch [ 581/2600] -> Loss: 1620.1870
Epoch [ 582/2600] -> Loss: 1625.0317
Epoch [ 583/2600] -> Loss: 1614.2444
Epoch [ 584/2600] -> Loss: 1610.3576
Epoch [ 585/2600] -> Loss: 1606.8681
Epoch [ 586/2600] -> Loss: 1605.9001
Epoch [ 587/2600] -> Loss: 1614.1649
Epoch [ 588/2600] -> Loss: 1609.4319
Epoch [ 589/2600] -> Loss: 1614.9847
Epoch [ 590/2600] -> Loss: 1615.6601
Epoch [ 591/2600] -> Loss: 1604.8770
Epoch [ 592/2600] -> Loss: 1620.4709
Epoch [ 593/2600] -> Loss: 1610.2028
Epoch [ 594/2600] -> Loss: 1622.9551
Epoch [ 595/2600] -> Loss: 1615.1993
Epoch [ 596/2600] -> Loss: 1615.4668
Epoch [ 597/2600] -> Loss: 1612.8366
Epoch [ 598/2600] -> Loss: 1618.2584
Epoch [ 599/2600] -> Loss: 1611.6491
--------------------------------------------------
Model checkpoint saved as FFNN_600.pth
--------------------------------------------------
Epoch [ 600/2600] -> Loss: 1619.9474
Epoch [ 601/2600] -> Loss: 1610.5765
Epoch [ 602/2600] -> Loss: 1602.7889
Epoch [ 603/2600] -> Loss: 1610.6623
Epoch [ 604/2600] -> Loss: 1608.5826
Epoch [ 605/2600] -> Loss: 1615.6354
Epoch [ 606/2600] -> Loss: 1606.1110
Epoch [ 607/2600] -> Loss: 1613.1175
Epoch [ 608/2600] -> Loss: 1609.7318
Epoch [ 609/2600] -> Loss: 1611.5983
Epoch [ 610/2600] -> Loss: 1606.3292
Epoch [ 611/2600] -> Loss: 1612.4748
Epoch [ 612/2600] -> Loss: 1617.8516
Epoch [ 613/2600] -> Loss: 1615.4253
Epoch [ 614/2600] -> Loss: 1620.0975
Epoch [ 615/2600] -> Loss: 1613.3815
Epoch [ 616/2600] -> Loss: 1605.8672
Epoch [ 617/2600] -> Loss: 1608.5923
Epoch [ 618/2600] -> Loss: 1606.7647
Epoch [ 619/2600] -> Loss: 1612.4798
Epoch [ 620/2600] -> Loss: 1611.8389
Epoch [ 621/2600] -> Loss: 1611.3446
Epoch [ 622/2600] -> Loss: 1621.1214
Epoch [ 623/2600] -> Loss: 1613.8259
Epoch [ 624/2600] -> Loss: 1614.5996
Epoch [ 625/2600] -> Loss: 1609.4937
Epoch [ 626/2600] -> Loss: 1609.1536
Epoch [ 627/2600] -> Loss: 1612.7733
Epoch [ 628/2600] -> Loss: 1625.6701
Epoch [ 629/2600] -> Loss: 1610.4146
Epoch [ 630/2600] -> Loss: 1611.6367
Epoch [ 631/2600] -> Loss: 1625.4547
Epoch [ 632/2600] -> Loss: 1615.1222
Epoch [ 633/2600] -> Loss: 1619.5222
Epoch [ 634/2600] -> Loss: 1609.8519
Epoch [ 635/2600] -> Loss: 1607.2626
Epoch [ 636/2600] -> Loss: 1622.4316
Epoch [ 637/2600] -> Loss: 1617.9670
Epoch [ 638/2600] -> Loss: 1617.8908
Epoch [ 639/2600] -> Loss: 1624.5374
Epoch [ 640/2600] -> Loss: 1614.3789
Epoch [ 641/2600] -> Loss: 1614.0257
Epoch [ 642/2600] -> Loss: 1625.0525
Epoch [ 643/2600] -> Loss: 1607.5604
Epoch [ 644/2600] -> Loss: 1615.3324
Epoch [ 645/2600] -> Loss: 1608.8343
Epoch [ 646/2600] -> Loss: 1618.2535
Epoch [ 647/2600] -> Loss: 1610.9510
Epoch [ 648/2600] -> Loss: 1616.3537
Epoch [ 649/2600] -> Loss: 1612.5984
Epoch [ 650/2600] -> Loss: 1614.6153
Epoch [ 651/2600] -> Loss: 1612.6023
Epoch [ 652/2600] -> Loss: 1620.3939
Epoch [ 653/2600] -> Loss: 1606.5744
Epoch [ 654/2600] -> Loss: 1615.6244
Epoch [ 655/2600] -> Loss: 1616.9615
Epoch [ 656/2600] -> Loss: 1610.7618
Epoch [ 657/2600] -> Loss: 1604.6277
Epoch [ 658/2600] -> Loss: 1612.5051
Epoch [ 659/2600] -> Loss: 1613.2071
Epoch [ 660/2600] -> Loss: 1611.5929
Epoch [ 661/2600] -> Loss: 1613.4452
Epoch [ 662/2600] -> Loss: 1604.8152
Epoch [ 663/2600] -> Loss: 1614.6992
Epoch [ 664/2600] -> Loss: 1607.3253
Epoch [ 665/2600] -> Loss: 1610.6146
Epoch [ 666/2600] -> Loss: 1611.9351
Epoch [ 667/2600] -> Loss: 1606.5413
Epoch [ 668/2600] -> Loss: 1612.4327
Epoch [ 669/2600] -> Loss: 1612.9241
Epoch [ 670/2600] -> Loss: 1613.0298
Epoch [ 671/2600] -> Loss: 1614.3780
Epoch [ 672/2600] -> Loss: 1619.6213
Epoch [ 673/2600] -> Loss: 1605.4320
Epoch [ 674/2600] -> Loss: 1607.6767
Epoch [ 675/2600] -> Loss: 1616.3970
Epoch [ 676/2600] -> Loss: 1615.9247
Epoch [ 677/2600] -> Loss: 1611.7528
Epoch [ 678/2600] -> Loss: 1619.1640
Epoch [ 679/2600] -> Loss: 1606.3933
Epoch [ 680/2600] -> Loss: 1615.8987
Epoch [ 681/2600] -> Loss: 1619.2693
Epoch [ 682/2600] -> Loss: 1623.3328
Epoch [ 683/2600] -> Loss: 1611.4315
Epoch [ 684/2600] -> Loss: 1617.2080
Epoch [ 685/2600] -> Loss: 1619.4920
Epoch [ 686/2600] -> Loss: 1612.1411
Epoch [ 687/2600] -> Loss: 1619.7520
Epoch [ 688/2600] -> Loss: 1616.3680
Epoch [ 689/2600] -> Loss: 1617.4395
Epoch [ 690/2600] -> Loss: 1609.0973
Epoch [ 691/2600] -> Loss: 1608.0502
Epoch [ 692/2600] -> Loss: 1608.5119
Epoch [ 693/2600] -> Loss: 1616.1621
Epoch [ 694/2600] -> Loss: 1617.4731
Epoch [ 695/2600] -> Loss: 1621.1567
Epoch [ 696/2600] -> Loss: 1618.4397
Epoch [ 697/2600] -> Loss: 1616.2060
Epoch [ 698/2600] -> Loss: 1606.1182
Epoch [ 699/2600] -> Loss: 1608.7621
Epoch [ 700/2600] -> Loss: 1613.4399
Epoch [ 701/2600] -> Loss: 1618.9602
Epoch [ 702/2600] -> Loss: 1610.9843
Epoch [ 703/2600] -> Loss: 1609.7556
Epoch [ 704/2600] -> Loss: 1612.5768
Epoch [ 705/2600] -> Loss: 1617.7377
Epoch [ 706/2600] -> Loss: 1612.8972
Epoch [ 707/2600] -> Loss: 1620.8728
Epoch [ 708/2600] -> Loss: 1620.4683
Epoch [ 709/2600] -> Loss: 1623.5913
Epoch [ 710/2600] -> Loss: 1614.3150
Epoch [ 711/2600] -> Loss: 1613.5481
Epoch [ 712/2600] -> Loss: 1606.7272
Epoch [ 713/2600] -> Loss: 1615.6472
Epoch [ 714/2600] -> Loss: 1613.5682
Epoch [ 715/2600] -> Loss: 1617.1998
Epoch [ 716/2600] -> Loss: 1612.4453
Epoch [ 717/2600] -> Loss: 1605.5503
Epoch [ 718/2600] -> Loss: 1609.5021
Epoch [ 719/2600] -> Loss: 1620.3567
Epoch [ 720/2600] -> Loss: 1611.4643
Epoch [ 721/2600] -> Loss: 1614.4731
Epoch [ 722/2600] -> Loss: 1607.9074
Epoch [ 723/2600] -> Loss: 1621.5089
Epoch [ 724/2600] -> Loss: 1611.2238
Epoch [ 725/2600] -> Loss: 1612.1522
Epoch [ 726/2600] -> Loss: 1614.4948
Epoch [ 727/2600] -> Loss: 1607.7498
Epoch [ 728/2600] -> Loss: 1608.2371
Epoch [ 729/2600] -> Loss: 1619.1151
Epoch [ 730/2600] -> Loss: 1605.4116
Epoch [ 731/2600] -> Loss: 1610.4531
Epoch [ 732/2600] -> Loss: 1619.2249
Epoch [ 733/2600] -> Loss: 1613.5593
Epoch [ 734/2600] -> Loss: 1609.2187
Epoch [ 735/2600] -> Loss: 1614.0038
Epoch [ 736/2600] -> Loss: 1617.6891
Epoch [ 737/2600] -> Loss: 1612.4948
Epoch [ 738/2600] -> Loss: 1626.5814
Epoch [ 739/2600] -> Loss: 1623.5476
Epoch [ 740/2600] -> Loss: 1606.8267
Epoch [ 741/2600] -> Loss: 1622.4213
Epoch [ 742/2600] -> Loss: 1616.7766
Epoch [ 743/2600] -> Loss: 1609.2655
Epoch [ 744/2600] -> Loss: 1625.4779
Epoch [ 745/2600] -> Loss: 1606.1591
Epoch [ 746/2600] -> Loss: 1613.5365
Epoch [ 747/2600] -> Loss: 1611.6314
Epoch [ 748/2600] -> Loss: 1606.6401
Epoch [ 749/2600] -> Loss: 1613.4307
Epoch [ 750/2600] -> Loss: 1618.3502
Epoch [ 751/2600] -> Loss: 1608.8882
Epoch [ 752/2600] -> Loss: 1608.7387
Epoch [ 753/2600] -> Loss: 1612.6160
Epoch [ 754/2600] -> Loss: 1609.0673
Epoch [ 755/2600] -> Loss: 1612.2530
Epoch [ 756/2600] -> Loss: 1609.0098
Epoch [ 757/2600] -> Loss: 1615.4825
Epoch [ 758/2600] -> Loss: 1612.6199
Epoch [ 759/2600] -> Loss: 1624.7334
Epoch [ 760/2600] -> Loss: 1618.4015
Epoch [ 761/2600] -> Loss: 1611.4571
Epoch [ 762/2600] -> Loss: 1616.4166
Epoch [ 763/2600] -> Loss: 1609.5131
Epoch [ 764/2600] -> Loss: 1610.3874
Epoch [ 765/2600] -> Loss: 1612.3987
Epoch [ 766/2600] -> Loss: 1614.6531
Epoch [ 767/2600] -> Loss: 1617.7460
Epoch [ 768/2600] -> Loss: 1606.9870
Epoch [ 769/2600] -> Loss: 1612.2152
Epoch [ 770/2600] -> Loss: 1616.1643
Epoch [ 771/2600] -> Loss: 1613.6343
Epoch [ 772/2600] -> Loss: 1616.5206
Epoch [ 773/2600] -> Loss: 1611.5764
Epoch [ 774/2600] -> Loss: 1618.9303
Epoch [ 775/2600] -> Loss: 1607.2093
Epoch [ 776/2600] -> Loss: 1616.8140
Epoch [ 777/2600] -> Loss: 1617.4463
Epoch [ 778/2600] -> Loss: 1622.2957
Epoch [ 779/2600] -> Loss: 1611.7369
Epoch [ 780/2600] -> Loss: 1618.8456
Epoch [ 781/2600] -> Loss: 1618.2010
Epoch [ 782/2600] -> Loss: 1616.7185
Epoch [ 783/2600] -> Loss: 1620.9501
Epoch [ 784/2600] -> Loss: 1611.1078
Epoch [ 785/2600] -> Loss: 1613.7283
Epoch [ 786/2600] -> Loss: 1613.1632
Epoch [ 787/2600] -> Loss: 1612.6698
Epoch [ 788/2600] -> Loss: 1619.8976
Epoch [ 789/2600] -> Loss: 1613.4488
Epoch [ 790/2600] -> Loss: 1625.7894
Epoch [ 791/2600] -> Loss: 1610.0579
Epoch [ 792/2600] -> Loss: 1608.4570
Epoch [ 793/2600] -> Loss: 1611.9912
Epoch [ 794/2600] -> Loss: 1607.5183
Epoch [ 795/2600] -> Loss: 1613.4283
Epoch [ 796/2600] -> Loss: 1613.5838
Epoch [ 797/2600] -> Loss: 1617.8858
Epoch [ 798/2600] -> Loss: 1609.3246
Epoch [ 799/2600] -> Loss: 1611.3045
--------------------------------------------------
Model checkpoint saved as FFNN_800.pth
--------------------------------------------------
Epoch [ 800/2600] -> Loss: 1614.4652
Epoch [ 801/2600] -> Loss: 1611.4209
Epoch [ 802/2600] -> Loss: 1612.6021
Epoch [ 803/2600] -> Loss: 1613.3468
Epoch [ 804/2600] -> Loss: 1610.2453
Epoch [ 805/2600] -> Loss: 1610.3474
Epoch [ 806/2600] -> Loss: 1618.5155
Epoch [ 807/2600] -> Loss: 1620.4370
Epoch [ 808/2600] -> Loss: 1615.8832
Epoch [ 809/2600] -> Loss: 1617.7172
Epoch [ 810/2600] -> Loss: 1608.0588
Epoch [ 811/2600] -> Loss: 1620.6920
Epoch [ 812/2600] -> Loss: 1609.5165
Epoch [ 813/2600] -> Loss: 1620.9862
Epoch [ 814/2600] -> Loss: 1613.7642
Epoch [ 815/2600] -> Loss: 1612.8383
Epoch [ 816/2600] -> Loss: 1616.1323
Epoch [ 817/2600] -> Loss: 1610.6301
Epoch [ 818/2600] -> Loss: 1619.3755
Epoch [ 819/2600] -> Loss: 1617.1694
Epoch [ 820/2600] -> Loss: 1618.1945
Epoch [ 821/2600] -> Loss: 1606.5713
Epoch [ 822/2600] -> Loss: 1602.5777
Epoch [ 823/2600] -> Loss: 1613.4802
Epoch [ 824/2600] -> Loss: 1621.1279
Epoch [ 825/2600] -> Loss: 1620.6784
Epoch [ 826/2600] -> Loss: 1608.2766
Epoch [ 827/2600] -> Loss: 1609.1272
Epoch [ 828/2600] -> Loss: 1605.7341
Epoch [ 829/2600] -> Loss: 1615.4709
Epoch [ 830/2600] -> Loss: 1616.4065
Epoch [ 831/2600] -> Loss: 1615.9208
Epoch [ 832/2600] -> Loss: 1605.2610
Epoch [ 833/2600] -> Loss: 1614.7756
Epoch [ 834/2600] -> Loss: 1611.4117
Epoch [ 835/2600] -> Loss: 1620.2420
Epoch [ 836/2600] -> Loss: 1608.0266
Epoch [ 837/2600] -> Loss: 1613.0302
Epoch [ 838/2600] -> Loss: 1610.4254
Epoch [ 839/2600] -> Loss: 1619.1395
Epoch [ 840/2600] -> Loss: 1617.4325
Epoch [ 841/2600] -> Loss: 1612.3255
Epoch [ 842/2600] -> Loss: 1610.1695
Epoch [ 843/2600] -> Loss: 1613.5930
Epoch [ 844/2600] -> Loss: 1613.8083
Epoch [ 845/2600] -> Loss: 1614.7117
Epoch [ 846/2600] -> Loss: 1617.2735
Epoch [ 847/2600] -> Loss: 1618.7827
Epoch [ 848/2600] -> Loss: 1612.3367
Epoch [ 849/2600] -> Loss: 1620.7339
Epoch [ 850/2600] -> Loss: 1625.8215
Epoch [ 851/2600] -> Loss: 1606.6065
Epoch [ 852/2600] -> Loss: 1610.9995
Epoch [ 853/2600] -> Loss: 1622.4531
Epoch [ 854/2600] -> Loss: 1619.0893
Epoch [ 855/2600] -> Loss: 1618.1756
Epoch [ 856/2600] -> Loss: 1616.2543
Epoch [ 857/2600] -> Loss: 1615.2538
Epoch [ 858/2600] -> Loss: 1610.0162
Epoch [ 859/2600] -> Loss: 1615.6817
Epoch [ 860/2600] -> Loss: 1614.9528
Epoch [ 861/2600] -> Loss: 1614.8389
Epoch [ 862/2600] -> Loss: 1611.7594
Epoch [ 863/2600] -> Loss: 1619.0716
Epoch [ 864/2600] -> Loss: 1611.8987
Epoch [ 865/2600] -> Loss: 1621.0602
Epoch [ 866/2600] -> Loss: 1617.1896
Epoch [ 867/2600] -> Loss: 1611.9774
Epoch [ 868/2600] -> Loss: 1616.9775
Epoch [ 869/2600] -> Loss: 1608.1303
Epoch [ 870/2600] -> Loss: 1616.5482
Epoch [ 871/2600] -> Loss: 1612.6725
Epoch [ 872/2600] -> Loss: 1609.0827
Epoch [ 873/2600] -> Loss: 1617.5638
Epoch [ 874/2600] -> Loss: 1600.7536
Epoch [ 875/2600] -> Loss: 1619.1747
Epoch [ 876/2600] -> Loss: 1620.6497
Epoch [ 877/2600] -> Loss: 1607.9927
Epoch [ 878/2600] -> Loss: 1610.1076
Epoch [ 879/2600] -> Loss: 1616.4505
Epoch [ 880/2600] -> Loss: 1611.0254
Epoch [ 881/2600] -> Loss: 1618.7751
Epoch [ 882/2600] -> Loss: 1609.7145
Epoch [ 883/2600] -> Loss: 1615.0519
Epoch [ 884/2600] -> Loss: 1620.8866
Epoch [ 885/2600] -> Loss: 1616.7872
Epoch [ 886/2600] -> Loss: 1614.4648
Epoch [ 887/2600] -> Loss: 1613.0764
Epoch [ 888/2600] -> Loss: 1607.6686
Epoch [ 889/2600] -> Loss: 1608.7751
Epoch [ 890/2600] -> Loss: 1608.8742
Epoch [ 891/2600] -> Loss: 1615.9256
Epoch [ 892/2600] -> Loss: 1605.9327
Epoch [ 893/2600] -> Loss: 1606.7121
Epoch [ 894/2600] -> Loss: 1610.7168
Epoch [ 895/2600] -> Loss: 1615.2258
Epoch [ 896/2600] -> Loss: 1619.6885
Epoch [ 897/2600] -> Loss: 1607.0779
Epoch [ 898/2600] -> Loss: 1608.2654
Epoch [ 899/2600] -> Loss: 1607.3190
Epoch [ 900/2600] -> Loss: 1611.4460
Epoch [ 901/2600] -> Loss: 1613.1396
Epoch [ 902/2600] -> Loss: 1609.9933
Epoch [ 903/2600] -> Loss: 1620.0190
Epoch [ 904/2600] -> Loss: 1619.9839
Epoch [ 905/2600] -> Loss: 1612.1385
Epoch [ 906/2600] -> Loss: 1611.4088
Epoch [ 907/2600] -> Loss: 1609.8179
Epoch [ 908/2600] -> Loss: 1611.4544
Epoch [ 909/2600] -> Loss: 1615.7943
Epoch [ 910/2600] -> Loss: 1605.3940
Epoch [ 911/2600] -> Loss: 1611.1560
Epoch [ 912/2600] -> Loss: 1614.8863
Epoch [ 913/2600] -> Loss: 1609.8759
Epoch [ 914/2600] -> Loss: 1616.4468
Epoch [ 915/2600] -> Loss: 1604.5540
Epoch [ 916/2600] -> Loss: 1612.4352
Epoch [ 917/2600] -> Loss: 1603.8621
Epoch [ 918/2600] -> Loss: 1612.5932
Epoch [ 919/2600] -> Loss: 1616.4164
Epoch [ 920/2600] -> Loss: 1606.1832
Epoch [ 921/2600] -> Loss: 1612.1769
Epoch [ 922/2600] -> Loss: 1607.0632
Epoch [ 923/2600] -> Loss: 1611.2207
Epoch [ 924/2600] -> Loss: 1608.1613
Epoch [ 925/2600] -> Loss: 1605.6382
Epoch [ 926/2600] -> Loss: 1610.6220
Epoch [ 927/2600] -> Loss: 1618.9350
Epoch [ 928/2600] -> Loss: 1606.5868
Epoch [ 929/2600] -> Loss: 1620.8803
Epoch [ 930/2600] -> Loss: 1615.1901
Epoch [ 931/2600] -> Loss: 1613.0312
Epoch [ 932/2600] -> Loss: 1618.6671
Epoch [ 933/2600] -> Loss: 1611.4184
Epoch [ 934/2600] -> Loss: 1612.4668
Epoch [ 935/2600] -> Loss: 1613.2600
Epoch [ 936/2600] -> Loss: 1610.8301
Epoch [ 937/2600] -> Loss: 1610.3825
Epoch [ 938/2600] -> Loss: 1615.3018
Epoch [ 939/2600] -> Loss: 1622.7868
Epoch [ 940/2600] -> Loss: 1613.9212
Epoch [ 941/2600] -> Loss: 1620.2967
Epoch [ 942/2600] -> Loss: 1607.6439
Epoch [ 943/2600] -> Loss: 1625.1032
Epoch [ 944/2600] -> Loss: 1622.8896
Epoch [ 945/2600] -> Loss: 1608.6155
Epoch [ 946/2600] -> Loss: 1606.9489
Epoch [ 947/2600] -> Loss: 1608.8787
Epoch [ 948/2600] -> Loss: 1618.0633
Epoch [ 949/2600] -> Loss: 1614.3539
Epoch [ 950/2600] -> Loss: 1615.2992
Epoch [ 951/2600] -> Loss: 1621.9523
Epoch [ 952/2600] -> Loss: 1622.1921
Epoch [ 953/2600] -> Loss: 1605.8099
Epoch [ 954/2600] -> Loss: 1616.8464
Epoch [ 955/2600] -> Loss: 1607.1109
Epoch [ 956/2600] -> Loss: 1609.8602
Epoch [ 957/2600] -> Loss: 1609.9344
Epoch [ 958/2600] -> Loss: 1608.5684
Epoch [ 959/2600] -> Loss: 1623.0436
Epoch [ 960/2600] -> Loss: 1619.4069
Epoch [ 961/2600] -> Loss: 1608.9461
Epoch [ 962/2600] -> Loss: 1615.7481
Epoch [ 963/2600] -> Loss: 1610.9564
Epoch [ 964/2600] -> Loss: 1611.0422
Epoch [ 965/2600] -> Loss: 1605.9038
Epoch [ 966/2600] -> Loss: 1610.2648
Epoch [ 967/2600] -> Loss: 1610.5791
Epoch [ 968/2600] -> Loss: 1603.4024
Epoch [ 969/2600] -> Loss: 1639.4896
Epoch [ 970/2600] -> Loss: 1611.1823
Epoch [ 971/2600] -> Loss: 1609.2377
Epoch [ 972/2600] -> Loss: 1607.1506
Epoch [ 973/2600] -> Loss: 1613.9295
Epoch [ 974/2600] -> Loss: 1604.5624
Epoch [ 975/2600] -> Loss: 1610.3447
Epoch [ 976/2600] -> Loss: 1620.2457
Epoch [ 977/2600] -> Loss: 1615.8134
Epoch [ 978/2600] -> Loss: 1602.4722
Epoch [ 979/2600] -> Loss: 1612.3910
Epoch [ 980/2600] -> Loss: 1612.6023
Epoch [ 981/2600] -> Loss: 1615.0494
Epoch [ 982/2600] -> Loss: 1606.1538
Epoch [ 983/2600] -> Loss: 1620.9264
Epoch [ 984/2600] -> Loss: 1606.3322
Epoch [ 985/2600] -> Loss: 1614.7127
Epoch [ 986/2600] -> Loss: 1616.2232
Epoch [ 987/2600] -> Loss: 1616.8641
Epoch [ 988/2600] -> Loss: 1609.5408
Epoch [ 989/2600] -> Loss: 1607.0118
Epoch [ 990/2600] -> Loss: 1611.8264
Epoch [ 991/2600] -> Loss: 1608.0381
Epoch [ 992/2600] -> Loss: 1607.5997
Epoch [ 993/2600] -> Loss: 1614.4754
Epoch [ 994/2600] -> Loss: 1612.4667
Epoch [ 995/2600] -> Loss: 1616.2023
Epoch [ 996/2600] -> Loss: 1614.7011
Epoch [ 997/2600] -> Loss: 1603.0910
Epoch [ 998/2600] -> Loss: 1609.2296
Epoch [ 999/2600] -> Loss: 1608.8793
--------------------------------------------------
Model checkpoint saved as FFNN_1000.pth
--------------------------------------------------
Epoch [1000/2600] -> Loss: 1615.7058
Epoch [1001/2600] -> Loss: 1605.3154
Epoch [1002/2600] -> Loss: 1610.6139
Epoch [1003/2600] -> Loss: 1623.4337
Epoch [1004/2600] -> Loss: 1622.8919
Epoch [1005/2600] -> Loss: 1614.3159
Epoch [1006/2600] -> Loss: 1605.2758
Epoch [1007/2600] -> Loss: 1622.8054
Epoch [1008/2600] -> Loss: 1606.3533
Epoch [1009/2600] -> Loss: 1616.2924
Epoch [1010/2600] -> Loss: 1621.4794
Epoch [1011/2600] -> Loss: 1613.0581
Epoch [1012/2600] -> Loss: 1611.5181
Epoch [1013/2600] -> Loss: 1615.7954
Epoch [1014/2600] -> Loss: 1613.5758
Epoch [1015/2600] -> Loss: 1616.8263
Epoch [1016/2600] -> Loss: 1624.2167
Epoch [1017/2600] -> Loss: 1627.1314
Epoch [1018/2600] -> Loss: 1622.1780
Epoch [1019/2600] -> Loss: 1611.9362
Epoch [1020/2600] -> Loss: 1610.5162
Epoch [1021/2600] -> Loss: 1619.9230
Epoch [1022/2600] -> Loss: 1606.1157
Epoch [1023/2600] -> Loss: 1612.2681
Epoch [1024/2600] -> Loss: 1611.3525
Epoch [1025/2600] -> Loss: 1615.0124
Epoch [1026/2600] -> Loss: 1615.3544
Epoch [1027/2600] -> Loss: 1607.7294
Epoch [1028/2600] -> Loss: 1613.6149
Epoch [1029/2600] -> Loss: 1614.6118
Epoch [1030/2600] -> Loss: 1618.0518
Epoch [1031/2600] -> Loss: 1613.1956
Epoch [1032/2600] -> Loss: 1620.2445
Epoch [1033/2600] -> Loss: 1612.1482
Epoch [1034/2600] -> Loss: 1613.6490
Epoch [1035/2600] -> Loss: 1609.5768
Epoch [1036/2600] -> Loss: 1608.4407
Epoch [1037/2600] -> Loss: 1607.0734
Epoch [1038/2600] -> Loss: 1613.1625
Epoch [1039/2600] -> Loss: 1604.8285
Epoch [1040/2600] -> Loss: 1608.0889
Epoch [1041/2600] -> Loss: 1617.9904
Epoch [1042/2600] -> Loss: 1619.8835
Epoch [1043/2600] -> Loss: 1609.9189
Epoch [1044/2600] -> Loss: 1616.3273
Epoch [1045/2600] -> Loss: 1619.5506
Epoch [1046/2600] -> Loss: 1609.9294
Epoch [1047/2600] -> Loss: 1604.6921
Epoch [1048/2600] -> Loss: 1610.9773
Epoch [1049/2600] -> Loss: 1607.8121
Epoch [1050/2600] -> Loss: 1615.0702
Epoch [1051/2600] -> Loss: 1611.3604
Epoch [1052/2600] -> Loss: 1614.0793
Epoch [1053/2600] -> Loss: 1607.3903
Epoch [1054/2600] -> Loss: 1613.1277
Epoch [1055/2600] -> Loss: 1611.9416
Epoch [1056/2600] -> Loss: 1608.6257
Epoch [1057/2600] -> Loss: 1610.8286
Epoch [1058/2600] -> Loss: 1617.9842
Epoch [1059/2600] -> Loss: 1603.6384
Epoch [1060/2600] -> Loss: 1620.2974
Epoch [1061/2600] -> Loss: 1623.6867
Epoch [1062/2600] -> Loss: 1609.4911
Epoch [1063/2600] -> Loss: 1611.2052
Epoch [1064/2600] -> Loss: 1610.7661
Epoch [1065/2600] -> Loss: 1608.1171
Epoch [1066/2600] -> Loss: 1619.1400
Epoch [1067/2600] -> Loss: 1626.3212
Epoch [1068/2600] -> Loss: 1607.1779
Epoch [1069/2600] -> Loss: 1609.8990
Epoch [1070/2600] -> Loss: 1608.3810
Epoch [1071/2600] -> Loss: 1616.5695
Epoch [1072/2600] -> Loss: 1611.5779
Epoch [1073/2600] -> Loss: 1610.7245
Epoch [1074/2600] -> Loss: 1613.5029
Epoch [1075/2600] -> Loss: 1604.2631
Epoch [1076/2600] -> Loss: 1613.5976
Epoch [1077/2600] -> Loss: 1609.9046
Epoch [1078/2600] -> Loss: 1616.5724
Epoch [1079/2600] -> Loss: 1616.7667
Epoch [1080/2600] -> Loss: 1619.2056
Epoch [1081/2600] -> Loss: 1608.0291
Epoch [1082/2600] -> Loss: 1623.6041
Epoch [1083/2600] -> Loss: 1606.1161
Epoch [1084/2600] -> Loss: 1613.5483
Epoch [1085/2600] -> Loss: 1611.0405
Epoch [1086/2600] -> Loss: 1610.8955
Epoch [1087/2600] -> Loss: 1611.7557
Epoch [1088/2600] -> Loss: 1618.5131
Epoch [1089/2600] -> Loss: 1620.8059
Epoch [1090/2600] -> Loss: 1608.7994
Epoch [1091/2600] -> Loss: 1611.9427
Epoch [1092/2600] -> Loss: 1615.8297
Epoch [1093/2600] -> Loss: 1616.0731
Epoch [1094/2600] -> Loss: 1623.7737
Epoch [1095/2600] -> Loss: 1614.4537
Epoch [1096/2600] -> Loss: 1617.6068
Epoch [1097/2600] -> Loss: 1619.4506
Epoch [1098/2600] -> Loss: 1618.7533
Epoch [1099/2600] -> Loss: 1607.1732
Epoch [1100/2600] -> Loss: 1606.8472
Epoch [1101/2600] -> Loss: 1606.9133
Epoch [1102/2600] -> Loss: 1608.8077
Epoch [1103/2600] -> Loss: 1609.9996
Epoch [1104/2600] -> Loss: 1620.7030
Epoch [1105/2600] -> Loss: 1618.4026
Epoch [1106/2600] -> Loss: 1610.2903
Epoch [1107/2600] -> Loss: 1609.1377
Epoch [1108/2600] -> Loss: 1615.3144
Epoch [1109/2600] -> Loss: 1619.4936
Epoch [1110/2600] -> Loss: 1611.5903
Epoch [1111/2600] -> Loss: 1611.4779
Epoch [1112/2600] -> Loss: 1614.9440
Epoch [1113/2600] -> Loss: 1608.1834
Epoch [1114/2600] -> Loss: 1610.4608
Epoch [1115/2600] -> Loss: 1611.5562
Epoch [1116/2600] -> Loss: 1614.1442
Epoch [1117/2600] -> Loss: 1630.1348
Epoch [1118/2600] -> Loss: 1626.3541
Epoch [1119/2600] -> Loss: 1609.2440
Epoch [1120/2600] -> Loss: 1604.7506
Epoch [1121/2600] -> Loss: 1625.9134
Epoch [1122/2600] -> Loss: 1611.1061
Epoch [1123/2600] -> Loss: 1608.6904
Epoch [1124/2600] -> Loss: 1609.5476
Epoch [1125/2600] -> Loss: 1613.4832
Epoch [1126/2600] -> Loss: 1614.5462
Epoch [1127/2600] -> Loss: 1628.5119
Epoch [1128/2600] -> Loss: 1610.7609
Epoch [1129/2600] -> Loss: 1616.9461
Epoch [1130/2600] -> Loss: 1604.5352
Epoch [1131/2600] -> Loss: 1610.3314
Epoch [1132/2600] -> Loss: 1606.5582
Epoch [1133/2600] -> Loss: 1619.9967
Epoch [1134/2600] -> Loss: 1608.2442
Epoch [1135/2600] -> Loss: 1614.9648
Epoch [1136/2600] -> Loss: 1611.8705
Epoch [1137/2600] -> Loss: 1612.9088
Epoch [1138/2600] -> Loss: 1615.0000
Epoch [1139/2600] -> Loss: 1615.4443
Epoch [1140/2600] -> Loss: 1613.6659
Epoch [1141/2600] -> Loss: 1612.1711
Epoch [1142/2600] -> Loss: 1626.1483
Epoch [1143/2600] -> Loss: 1618.4057
Epoch [1144/2600] -> Loss: 1622.0706
Epoch [1145/2600] -> Loss: 1617.2971
Epoch [1146/2600] -> Loss: 1611.1191
Epoch [1147/2600] -> Loss: 1607.0737
Epoch [1148/2600] -> Loss: 1620.6264
Epoch [1149/2600] -> Loss: 1617.2332
Epoch [1150/2600] -> Loss: 1620.3544
Epoch [1151/2600] -> Loss: 1617.9144
Epoch [1152/2600] -> Loss: 1616.5399
Epoch [1153/2600] -> Loss: 1615.9051
Epoch [1154/2600] -> Loss: 1608.7479
Epoch [1155/2600] -> Loss: 1612.0237
Epoch [1156/2600] -> Loss: 1615.6953
Epoch [1157/2600] -> Loss: 1611.7674
Epoch [1158/2600] -> Loss: 1616.8418
Epoch [1159/2600] -> Loss: 1620.5903
Epoch [1160/2600] -> Loss: 1609.4107
Epoch [1161/2600] -> Loss: 1613.2209
Epoch [1162/2600] -> Loss: 1611.7038
Epoch [1163/2600] -> Loss: 1614.9401
Epoch [1164/2600] -> Loss: 1620.0916
Epoch [1165/2600] -> Loss: 1621.6488
Epoch [1166/2600] -> Loss: 1610.6947
Epoch [1167/2600] -> Loss: 1613.2991
Epoch [1168/2600] -> Loss: 1617.6784
Epoch [1169/2600] -> Loss: 1613.4492
Epoch [1170/2600] -> Loss: 1614.5480
Epoch [1171/2600] -> Loss: 1614.1748
Epoch [1172/2600] -> Loss: 1611.6810
Epoch [1173/2600] -> Loss: 1617.9230
Epoch [1174/2600] -> Loss: 1613.1934
Epoch [1175/2600] -> Loss: 1608.5861
Epoch [1176/2600] -> Loss: 1608.8935
Epoch [1177/2600] -> Loss: 1609.0704
Epoch [1178/2600] -> Loss: 1609.4912
Epoch [1179/2600] -> Loss: 1621.4495
Epoch [1180/2600] -> Loss: 1612.3069
Epoch [1181/2600] -> Loss: 1614.5105
Epoch [1182/2600] -> Loss: 1618.6494
Epoch [1183/2600] -> Loss: 1616.5800
Epoch [1184/2600] -> Loss: 1610.4498
Epoch [1185/2600] -> Loss: 1612.3807
Epoch [1186/2600] -> Loss: 1613.6072
Epoch [1187/2600] -> Loss: 1612.9355
Epoch [1188/2600] -> Loss: 1609.8674
Epoch [1189/2600] -> Loss: 1618.6313
Epoch [1190/2600] -> Loss: 1610.5655
Epoch [1191/2600] -> Loss: 1608.1479
Epoch [1192/2600] -> Loss: 1621.0198
Epoch [1193/2600] -> Loss: 1605.5831
Epoch [1194/2600] -> Loss: 1628.5759
Epoch [1195/2600] -> Loss: 1610.6348
Epoch [1196/2600] -> Loss: 1616.7962
Epoch [1197/2600] -> Loss: 1612.6929
Epoch [1198/2600] -> Loss: 1606.3589
Epoch [1199/2600] -> Loss: 1601.7187
--------------------------------------------------
Model checkpoint saved as FFNN_1200.pth
--------------------------------------------------
Epoch [1200/2600] -> Loss: 1616.1669
Epoch [1201/2600] -> Loss: 1623.9997
Epoch [1202/2600] -> Loss: 1621.1147
Epoch [1203/2600] -> Loss: 1609.2904
Epoch [1204/2600] -> Loss: 1614.5549
Epoch [1205/2600] -> Loss: 1611.5178
Epoch [1206/2600] -> Loss: 1615.3727
Epoch [1207/2600] -> Loss: 1617.0190
Epoch [1208/2600] -> Loss: 1611.1645
Epoch [1209/2600] -> Loss: 1608.1333
Epoch [1210/2600] -> Loss: 1615.0691
Epoch [1211/2600] -> Loss: 1611.4868
Epoch [1212/2600] -> Loss: 1610.2224
Epoch [1213/2600] -> Loss: 1612.5896
Epoch [1214/2600] -> Loss: 1610.5576
Epoch [1215/2600] -> Loss: 1606.6459
Epoch [1216/2600] -> Loss: 1615.2840
Epoch [1217/2600] -> Loss: 1613.2370
Epoch [1218/2600] -> Loss: 1612.4369
Epoch [1219/2600] -> Loss: 1616.7003
Epoch [1220/2600] -> Loss: 1610.5647
Epoch [1221/2600] -> Loss: 1613.7561
Epoch [1222/2600] -> Loss: 1606.4664
Epoch [1223/2600] -> Loss: 1612.0152
Epoch [1224/2600] -> Loss: 1621.0648
Epoch [1225/2600] -> Loss: 1607.4883
Epoch [1226/2600] -> Loss: 1617.2084
Epoch [1227/2600] -> Loss: 1617.8386
Epoch [1228/2600] -> Loss: 1612.2239
Epoch [1229/2600] -> Loss: 1615.4166
Epoch [1230/2600] -> Loss: 1602.1475
Epoch [1231/2600] -> Loss: 1615.6474
Epoch [1232/2600] -> Loss: 1613.3971
Epoch [1233/2600] -> Loss: 1612.6426
Epoch [1234/2600] -> Loss: 1608.7860
Epoch [1235/2600] -> Loss: 1604.1173
Epoch [1236/2600] -> Loss: 1609.1827
Epoch [1237/2600] -> Loss: 1603.8811
Epoch [1238/2600] -> Loss: 1609.8593
Epoch [1239/2600] -> Loss: 1612.6305
Epoch [1240/2600] -> Loss: 1618.7814
Epoch [1241/2600] -> Loss: 1609.4915
Epoch [1242/2600] -> Loss: 1604.2625
Epoch [1243/2600] -> Loss: 1613.6434
Epoch [1244/2600] -> Loss: 1608.7339
Epoch [1245/2600] -> Loss: 1614.2287
Epoch [1246/2600] -> Loss: 1605.4937
Epoch [1247/2600] -> Loss: 1614.4558
Epoch [1248/2600] -> Loss: 1604.5046
Epoch [1249/2600] -> Loss: 1611.2892
Epoch [1250/2600] -> Loss: 1612.6178
Epoch [1251/2600] -> Loss: 1607.8013
Epoch [1252/2600] -> Loss: 1615.0530
Epoch [1253/2600] -> Loss: 1616.8378
Epoch [1254/2600] -> Loss: 1611.8526
Epoch [1255/2600] -> Loss: 1613.9953
Epoch [1256/2600] -> Loss: 1614.3603
Epoch [1257/2600] -> Loss: 1617.1371
Epoch [1258/2600] -> Loss: 1617.1451
Epoch [1259/2600] -> Loss: 1611.4511
Epoch [1260/2600] -> Loss: 1618.1637
Epoch [1261/2600] -> Loss: 1607.1013
Epoch [1262/2600] -> Loss: 1611.0349
Epoch [1263/2600] -> Loss: 1614.6943
Epoch [1264/2600] -> Loss: 1613.3876
Epoch [1265/2600] -> Loss: 1609.4791
Epoch [1266/2600] -> Loss: 1618.9601
Epoch [1267/2600] -> Loss: 1614.6545
Epoch [1268/2600] -> Loss: 1612.8306
Epoch [1269/2600] -> Loss: 1608.0229
Epoch [1270/2600] -> Loss: 1612.2379
Epoch [1271/2600] -> Loss: 1607.3172
Epoch [1272/2600] -> Loss: 1617.2764
Epoch [1273/2600] -> Loss: 1611.8646
Epoch [1274/2600] -> Loss: 1623.8986
Epoch [1275/2600] -> Loss: 1615.5465
Epoch [1276/2600] -> Loss: 1611.2390
Epoch [1277/2600] -> Loss: 1611.2818
Epoch [1278/2600] -> Loss: 1616.5056
Epoch [1279/2600] -> Loss: 1616.7823
Epoch [1280/2600] -> Loss: 1618.1657
Epoch [1281/2600] -> Loss: 1612.2823
Epoch [1282/2600] -> Loss: 1612.4232
Epoch [1283/2600] -> Loss: 1612.2690
Epoch [1284/2600] -> Loss: 1614.7032
Epoch [1285/2600] -> Loss: 1606.5185
Epoch [1286/2600] -> Loss: 1615.4630
Epoch [1287/2600] -> Loss: 1614.6733
Epoch [1288/2600] -> Loss: 1614.0661
Epoch [1289/2600] -> Loss: 1608.4866
Epoch [1290/2600] -> Loss: 1613.3732
Epoch [1291/2600] -> Loss: 1619.1249
Epoch [1292/2600] -> Loss: 1619.7620
Epoch [1293/2600] -> Loss: 1619.9285
Epoch [1294/2600] -> Loss: 1616.4610
Epoch [1295/2600] -> Loss: 1610.2411
Epoch [1296/2600] -> Loss: 1610.5349
Epoch [1297/2600] -> Loss: 1624.2721
Epoch [1298/2600] -> Loss: 1617.9302
Epoch [1299/2600] -> Loss: 1613.8140
Epoch [1300/2600] -> Loss: 1620.9585
Epoch [1301/2600] -> Loss: 1610.7054
Epoch [1302/2600] -> Loss: 1614.8523
Epoch [1303/2600] -> Loss: 1614.6203
Epoch [1304/2600] -> Loss: 1612.2695
Epoch [1305/2600] -> Loss: 1611.2048
Epoch [1306/2600] -> Loss: 1612.8140
Epoch [1307/2600] -> Loss: 1609.5069
Epoch [1308/2600] -> Loss: 1619.5744
Epoch [1309/2600] -> Loss: 1610.3851
Epoch [1310/2600] -> Loss: 1605.1810
Epoch [1311/2600] -> Loss: 1612.0423
Epoch [1312/2600] -> Loss: 1617.1700
Epoch [1313/2600] -> Loss: 1613.1312
Epoch [1314/2600] -> Loss: 1619.2803
Epoch [1315/2600] -> Loss: 1619.7229
Epoch [1316/2600] -> Loss: 1621.9510
Epoch [1317/2600] -> Loss: 1615.6895
Epoch [1318/2600] -> Loss: 1612.7295
Epoch [1319/2600] -> Loss: 1609.6481
Epoch [1320/2600] -> Loss: 1613.5909
Epoch [1321/2600] -> Loss: 1618.9653
Epoch [1322/2600] -> Loss: 1613.5385
Epoch [1323/2600] -> Loss: 1612.1248
Epoch [1324/2600] -> Loss: 1617.7985
Epoch [1325/2600] -> Loss: 1617.0022
Epoch [1326/2600] -> Loss: 1615.1520
Epoch [1327/2600] -> Loss: 1616.0956
Epoch [1328/2600] -> Loss: 1619.3204
Epoch [1329/2600] -> Loss: 1618.3643
Epoch [1330/2600] -> Loss: 1609.5494
Epoch [1331/2600] -> Loss: 1602.8082
Epoch [1332/2600] -> Loss: 1611.2094
Epoch [1333/2600] -> Loss: 1615.0965
Epoch [1334/2600] -> Loss: 1616.1443
Epoch [1335/2600] -> Loss: 1609.5514
Epoch [1336/2600] -> Loss: 1613.6440
Epoch [1337/2600] -> Loss: 1625.3400
Epoch [1338/2600] -> Loss: 1607.8621
Epoch [1339/2600] -> Loss: 1618.6422
Epoch [1340/2600] -> Loss: 1611.9689
Epoch [1341/2600] -> Loss: 1609.6407
Epoch [1342/2600] -> Loss: 1613.8628
Epoch [1343/2600] -> Loss: 1604.4218
Epoch [1344/2600] -> Loss: 1620.8983
Epoch [1345/2600] -> Loss: 1608.3987
Epoch [1346/2600] -> Loss: 1609.4164
Epoch [1347/2600] -> Loss: 1610.2863
Epoch [1348/2600] -> Loss: 1619.0069
Epoch [1349/2600] -> Loss: 1611.1191
Epoch [1350/2600] -> Loss: 1613.0856
Epoch [1351/2600] -> Loss: 1606.3572
Epoch [1352/2600] -> Loss: 1608.0454
Epoch [1353/2600] -> Loss: 1621.2098
Epoch [1354/2600] -> Loss: 1615.9989
Epoch [1355/2600] -> Loss: 1611.6223
Epoch [1356/2600] -> Loss: 1613.7721
Epoch [1357/2600] -> Loss: 1616.9236
Epoch [1358/2600] -> Loss: 1617.7352
Epoch [1359/2600] -> Loss: 1615.1735
Epoch [1360/2600] -> Loss: 1607.6504
Epoch [1361/2600] -> Loss: 1605.0774
Epoch [1362/2600] -> Loss: 1618.1914
Epoch [1363/2600] -> Loss: 1608.4323
Epoch [1364/2600] -> Loss: 1621.6306
Epoch [1365/2600] -> Loss: 1612.8847
Epoch [1366/2600] -> Loss: 1609.6542
Epoch [1367/2600] -> Loss: 1613.8732
Epoch [1368/2600] -> Loss: 1616.1694
Epoch [1369/2600] -> Loss: 1612.7557
Epoch [1370/2600] -> Loss: 1617.2449
Epoch [1371/2600] -> Loss: 1620.8013
Epoch [1372/2600] -> Loss: 1606.2483
Epoch [1373/2600] -> Loss: 1606.8898
Epoch [1374/2600] -> Loss: 1620.3088
Epoch [1375/2600] -> Loss: 1614.9301
Epoch [1376/2600] -> Loss: 1614.7611
Epoch [1377/2600] -> Loss: 1618.6542
Epoch [1378/2600] -> Loss: 1611.2727
Epoch [1379/2600] -> Loss: 1612.4826
Epoch [1380/2600] -> Loss: 1625.5108
Epoch [1381/2600] -> Loss: 1612.3527
Epoch [1382/2600] -> Loss: 1611.7461
Epoch [1383/2600] -> Loss: 1613.6542
Epoch [1384/2600] -> Loss: 1629.0701
Epoch [1385/2600] -> Loss: 1606.3580
Epoch [1386/2600] -> Loss: 1608.3544
Epoch [1387/2600] -> Loss: 1609.4401
Epoch [1388/2600] -> Loss: 1616.8031
Epoch [1389/2600] -> Loss: 1613.9832
Epoch [1390/2600] -> Loss: 1609.1198
Epoch [1391/2600] -> Loss: 1610.1583
Epoch [1392/2600] -> Loss: 1608.9839
Epoch [1393/2600] -> Loss: 1611.2511
Epoch [1394/2600] -> Loss: 1611.5682
Epoch [1395/2600] -> Loss: 1612.2517
Epoch [1396/2600] -> Loss: 1615.4296
Epoch [1397/2600] -> Loss: 1616.8639
Epoch [1398/2600] -> Loss: 1615.8830
Epoch [1399/2600] -> Loss: 1622.0437
--------------------------------------------------
Model checkpoint saved as FFNN_1400.pth
--------------------------------------------------
Epoch [1400/2600] -> Loss: 1627.1266
Epoch [1401/2600] -> Loss: 1606.3489
Epoch [1402/2600] -> Loss: 1615.0941
Epoch [1403/2600] -> Loss: 1617.8765
Epoch [1404/2600] -> Loss: 1614.5421
Epoch [1405/2600] -> Loss: 1616.3085
Epoch [1406/2600] -> Loss: 1612.7340
Epoch [1407/2600] -> Loss: 1609.4283
Epoch [1408/2600] -> Loss: 1606.8684
Epoch [1409/2600] -> Loss: 1606.5551
Epoch [1410/2600] -> Loss: 1607.1121
Epoch [1411/2600] -> Loss: 1614.2290
Epoch [1412/2600] -> Loss: 1612.8181
Epoch [1413/2600] -> Loss: 1611.3274
Epoch [1414/2600] -> Loss: 1614.0136
Epoch [1415/2600] -> Loss: 1618.5309
Epoch [1416/2600] -> Loss: 1609.1717
Epoch [1417/2600] -> Loss: 1617.2710
Epoch [1418/2600] -> Loss: 1609.8712
Epoch [1419/2600] -> Loss: 1608.9215
Epoch [1420/2600] -> Loss: 1610.6139
Epoch [1421/2600] -> Loss: 1616.9600
Epoch [1422/2600] -> Loss: 1613.3201
Epoch [1423/2600] -> Loss: 1609.1044
Epoch [1424/2600] -> Loss: 1627.8333
Epoch [1425/2600] -> Loss: 1613.2430
Epoch [1426/2600] -> Loss: 1609.7548
Epoch [1427/2600] -> Loss: 1614.6423
Epoch [1428/2600] -> Loss: 1618.1187
Epoch [1429/2600] -> Loss: 1615.1077
Epoch [1430/2600] -> Loss: 1607.8244
Epoch [1431/2600] -> Loss: 1616.8386
Epoch [1432/2600] -> Loss: 1606.5632
Epoch [1433/2600] -> Loss: 1613.1791
Epoch [1434/2600] -> Loss: 1612.7562
Epoch [1435/2600] -> Loss: 1613.6330
Epoch [1436/2600] -> Loss: 1621.0806
Epoch [1437/2600] -> Loss: 1622.6100
Epoch [1438/2600] -> Loss: 1617.6669
Epoch [1439/2600] -> Loss: 1603.6642
Epoch [1440/2600] -> Loss: 1601.6606
Epoch [1441/2600] -> Loss: 1609.0500
Epoch [1442/2600] -> Loss: 1607.1978
Epoch [1443/2600] -> Loss: 1620.0929
Epoch [1444/2600] -> Loss: 1612.9854
Epoch [1445/2600] -> Loss: 1620.8544
Epoch [1446/2600] -> Loss: 1618.3673
Epoch [1447/2600] -> Loss: 1616.5004
Epoch [1448/2600] -> Loss: 1623.5655
Epoch [1449/2600] -> Loss: 1608.4270
Epoch [1450/2600] -> Loss: 1612.5382
Epoch [1451/2600] -> Loss: 1612.1597
Epoch [1452/2600] -> Loss: 1610.2164
Epoch [1453/2600] -> Loss: 1615.6158
Epoch [1454/2600] -> Loss: 1615.6382
Epoch [1455/2600] -> Loss: 1618.8360
Epoch [1456/2600] -> Loss: 1610.3745
Epoch [1457/2600] -> Loss: 1623.4345
Epoch [1458/2600] -> Loss: 1612.9063
Epoch [1459/2600] -> Loss: 1615.2845
Epoch [1460/2600] -> Loss: 1626.6460
Epoch [1461/2600] -> Loss: 1609.3426
Epoch [1462/2600] -> Loss: 1606.0984
Epoch [1463/2600] -> Loss: 1634.1710
Epoch [1464/2600] -> Loss: 1614.4739
Epoch [1465/2600] -> Loss: 1618.1921
Epoch [1466/2600] -> Loss: 1607.8891
Epoch [1467/2600] -> Loss: 1605.5908
Epoch [1468/2600] -> Loss: 1616.3534
Epoch [1469/2600] -> Loss: 1612.5731
Epoch [1470/2600] -> Loss: 1627.0162
Epoch [1471/2600] -> Loss: 1617.0299
Epoch [1472/2600] -> Loss: 1616.0619
Epoch [1473/2600] -> Loss: 1609.5611
Epoch [1474/2600] -> Loss: 1614.8784
Epoch [1475/2600] -> Loss: 1605.8659
Epoch [1476/2600] -> Loss: 1611.4938
Epoch [1477/2600] -> Loss: 1611.2366
Epoch [1478/2600] -> Loss: 1606.2364
Epoch [1479/2600] -> Loss: 1616.0307
Epoch [1480/2600] -> Loss: 1609.5519
Epoch [1481/2600] -> Loss: 1608.6073
Epoch [1482/2600] -> Loss: 1621.9201
Epoch [1483/2600] -> Loss: 1609.9013
Epoch [1484/2600] -> Loss: 1612.5229
Epoch [1485/2600] -> Loss: 1614.6229
Epoch [1486/2600] -> Loss: 1613.9738
Epoch [1487/2600] -> Loss: 1604.7676
Epoch [1488/2600] -> Loss: 1617.0732
Epoch [1489/2600] -> Loss: 1612.1956
Epoch [1490/2600] -> Loss: 1615.0168
Epoch [1491/2600] -> Loss: 1608.4277
Epoch [1492/2600] -> Loss: 1611.0711
Epoch [1493/2600] -> Loss: 1612.5407
Epoch [1494/2600] -> Loss: 1609.9728
Epoch [1495/2600] -> Loss: 1609.2571
Epoch [1496/2600] -> Loss: 1606.3247
Epoch [1497/2600] -> Loss: 1625.3857
Epoch [1498/2600] -> Loss: 1610.0249
Epoch [1499/2600] -> Loss: 1617.3807
Epoch [1500/2600] -> Loss: 1620.5649
Epoch [1501/2600] -> Loss: 1611.7697
Epoch [1502/2600] -> Loss: 1612.5473
Epoch [1503/2600] -> Loss: 1620.0429
Epoch [1504/2600] -> Loss: 1609.6156
Epoch [1505/2600] -> Loss: 1614.2085
Epoch [1506/2600] -> Loss: 1609.3838
Epoch [1507/2600] -> Loss: 1607.5360
Epoch [1508/2600] -> Loss: 1620.0659
Epoch [1509/2600] -> Loss: 1612.0417
Epoch [1510/2600] -> Loss: 1607.5316
Epoch [1511/2600] -> Loss: 1612.1535
Epoch [1512/2600] -> Loss: 1611.7142
Epoch [1513/2600] -> Loss: 1607.2073
Epoch [1514/2600] -> Loss: 1613.8270
Epoch [1515/2600] -> Loss: 1621.5504
Epoch [1516/2600] -> Loss: 1616.7335
Epoch [1517/2600] -> Loss: 1606.5803
Epoch [1518/2600] -> Loss: 1614.8968
Epoch [1519/2600] -> Loss: 1620.2824
Epoch [1520/2600] -> Loss: 1613.5891
Epoch [1521/2600] -> Loss: 1611.7820
Epoch [1522/2600] -> Loss: 1611.1039
Epoch [1523/2600] -> Loss: 1619.4943
Epoch [1524/2600] -> Loss: 1612.8779
Epoch [1525/2600] -> Loss: 1621.0765
Epoch [1526/2600] -> Loss: 1610.8979
Epoch [1527/2600] -> Loss: 1613.2565
Epoch [1528/2600] -> Loss: 1610.9315
Epoch [1529/2600] -> Loss: 1612.7028
Epoch [1530/2600] -> Loss: 1616.8892
Epoch [1531/2600] -> Loss: 1622.7575
Epoch [1532/2600] -> Loss: 1608.0167
Epoch [1533/2600] -> Loss: 1621.2855
Epoch [1534/2600] -> Loss: 1613.4427
Epoch [1535/2600] -> Loss: 1620.5208
Epoch [1536/2600] -> Loss: 1615.5997
Epoch [1537/2600] -> Loss: 1605.2351
Epoch [1538/2600] -> Loss: 1611.7353
Epoch [1539/2600] -> Loss: 1615.1430
Epoch [1540/2600] -> Loss: 1607.7525
Epoch [1541/2600] -> Loss: 1609.8272
Epoch [1542/2600] -> Loss: 1617.5113
Epoch [1543/2600] -> Loss: 1608.9466
Epoch [1544/2600] -> Loss: 1611.4622
Epoch [1545/2600] -> Loss: 1610.6815
Epoch [1546/2600] -> Loss: 1611.8625
Epoch [1547/2600] -> Loss: 1622.2165
Epoch [1548/2600] -> Loss: 1613.3414
Epoch [1549/2600] -> Loss: 1615.2812
Epoch [1550/2600] -> Loss: 1614.0965
Epoch [1551/2600] -> Loss: 1604.9376
Epoch [1552/2600] -> Loss: 1612.5920
Epoch [1553/2600] -> Loss: 1616.1179
Epoch [1554/2600] -> Loss: 1618.4233
Epoch [1555/2600] -> Loss: 1606.6129
Epoch [1556/2600] -> Loss: 1612.2729
Epoch [1557/2600] -> Loss: 1606.3083
Epoch [1558/2600] -> Loss: 1611.8074
Epoch [1559/2600] -> Loss: 1610.2266
Epoch [1560/2600] -> Loss: 1606.7345
Epoch [1561/2600] -> Loss: 1611.1692
Epoch [1562/2600] -> Loss: 1611.0016
Epoch [1563/2600] -> Loss: 1611.0187
Epoch [1564/2600] -> Loss: 1610.7860
Epoch [1565/2600] -> Loss: 1612.8475
Epoch [1566/2600] -> Loss: 1604.9342
Epoch [1567/2600] -> Loss: 1614.9401
Epoch [1568/2600] -> Loss: 1607.0339
Epoch [1569/2600] -> Loss: 1609.4994
Epoch [1570/2600] -> Loss: 1615.5638
Epoch [1571/2600] -> Loss: 1614.1465
Epoch [1572/2600] -> Loss: 1619.1899
Epoch [1573/2600] -> Loss: 1605.3004
Epoch [1574/2600] -> Loss: 1616.1198
Epoch [1575/2600] -> Loss: 1616.2467
Epoch [1576/2600] -> Loss: 1631.7290
Epoch [1577/2600] -> Loss: 1618.5207
Epoch [1578/2600] -> Loss: 1612.1868
Epoch [1579/2600] -> Loss: 1613.3235
Epoch [1580/2600] -> Loss: 1612.1264
Epoch [1581/2600] -> Loss: 1609.6295
Epoch [1582/2600] -> Loss: 1611.2472
Epoch [1583/2600] -> Loss: 1611.6543
Epoch [1584/2600] -> Loss: 1615.4712
Epoch [1585/2600] -> Loss: 1618.4172
Epoch [1586/2600] -> Loss: 1615.3816
Epoch [1587/2600] -> Loss: 1608.1254
Epoch [1588/2600] -> Loss: 1622.3654
Epoch [1589/2600] -> Loss: 1608.7236
Epoch [1590/2600] -> Loss: 1615.4867
Epoch [1591/2600] -> Loss: 1613.1669
Epoch [1592/2600] -> Loss: 1613.2679
Epoch [1593/2600] -> Loss: 1614.5334
Epoch [1594/2600] -> Loss: 1604.7931
Epoch [1595/2600] -> Loss: 1605.3279
Epoch [1596/2600] -> Loss: 1609.3724
Epoch [1597/2600] -> Loss: 1607.3749
Epoch [1598/2600] -> Loss: 1618.1297
Epoch [1599/2600] -> Loss: 1604.9789
--------------------------------------------------
Model checkpoint saved as FFNN_1600.pth
--------------------------------------------------
Epoch [1600/2600] -> Loss: 1615.1594
Epoch [1601/2600] -> Loss: 1608.3989
Epoch [1602/2600] -> Loss: 1606.9750
Epoch [1603/2600] -> Loss: 1605.6848
Epoch [1604/2600] -> Loss: 1613.0195
Epoch [1605/2600] -> Loss: 1613.0012
Epoch [1606/2600] -> Loss: 1614.7546
Epoch [1607/2600] -> Loss: 1607.1629
Epoch [1608/2600] -> Loss: 1616.4920
Epoch [1609/2600] -> Loss: 1617.3953
Epoch [1610/2600] -> Loss: 1626.5096
Epoch [1611/2600] -> Loss: 1617.6114
Epoch [1612/2600] -> Loss: 1616.9021
Epoch [1613/2600] -> Loss: 1622.7586
Epoch [1614/2600] -> Loss: 1613.1494
Epoch [1615/2600] -> Loss: 1621.2343
Epoch [1616/2600] -> Loss: 1613.3720
Epoch [1617/2600] -> Loss: 1620.7726
Epoch [1618/2600] -> Loss: 1617.6849
Epoch [1619/2600] -> Loss: 1609.9802
Epoch [1620/2600] -> Loss: 1605.2971
Epoch [1621/2600] -> Loss: 1608.1384
Epoch [1622/2600] -> Loss: 1612.4283
Epoch [1623/2600] -> Loss: 1616.2336
Epoch [1624/2600] -> Loss: 1608.2433
Epoch [1625/2600] -> Loss: 1611.9081
Epoch [1626/2600] -> Loss: 1612.5184
Epoch [1627/2600] -> Loss: 1616.4440
Epoch [1628/2600] -> Loss: 1611.5417
Epoch [1629/2600] -> Loss: 1608.7522
Epoch [1630/2600] -> Loss: 1609.6554
Epoch [1631/2600] -> Loss: 1618.9895
Epoch [1632/2600] -> Loss: 1608.3226
Epoch [1633/2600] -> Loss: 1609.7766
Epoch [1634/2600] -> Loss: 1624.4592
Epoch [1635/2600] -> Loss: 1610.4310
Epoch [1636/2600] -> Loss: 1609.5623
Epoch [1637/2600] -> Loss: 1608.4753
Epoch [1638/2600] -> Loss: 1611.0529
Epoch [1639/2600] -> Loss: 1622.8476
Epoch [1640/2600] -> Loss: 1608.9329
Epoch [1641/2600] -> Loss: 1615.3179
Epoch [1642/2600] -> Loss: 1616.1597
Epoch [1643/2600] -> Loss: 1613.3221
Epoch [1644/2600] -> Loss: 1610.6653
Epoch [1645/2600] -> Loss: 1608.8931
Epoch [1646/2600] -> Loss: 1609.8618
Epoch [1647/2600] -> Loss: 1612.0696
Epoch [1648/2600] -> Loss: 1617.8515
Epoch [1649/2600] -> Loss: 1610.2689
Epoch [1650/2600] -> Loss: 1613.6581
Epoch [1651/2600] -> Loss: 1602.7198
Epoch [1652/2600] -> Loss: 1617.1521
Epoch [1653/2600] -> Loss: 1609.5753
Epoch [1654/2600] -> Loss: 1610.3650
Epoch [1655/2600] -> Loss: 1610.0358
Epoch [1656/2600] -> Loss: 1617.6506
Epoch [1657/2600] -> Loss: 1614.3347
Epoch [1658/2600] -> Loss: 1611.6035
Epoch [1659/2600] -> Loss: 1613.8435
Epoch [1660/2600] -> Loss: 1608.8307
Epoch [1661/2600] -> Loss: 1616.4557
Epoch [1662/2600] -> Loss: 1609.9677
Epoch [1663/2600] -> Loss: 1615.3867
Epoch [1664/2600] -> Loss: 1628.6342
Epoch [1665/2600] -> Loss: 1608.3314
Epoch [1666/2600] -> Loss: 1614.9685
Epoch [1667/2600] -> Loss: 1612.2987
Epoch [1668/2600] -> Loss: 1616.9209
Epoch [1669/2600] -> Loss: 1619.9266
Epoch [1670/2600] -> Loss: 1610.2703
Epoch [1671/2600] -> Loss: 1620.3229
Epoch [1672/2600] -> Loss: 1626.5036
Epoch [1673/2600] -> Loss: 1614.0297
Epoch [1674/2600] -> Loss: 1617.1581
Epoch [1675/2600] -> Loss: 1613.4665
Epoch [1676/2600] -> Loss: 1612.0283
Epoch [1677/2600] -> Loss: 1618.3428
Epoch [1678/2600] -> Loss: 1618.5163
Epoch [1679/2600] -> Loss: 1614.6381
Epoch [1680/2600] -> Loss: 1631.1428
Epoch [1681/2600] -> Loss: 1620.8213
Epoch [1682/2600] -> Loss: 1608.4866
Epoch [1683/2600] -> Loss: 1604.8978
Epoch [1684/2600] -> Loss: 1612.1616
Epoch [1685/2600] -> Loss: 1613.9780
Epoch [1686/2600] -> Loss: 1621.3347
Epoch [1687/2600] -> Loss: 1609.2841
Epoch [1688/2600] -> Loss: 1619.1269
Epoch [1689/2600] -> Loss: 1620.5583
Epoch [1690/2600] -> Loss: 1607.5047
Epoch [1691/2600] -> Loss: 1609.0274
Epoch [1692/2600] -> Loss: 1625.7658
Epoch [1693/2600] -> Loss: 1610.0217
Epoch [1694/2600] -> Loss: 1606.0298
Epoch [1695/2600] -> Loss: 1623.9050
Epoch [1696/2600] -> Loss: 1612.4074
Epoch [1697/2600] -> Loss: 1612.2874
Epoch [1698/2600] -> Loss: 1615.0989
Epoch [1699/2600] -> Loss: 1610.7475
Epoch [1700/2600] -> Loss: 1615.7407
Epoch [1701/2600] -> Loss: 1619.0069
Epoch [1702/2600] -> Loss: 1616.2689
Epoch [1703/2600] -> Loss: 1608.7345
Epoch [1704/2600] -> Loss: 1610.7946
Epoch [1705/2600] -> Loss: 1616.4209
Epoch [1706/2600] -> Loss: 1615.3652
Epoch [1707/2600] -> Loss: 1623.8896
Epoch [1708/2600] -> Loss: 1607.9946
Epoch [1709/2600] -> Loss: 1622.3782
Epoch [1710/2600] -> Loss: 1616.3358
Epoch [1711/2600] -> Loss: 1610.9511
Epoch [1712/2600] -> Loss: 1607.2812
Epoch [1713/2600] -> Loss: 1615.3757
Epoch [1714/2600] -> Loss: 1615.2763
Epoch [1715/2600] -> Loss: 1613.9908
Epoch [1716/2600] -> Loss: 1618.4472
Epoch [1717/2600] -> Loss: 1611.7465
Epoch [1718/2600] -> Loss: 1616.5562
Epoch [1719/2600] -> Loss: 1616.5544
Epoch [1720/2600] -> Loss: 1623.7037
Epoch [1721/2600] -> Loss: 1617.2640
Epoch [1722/2600] -> Loss: 1609.4899
Epoch [1723/2600] -> Loss: 1620.4850
Epoch [1724/2600] -> Loss: 1612.9333
Epoch [1725/2600] -> Loss: 1616.2411
Epoch [1726/2600] -> Loss: 1610.9299
Epoch [1727/2600] -> Loss: 1614.8623
Epoch [1728/2600] -> Loss: 1618.1370
Epoch [1729/2600] -> Loss: 1609.6859
Epoch [1730/2600] -> Loss: 1608.3576
Epoch [1731/2600] -> Loss: 1604.4485
Epoch [1732/2600] -> Loss: 1609.2503
Epoch [1733/2600] -> Loss: 1609.8277
Epoch [1734/2600] -> Loss: 1610.8764
Epoch [1735/2600] -> Loss: 1612.8830
Epoch [1736/2600] -> Loss: 1613.4417
Epoch [1737/2600] -> Loss: 1600.7656
Epoch [1738/2600] -> Loss: 1617.0433
Epoch [1739/2600] -> Loss: 1612.2229
Epoch [1740/2600] -> Loss: 1617.6099
Epoch [1741/2600] -> Loss: 1610.2736
Epoch [1742/2600] -> Loss: 1617.7495
Epoch [1743/2600] -> Loss: 1611.6737
Epoch [1744/2600] -> Loss: 1619.5799
Epoch [1745/2600] -> Loss: 1614.1033
Epoch [1746/2600] -> Loss: 1612.3176
Epoch [1747/2600] -> Loss: 1607.8389
Epoch [1748/2600] -> Loss: 1614.4533
Epoch [1749/2600] -> Loss: 1618.9249
Epoch [1750/2600] -> Loss: 1613.3121
Epoch [1751/2600] -> Loss: 1608.9467
Epoch [1752/2600] -> Loss: 1612.6122
Epoch [1753/2600] -> Loss: 1612.2763
Epoch [1754/2600] -> Loss: 1614.3198
Epoch [1755/2600] -> Loss: 1612.1999
Epoch [1756/2600] -> Loss: 1603.8215
Epoch [1757/2600] -> Loss: 1613.9874
Epoch [1758/2600] -> Loss: 1610.3162
Epoch [1759/2600] -> Loss: 1608.5796
Epoch [1760/2600] -> Loss: 1606.5386
Epoch [1761/2600] -> Loss: 1610.4101
Epoch [1762/2600] -> Loss: 1618.5088
Epoch [1763/2600] -> Loss: 1621.1925
Epoch [1764/2600] -> Loss: 1614.3655
Epoch [1765/2600] -> Loss: 1613.0300
Epoch [1766/2600] -> Loss: 1615.0071
Epoch [1767/2600] -> Loss: 1612.2480
Epoch [1768/2600] -> Loss: 1614.1332
Epoch [1769/2600] -> Loss: 1613.8997
Epoch [1770/2600] -> Loss: 1612.7874
Epoch [1771/2600] -> Loss: 1621.1172
Epoch [1772/2600] -> Loss: 1617.7122
Epoch [1773/2600] -> Loss: 1610.1598
Epoch [1774/2600] -> Loss: 1619.8101
Epoch [1775/2600] -> Loss: 1610.1145
Epoch [1776/2600] -> Loss: 1612.7634
Epoch [1777/2600] -> Loss: 1619.3548
Epoch [1778/2600] -> Loss: 1617.8752
Epoch [1779/2600] -> Loss: 1607.6418
Epoch [1780/2600] -> Loss: 1619.3203
Epoch [1781/2600] -> Loss: 1616.6802
Epoch [1782/2600] -> Loss: 1610.4796
Epoch [1783/2600] -> Loss: 1615.6541
Epoch [1784/2600] -> Loss: 1610.8204
Epoch [1785/2600] -> Loss: 1613.5283
Epoch [1786/2600] -> Loss: 1620.1071
Epoch [1787/2600] -> Loss: 1613.0310
Epoch [1788/2600] -> Loss: 1617.6675
Epoch [1789/2600] -> Loss: 1616.2376
Epoch [1790/2600] -> Loss: 1613.6075
Epoch [1791/2600] -> Loss: 1608.9288
Epoch [1792/2600] -> Loss: 1616.8895
Epoch [1793/2600] -> Loss: 1618.5767
Epoch [1794/2600] -> Loss: 1606.7016
Epoch [1795/2600] -> Loss: 1611.5909
Epoch [1796/2600] -> Loss: 1607.4116
Epoch [1797/2600] -> Loss: 1617.4299
Epoch [1798/2600] -> Loss: 1621.8746
Epoch [1799/2600] -> Loss: 1606.0498
--------------------------------------------------
Model checkpoint saved as FFNN_1800.pth
--------------------------------------------------
Epoch [1800/2600] -> Loss: 1601.6892
Epoch [1801/2600] -> Loss: 1609.5867
Epoch [1802/2600] -> Loss: 1617.0073
Epoch [1803/2600] -> Loss: 1609.5771
Epoch [1804/2600] -> Loss: 1607.7609
Epoch [1805/2600] -> Loss: 1615.6188
Epoch [1806/2600] -> Loss: 1616.5445
Epoch [1807/2600] -> Loss: 1603.0962
Epoch [1808/2600] -> Loss: 1625.5446
Epoch [1809/2600] -> Loss: 1603.6994
Epoch [1810/2600] -> Loss: 1611.9052
Epoch [1811/2600] -> Loss: 1613.9361
Epoch [1812/2600] -> Loss: 1609.4683
Epoch [1813/2600] -> Loss: 1627.4447
Epoch [1814/2600] -> Loss: 1610.1532
Epoch [1815/2600] -> Loss: 1621.2089
Epoch [1816/2600] -> Loss: 1613.1683
Epoch [1817/2600] -> Loss: 1613.0620
Epoch [1818/2600] -> Loss: 1620.4173
Epoch [1819/2600] -> Loss: 1609.3502
Epoch [1820/2600] -> Loss: 1615.5023
Epoch [1821/2600] -> Loss: 1610.2456
Epoch [1822/2600] -> Loss: 1614.0032
Epoch [1823/2600] -> Loss: 1610.0067
Epoch [1824/2600] -> Loss: 1616.0579
Epoch [1825/2600] -> Loss: 1620.7400
Epoch [1826/2600] -> Loss: 1622.2047
Epoch [1827/2600] -> Loss: 1608.3291
Epoch [1828/2600] -> Loss: 1611.4728
Epoch [1829/2600] -> Loss: 1609.9566
Epoch [1830/2600] -> Loss: 1622.1527
Epoch [1831/2600] -> Loss: 1623.9160
Epoch [1832/2600] -> Loss: 1609.6265
Epoch [1833/2600] -> Loss: 1619.3994
Epoch [1834/2600] -> Loss: 1624.2860
Epoch [1835/2600] -> Loss: 1613.3501
Epoch [1836/2600] -> Loss: 1617.7778
Epoch [1837/2600] -> Loss: 1610.9729
Epoch [1838/2600] -> Loss: 1623.7296
Epoch [1839/2600] -> Loss: 1617.8233
Epoch [1840/2600] -> Loss: 1619.8103
Epoch [1841/2600] -> Loss: 1620.3976
Epoch [1842/2600] -> Loss: 1616.7750
Epoch [1843/2600] -> Loss: 1618.5753
Epoch [1844/2600] -> Loss: 1618.1505
Epoch [1845/2600] -> Loss: 1618.3632
Epoch [1846/2600] -> Loss: 1609.4164
Epoch [1847/2600] -> Loss: 1616.1248
Epoch [1848/2600] -> Loss: 1610.5757
Epoch [1849/2600] -> Loss: 1621.4923
Epoch [1850/2600] -> Loss: 1608.0466
Epoch [1851/2600] -> Loss: 1623.0367
Epoch [1852/2600] -> Loss: 1607.6028
Epoch [1853/2600] -> Loss: 1608.8016
Epoch [1854/2600] -> Loss: 1613.3261
Epoch [1855/2600] -> Loss: 1614.0518
Epoch [1856/2600] -> Loss: 1609.3698
Epoch [1857/2600] -> Loss: 1612.8264
Epoch [1858/2600] -> Loss: 1613.1000
Epoch [1859/2600] -> Loss: 1606.7358
Epoch [1860/2600] -> Loss: 1628.8461
Epoch [1861/2600] -> Loss: 1614.1033
Epoch [1862/2600] -> Loss: 1618.7519
Epoch [1863/2600] -> Loss: 1611.9922
Epoch [1864/2600] -> Loss: 1608.8539
Epoch [1865/2600] -> Loss: 1612.0686
Epoch [1866/2600] -> Loss: 1613.4971
Epoch [1867/2600] -> Loss: 1610.1911
Epoch [1868/2600] -> Loss: 1615.8066
Epoch [1869/2600] -> Loss: 1611.6957
Epoch [1870/2600] -> Loss: 1606.5818
Epoch [1871/2600] -> Loss: 1610.4026
Epoch [1872/2600] -> Loss: 1608.5312
Epoch [1873/2600] -> Loss: 1618.0183
Epoch [1874/2600] -> Loss: 1604.3592
Epoch [1875/2600] -> Loss: 1617.0061
Epoch [1876/2600] -> Loss: 1612.8632
Epoch [1877/2600] -> Loss: 1619.1917
Epoch [1878/2600] -> Loss: 1621.1156
Epoch [1879/2600] -> Loss: 1620.3648
Epoch [1880/2600] -> Loss: 1613.7203
Epoch [1881/2600] -> Loss: 1616.1176
Epoch [1882/2600] -> Loss: 1619.6494
Epoch [1883/2600] -> Loss: 1617.2280
Epoch [1884/2600] -> Loss: 1613.5883
Epoch [1885/2600] -> Loss: 1612.6368
Epoch [1886/2600] -> Loss: 1607.5504
Epoch [1887/2600] -> Loss: 1610.5023
Epoch [1888/2600] -> Loss: 1610.7050
Epoch [1889/2600] -> Loss: 1607.0847
Epoch [1890/2600] -> Loss: 1610.7576
Epoch [1891/2600] -> Loss: 1611.1941
Epoch [1892/2600] -> Loss: 1618.0193
Epoch [1893/2600] -> Loss: 1615.1556
Epoch [1894/2600] -> Loss: 1607.9451
Epoch [1895/2600] -> Loss: 1616.2875
Epoch [1896/2600] -> Loss: 1608.5287
Epoch [1897/2600] -> Loss: 1608.0636
Epoch [1898/2600] -> Loss: 1614.1057
Epoch [1899/2600] -> Loss: 1612.1087
Epoch [1900/2600] -> Loss: 1608.9692
Epoch [1901/2600] -> Loss: 1619.8879
Epoch [1902/2600] -> Loss: 1611.7658
Epoch [1903/2600] -> Loss: 1613.5556
Epoch [1904/2600] -> Loss: 1609.8778
Epoch [1905/2600] -> Loss: 1612.2529
Epoch [1906/2600] -> Loss: 1616.7761
Epoch [1907/2600] -> Loss: 1609.9320
Epoch [1908/2600] -> Loss: 1616.1781
Epoch [1909/2600] -> Loss: 1618.8470
Epoch [1910/2600] -> Loss: 1616.9623
Epoch [1911/2600] -> Loss: 1611.9720
Epoch [1912/2600] -> Loss: 1612.4882
Epoch [1913/2600] -> Loss: 1611.1118
Epoch [1914/2600] -> Loss: 1621.7577
Epoch [1915/2600] -> Loss: 1611.2462
Epoch [1916/2600] -> Loss: 1610.7654
Epoch [1917/2600] -> Loss: 1609.8739
Epoch [1918/2600] -> Loss: 1618.5961
Epoch [1919/2600] -> Loss: 1614.9621
Epoch [1920/2600] -> Loss: 1612.2615
Epoch [1921/2600] -> Loss: 1609.8925
Epoch [1922/2600] -> Loss: 1614.0919
Epoch [1923/2600] -> Loss: 1614.7029
Epoch [1924/2600] -> Loss: 1619.9260
Epoch [1925/2600] -> Loss: 1612.5532
Epoch [1926/2600] -> Loss: 1612.0016
Epoch [1927/2600] -> Loss: 1614.5079
Epoch [1928/2600] -> Loss: 1622.5276
Epoch [1929/2600] -> Loss: 1614.6028
Epoch [1930/2600] -> Loss: 1620.9173
Epoch [1931/2600] -> Loss: 1619.3941
Epoch [1932/2600] -> Loss: 1621.9565
Epoch [1933/2600] -> Loss: 1616.1854
Epoch [1934/2600] -> Loss: 1626.8608
Epoch [1935/2600] -> Loss: 1612.6842
Epoch [1936/2600] -> Loss: 1614.4904
Epoch [1937/2600] -> Loss: 1611.5009
Epoch [1938/2600] -> Loss: 1626.6901
Epoch [1939/2600] -> Loss: 1616.5795
Epoch [1940/2600] -> Loss: 1617.8010
Epoch [1941/2600] -> Loss: 1615.2108
Epoch [1942/2600] -> Loss: 1612.0331
Epoch [1943/2600] -> Loss: 1616.1014
Epoch [1944/2600] -> Loss: 1612.4986
Epoch [1945/2600] -> Loss: 1624.1566
Epoch [1946/2600] -> Loss: 1623.8504
Epoch [1947/2600] -> Loss: 1611.6993
Epoch [1948/2600] -> Loss: 1614.6215
Epoch [1949/2600] -> Loss: 1602.3427
Epoch [1950/2600] -> Loss: 1606.9519
Epoch [1951/2600] -> Loss: 1613.3999
Epoch [1952/2600] -> Loss: 1607.9532
Epoch [1953/2600] -> Loss: 1615.4582
Epoch [1954/2600] -> Loss: 1625.2643
Epoch [1955/2600] -> Loss: 1620.0415
Epoch [1956/2600] -> Loss: 1615.8089
Epoch [1957/2600] -> Loss: 1606.1842
Epoch [1958/2600] -> Loss: 1605.0351
Epoch [1959/2600] -> Loss: 1604.5597
Epoch [1960/2600] -> Loss: 1625.5771
Epoch [1961/2600] -> Loss: 1621.6091
Epoch [1962/2600] -> Loss: 1612.2306
Epoch [1963/2600] -> Loss: 1628.9598
Epoch [1964/2600] -> Loss: 1616.8174
Epoch [1965/2600] -> Loss: 1620.9828
Epoch [1966/2600] -> Loss: 1605.9494
Epoch [1967/2600] -> Loss: 1610.5783
Epoch [1968/2600] -> Loss: 1609.6397
Epoch [1969/2600] -> Loss: 1611.2089
Epoch [1970/2600] -> Loss: 1613.3010
Epoch [1971/2600] -> Loss: 1622.8604
Epoch [1972/2600] -> Loss: 1600.2225
Epoch [1973/2600] -> Loss: 1609.7300
Epoch [1974/2600] -> Loss: 1613.4000
Epoch [1975/2600] -> Loss: 1611.1841
Epoch [1976/2600] -> Loss: 1615.9558
Epoch [1977/2600] -> Loss: 1606.2448
Epoch [1978/2600] -> Loss: 1616.2368
Epoch [1979/2600] -> Loss: 1628.4740
Epoch [1980/2600] -> Loss: 1612.8644
Epoch [1981/2600] -> Loss: 1609.9448
Epoch [1982/2600] -> Loss: 1603.0900
Epoch [1983/2600] -> Loss: 1612.9174
Epoch [1984/2600] -> Loss: 1622.9483
Epoch [1985/2600] -> Loss: 1623.8121
Epoch [1986/2600] -> Loss: 1609.5196
Epoch [1987/2600] -> Loss: 1605.4589
Epoch [1988/2600] -> Loss: 1619.2473
Epoch [1989/2600] -> Loss: 1611.6238
Epoch [1990/2600] -> Loss: 1613.8276
Epoch [1991/2600] -> Loss: 1614.4578
Epoch [1992/2600] -> Loss: 1616.7718
Epoch [1993/2600] -> Loss: 1614.9967
Epoch [1994/2600] -> Loss: 1615.5578
Epoch [1995/2600] -> Loss: 1627.2018
Epoch [1996/2600] -> Loss: 1614.9825
Epoch [1997/2600] -> Loss: 1611.0393
Epoch [1998/2600] -> Loss: 1613.7452
Epoch [1999/2600] -> Loss: 1613.6673
--------------------------------------------------
Model checkpoint saved as FFNN_2000.pth
--------------------------------------------------
Epoch [2000/2600] -> Loss: 1620.9660
Epoch [2001/2600] -> Loss: 1605.6587
Epoch [2002/2600] -> Loss: 1611.7246
Epoch [2003/2600] -> Loss: 1610.6412
Epoch [2004/2600] -> Loss: 1626.7246
Epoch [2005/2600] -> Loss: 1616.3237
Epoch [2006/2600] -> Loss: 1611.1015
Epoch [2007/2600] -> Loss: 1617.5175
Epoch [2008/2600] -> Loss: 1608.7575
Epoch [2009/2600] -> Loss: 1616.1168
Epoch [2010/2600] -> Loss: 1609.9846
Epoch [2011/2600] -> Loss: 1602.7097
Epoch [2012/2600] -> Loss: 1613.6894
Epoch [2013/2600] -> Loss: 1616.4832
Epoch [2014/2600] -> Loss: 1621.4558
Epoch [2015/2600] -> Loss: 1612.9580
Epoch [2016/2600] -> Loss: 1619.9661
Epoch [2017/2600] -> Loss: 1611.7742
Epoch [2018/2600] -> Loss: 1618.0192
Epoch [2019/2600] -> Loss: 1609.3081
Epoch [2020/2600] -> Loss: 1610.9931
Epoch [2021/2600] -> Loss: 1613.6228
Epoch [2022/2600] -> Loss: 1609.2714
Epoch [2023/2600] -> Loss: 1608.4971
Epoch [2024/2600] -> Loss: 1610.6969
Epoch [2025/2600] -> Loss: 1612.3244
Epoch [2026/2600] -> Loss: 1609.9344
Epoch [2027/2600] -> Loss: 1624.8663
Epoch [2028/2600] -> Loss: 1607.3577
Epoch [2029/2600] -> Loss: 1612.9599
Epoch [2030/2600] -> Loss: 1617.6592
Epoch [2031/2600] -> Loss: 1612.9379
Epoch [2032/2600] -> Loss: 1612.9664
Epoch [2033/2600] -> Loss: 1615.3467
Epoch [2034/2600] -> Loss: 1611.4176
Epoch [2035/2600] -> Loss: 1611.8589
Epoch [2036/2600] -> Loss: 1612.1046
Epoch [2037/2600] -> Loss: 1609.1523
Epoch [2038/2600] -> Loss: 1614.0410
Epoch [2039/2600] -> Loss: 1606.4957
Epoch [2040/2600] -> Loss: 1607.6645
Epoch [2041/2600] -> Loss: 1614.3674
Epoch [2042/2600] -> Loss: 1618.9443
Epoch [2043/2600] -> Loss: 1615.0278
Epoch [2044/2600] -> Loss: 1619.9117
Epoch [2045/2600] -> Loss: 1614.0116
Epoch [2046/2600] -> Loss: 1615.7771
Epoch [2047/2600] -> Loss: 1610.4497
Epoch [2048/2600] -> Loss: 1607.7924
Epoch [2049/2600] -> Loss: 1633.3592
Epoch [2050/2600] -> Loss: 1611.7460
Epoch [2051/2600] -> Loss: 1607.7117
Epoch [2052/2600] -> Loss: 1618.5359
Epoch [2053/2600] -> Loss: 1609.7056
Epoch [2054/2600] -> Loss: 1625.4100
Epoch [2055/2600] -> Loss: 1610.3802
Epoch [2056/2600] -> Loss: 1616.7466
Epoch [2057/2600] -> Loss: 1612.1826
Epoch [2058/2600] -> Loss: 1623.6927
Epoch [2059/2600] -> Loss: 1618.7443
Epoch [2060/2600] -> Loss: 1624.3819
Epoch [2061/2600] -> Loss: 1610.1090
Epoch [2062/2600] -> Loss: 1606.2123
Epoch [2063/2600] -> Loss: 1615.5016
Epoch [2064/2600] -> Loss: 1608.9387
Epoch [2065/2600] -> Loss: 1622.3166
Epoch [2066/2600] -> Loss: 1610.5716
Epoch [2067/2600] -> Loss: 1615.0075
Epoch [2068/2600] -> Loss: 1610.5066
Epoch [2069/2600] -> Loss: 1614.1096
Epoch [2070/2600] -> Loss: 1616.2490
Epoch [2071/2600] -> Loss: 1613.7152
Epoch [2072/2600] -> Loss: 1612.4560
Epoch [2073/2600] -> Loss: 1619.5758
Epoch [2074/2600] -> Loss: 1627.5958
Epoch [2075/2600] -> Loss: 1610.0829
Epoch [2076/2600] -> Loss: 1614.3707
Epoch [2077/2600] -> Loss: 1610.0799
Epoch [2078/2600] -> Loss: 1617.3656
Epoch [2079/2600] -> Loss: 1611.7264
Epoch [2080/2600] -> Loss: 1625.8344
Epoch [2081/2600] -> Loss: 1606.7206
Epoch [2082/2600] -> Loss: 1611.4965
Epoch [2083/2600] -> Loss: 1609.0469
Epoch [2084/2600] -> Loss: 1610.0343
Epoch [2085/2600] -> Loss: 1616.8361
Epoch [2086/2600] -> Loss: 1611.4028
Epoch [2087/2600] -> Loss: 1616.5948
Epoch [2088/2600] -> Loss: 1624.8030
Epoch [2089/2600] -> Loss: 1614.1771
Epoch [2090/2600] -> Loss: 1616.5021
Epoch [2091/2600] -> Loss: 1615.3893
Epoch [2092/2600] -> Loss: 1613.8793
Epoch [2093/2600] -> Loss: 1608.7332
Epoch [2094/2600] -> Loss: 1616.2824
Epoch [2095/2600] -> Loss: 1610.4484
Epoch [2096/2600] -> Loss: 1607.6967
Epoch [2097/2600] -> Loss: 1610.7110
Epoch [2098/2600] -> Loss: 1613.6597
Epoch [2099/2600] -> Loss: 1609.7833
Epoch [2100/2600] -> Loss: 1614.3869
Epoch [2101/2600] -> Loss: 1613.8535
Epoch [2102/2600] -> Loss: 1614.7379
Epoch [2103/2600] -> Loss: 1619.1411
Epoch [2104/2600] -> Loss: 1617.8728
Epoch [2105/2600] -> Loss: 1616.3451
Epoch [2106/2600] -> Loss: 1613.8015
Epoch [2107/2600] -> Loss: 1617.5058
Epoch [2108/2600] -> Loss: 1622.1491
Epoch [2109/2600] -> Loss: 1612.5706
Epoch [2110/2600] -> Loss: 1612.2864
Epoch [2111/2600] -> Loss: 1628.1194
Epoch [2112/2600] -> Loss: 1620.7034
Epoch [2113/2600] -> Loss: 1612.9361
Epoch [2114/2600] -> Loss: 1602.9467
Epoch [2115/2600] -> Loss: 1614.1212
Epoch [2116/2600] -> Loss: 1611.0971
Epoch [2117/2600] -> Loss: 1607.0547
Epoch [2118/2600] -> Loss: 1615.4065
Epoch [2119/2600] -> Loss: 1612.6376
Epoch [2120/2600] -> Loss: 1618.6580
Epoch [2121/2600] -> Loss: 1620.4031
Epoch [2122/2600] -> Loss: 1611.6073
Epoch [2123/2600] -> Loss: 1611.3113
Epoch [2124/2600] -> Loss: 1606.0918
Epoch [2125/2600] -> Loss: 1621.0889
Epoch [2126/2600] -> Loss: 1618.6854
Epoch [2127/2600] -> Loss: 1611.9747
Epoch [2128/2600] -> Loss: 1609.5155
Epoch [2129/2600] -> Loss: 1611.8921
Epoch [2130/2600] -> Loss: 1610.5338
Epoch [2131/2600] -> Loss: 1622.8344
Epoch [2132/2600] -> Loss: 1621.9583
Epoch [2133/2600] -> Loss: 1611.8445
Epoch [2134/2600] -> Loss: 1618.3819
Epoch [2135/2600] -> Loss: 1619.1267
Epoch [2136/2600] -> Loss: 1614.3154
Epoch [2137/2600] -> Loss: 1614.1146
Epoch [2138/2600] -> Loss: 1612.0785
Epoch [2139/2600] -> Loss: 1616.8205
Epoch [2140/2600] -> Loss: 1607.6489
Epoch [2141/2600] -> Loss: 1614.6731
Epoch [2142/2600] -> Loss: 1617.8813
Epoch [2143/2600] -> Loss: 1622.9590
Epoch [2144/2600] -> Loss: 1611.8403
Epoch [2145/2600] -> Loss: 1613.5277
Epoch [2146/2600] -> Loss: 1615.2849
Epoch [2147/2600] -> Loss: 1607.2442
Epoch [2148/2600] -> Loss: 1612.4440
Epoch [2149/2600] -> Loss: 1610.5615
Epoch [2150/2600] -> Loss: 1615.4755
Epoch [2151/2600] -> Loss: 1610.4911
Epoch [2152/2600] -> Loss: 1618.7591
Epoch [2153/2600] -> Loss: 1613.1455
Epoch [2154/2600] -> Loss: 1610.8584
Epoch [2155/2600] -> Loss: 1621.7012
Epoch [2156/2600] -> Loss: 1603.4834
Epoch [2157/2600] -> Loss: 1622.0094
Epoch [2158/2600] -> Loss: 1614.2226
Epoch [2159/2600] -> Loss: 1606.3414
Epoch [2160/2600] -> Loss: 1613.7899
Epoch [2161/2600] -> Loss: 1619.9517
Epoch [2162/2600] -> Loss: 1613.7349
Epoch [2163/2600] -> Loss: 1606.1023
Epoch [2164/2600] -> Loss: 1618.2504
Epoch [2165/2600] -> Loss: 1613.1188
Epoch [2166/2600] -> Loss: 1618.1711
Epoch [2167/2600] -> Loss: 1613.2902
Epoch [2168/2600] -> Loss: 1605.8844
Epoch [2169/2600] -> Loss: 1609.0288
Epoch [2170/2600] -> Loss: 1604.1760
Epoch [2171/2600] -> Loss: 1622.7261
Epoch [2172/2600] -> Loss: 1607.5606
Epoch [2173/2600] -> Loss: 1609.2924
Epoch [2174/2600] -> Loss: 1609.3997
Epoch [2175/2600] -> Loss: 1625.2723
Epoch [2176/2600] -> Loss: 1607.6219
Epoch [2177/2600] -> Loss: 1619.6417
Epoch [2178/2600] -> Loss: 1608.1753
Epoch [2179/2600] -> Loss: 1613.3403
Epoch [2180/2600] -> Loss: 1617.3148
Epoch [2181/2600] -> Loss: 1614.6690
Epoch [2182/2600] -> Loss: 1627.3685
Epoch [2183/2600] -> Loss: 1612.9882
Epoch [2184/2600] -> Loss: 1613.7077
Epoch [2185/2600] -> Loss: 1605.6204
Epoch [2186/2600] -> Loss: 1606.4998
Epoch [2187/2600] -> Loss: 1624.9776
Epoch [2188/2600] -> Loss: 1609.2363
Epoch [2189/2600] -> Loss: 1610.1514
Epoch [2190/2600] -> Loss: 1610.7634
Epoch [2191/2600] -> Loss: 1621.7659
Epoch [2192/2600] -> Loss: 1621.6240
Epoch [2193/2600] -> Loss: 1621.1436
Epoch [2194/2600] -> Loss: 1624.3845
Epoch [2195/2600] -> Loss: 1616.9887
Epoch [2196/2600] -> Loss: 1611.6960
Epoch [2197/2600] -> Loss: 1617.3043
Epoch [2198/2600] -> Loss: 1616.7505
Epoch [2199/2600] -> Loss: 1608.5459
--------------------------------------------------
Model checkpoint saved as FFNN_2200.pth
--------------------------------------------------
Epoch [2200/2600] -> Loss: 1620.3293
Epoch [2201/2600] -> Loss: 1619.1627
Epoch [2202/2600] -> Loss: 1613.4396
Epoch [2203/2600] -> Loss: 1609.6696
Epoch [2204/2600] -> Loss: 1618.1854
Epoch [2205/2600] -> Loss: 1613.5901
Epoch [2206/2600] -> Loss: 1623.9316
Epoch [2207/2600] -> Loss: 1620.8202
Epoch [2208/2600] -> Loss: 1609.1961
Epoch [2209/2600] -> Loss: 1613.7160
Epoch [2210/2600] -> Loss: 1615.4814
Epoch [2211/2600] -> Loss: 1605.8245
Epoch [2212/2600] -> Loss: 1607.5365
Epoch [2213/2600] -> Loss: 1614.1157
Epoch [2214/2600] -> Loss: 1633.1815
Epoch [2215/2600] -> Loss: 1607.4196
Epoch [2216/2600] -> Loss: 1619.0226
Epoch [2217/2600] -> Loss: 1615.6095
Epoch [2218/2600] -> Loss: 1614.2415
Epoch [2219/2600] -> Loss: 1608.8924
Epoch [2220/2600] -> Loss: 1619.9774
Epoch [2221/2600] -> Loss: 1619.6636
Epoch [2222/2600] -> Loss: 1609.6453
Epoch [2223/2600] -> Loss: 1616.5390
Epoch [2224/2600] -> Loss: 1615.5063
Epoch [2225/2600] -> Loss: 1618.4749
Epoch [2226/2600] -> Loss: 1612.2978
Epoch [2227/2600] -> Loss: 1612.2428
Epoch [2228/2600] -> Loss: 1617.5413
Epoch [2229/2600] -> Loss: 1619.2727
Epoch [2230/2600] -> Loss: 1612.8761
Epoch [2231/2600] -> Loss: 1616.3058
Epoch [2232/2600] -> Loss: 1619.8721
Epoch [2233/2600] -> Loss: 1605.5095
Epoch [2234/2600] -> Loss: 1617.1888
Epoch [2235/2600] -> Loss: 1608.1547
Epoch [2236/2600] -> Loss: 1615.4705
Epoch [2237/2600] -> Loss: 1619.1215
Epoch [2238/2600] -> Loss: 1609.6225
Epoch [2239/2600] -> Loss: 1614.2104
Epoch [2240/2600] -> Loss: 1611.9940
Epoch [2241/2600] -> Loss: 1606.1902
Epoch [2242/2600] -> Loss: 1607.2385
Epoch [2243/2600] -> Loss: 1617.0357
Epoch [2244/2600] -> Loss: 1621.8839
Epoch [2245/2600] -> Loss: 1611.1553
Epoch [2246/2600] -> Loss: 1619.2117
Epoch [2247/2600] -> Loss: 1611.4610
Epoch [2248/2600] -> Loss: 1610.2460
Epoch [2249/2600] -> Loss: 1608.7556
Epoch [2250/2600] -> Loss: 1610.2394
Epoch [2251/2600] -> Loss: 1614.0223
Epoch [2252/2600] -> Loss: 1608.2445
Epoch [2253/2600] -> Loss: 1611.4720
Epoch [2254/2600] -> Loss: 1612.0695
Epoch [2255/2600] -> Loss: 1619.9595
Epoch [2256/2600] -> Loss: 1615.1337
Epoch [2257/2600] -> Loss: 1616.9060
Epoch [2258/2600] -> Loss: 1621.1300
Epoch [2259/2600] -> Loss: 1614.2260
Epoch [2260/2600] -> Loss: 1621.8785
Epoch [2261/2600] -> Loss: 1617.8047
Epoch [2262/2600] -> Loss: 1613.5574
Epoch [2263/2600] -> Loss: 1621.6704
Epoch [2264/2600] -> Loss: 1619.6745
Epoch [2265/2600] -> Loss: 1621.1279
Epoch [2266/2600] -> Loss: 1617.3136
Epoch [2267/2600] -> Loss: 1617.1580
Epoch [2268/2600] -> Loss: 1619.2435
Epoch [2269/2600] -> Loss: 1612.5374
Epoch [2270/2600] -> Loss: 1614.9067
Epoch [2271/2600] -> Loss: 1614.6057
Epoch [2272/2600] -> Loss: 1608.9713
Epoch [2273/2600] -> Loss: 1607.5312
Epoch [2274/2600] -> Loss: 1619.5871
Epoch [2275/2600] -> Loss: 1612.4982
Epoch [2276/2600] -> Loss: 1619.4584
Epoch [2277/2600] -> Loss: 1614.3073
Epoch [2278/2600] -> Loss: 1608.7602
Epoch [2279/2600] -> Loss: 1609.7111
Epoch [2280/2600] -> Loss: 1609.6254
Epoch [2281/2600] -> Loss: 1614.3592
Epoch [2282/2600] -> Loss: 1607.4002
Epoch [2283/2600] -> Loss: 1608.9960
Epoch [2284/2600] -> Loss: 1607.7837
Epoch [2285/2600] -> Loss: 1608.7319
Epoch [2286/2600] -> Loss: 1617.7900
Epoch [2287/2600] -> Loss: 1620.0315
Epoch [2288/2600] -> Loss: 1607.1490
Epoch [2289/2600] -> Loss: 1618.3486
Epoch [2290/2600] -> Loss: 1615.4372
Epoch [2291/2600] -> Loss: 1610.7531
Epoch [2292/2600] -> Loss: 1611.7975
Epoch [2293/2600] -> Loss: 1613.6589
Epoch [2294/2600] -> Loss: 1620.1802
Epoch [2295/2600] -> Loss: 1619.2883
Epoch [2296/2600] -> Loss: 1616.4005
Epoch [2297/2600] -> Loss: 1619.5962
Epoch [2298/2600] -> Loss: 1613.8747
Epoch [2299/2600] -> Loss: 1612.3022
Epoch [2300/2600] -> Loss: 1616.3996
Epoch [2301/2600] -> Loss: 1608.5680
Epoch [2302/2600] -> Loss: 1610.7550
Epoch [2303/2600] -> Loss: 1603.6377
Epoch [2304/2600] -> Loss: 1612.3141
Epoch [2305/2600] -> Loss: 1625.5786
Epoch [2306/2600] -> Loss: 1610.8782
Epoch [2307/2600] -> Loss: 1607.0513
Epoch [2308/2600] -> Loss: 1605.7018
Epoch [2309/2600] -> Loss: 1619.4000
Epoch [2310/2600] -> Loss: 1607.1174
Epoch [2311/2600] -> Loss: 1622.7535
Epoch [2312/2600] -> Loss: 1616.8289
Epoch [2313/2600] -> Loss: 1616.9021
Epoch [2314/2600] -> Loss: 1615.8146
Epoch [2315/2600] -> Loss: 1608.2359
Epoch [2316/2600] -> Loss: 1609.5680
Epoch [2317/2600] -> Loss: 1620.9585
Epoch [2318/2600] -> Loss: 1614.2462
Epoch [2319/2600] -> Loss: 1611.4269
Epoch [2320/2600] -> Loss: 1612.1496
Epoch [2321/2600] -> Loss: 1611.9690
Epoch [2322/2600] -> Loss: 1611.2228
Epoch [2323/2600] -> Loss: 1605.3359
Epoch [2324/2600] -> Loss: 1617.9162
Epoch [2325/2600] -> Loss: 1616.5808
Epoch [2326/2600] -> Loss: 1612.8888
Epoch [2327/2600] -> Loss: 1605.6504
Epoch [2328/2600] -> Loss: 1612.8857
Epoch [2329/2600] -> Loss: 1619.3818
Epoch [2330/2600] -> Loss: 1619.4236
Epoch [2331/2600] -> Loss: 1615.3433
Epoch [2332/2600] -> Loss: 1625.9005
Epoch [2333/2600] -> Loss: 1612.7730
Epoch [2334/2600] -> Loss: 1608.0781
Epoch [2335/2600] -> Loss: 1608.9647
Epoch [2336/2600] -> Loss: 1626.8232
Epoch [2337/2600] -> Loss: 1615.2078
Epoch [2338/2600] -> Loss: 1605.5611
Epoch [2339/2600] -> Loss: 1611.8515
Epoch [2340/2600] -> Loss: 1614.5711
Epoch [2341/2600] -> Loss: 1609.3104
Epoch [2342/2600] -> Loss: 1614.5660
Epoch [2343/2600] -> Loss: 1618.5673
Epoch [2344/2600] -> Loss: 1613.0587
Epoch [2345/2600] -> Loss: 1620.3576
Epoch [2346/2600] -> Loss: 1611.8548
Epoch [2347/2600] -> Loss: 1606.6305
Epoch [2348/2600] -> Loss: 1618.8936
Epoch [2349/2600] -> Loss: 1607.3471
Epoch [2350/2600] -> Loss: 1610.1926
Epoch [2351/2600] -> Loss: 1617.1958
Epoch [2352/2600] -> Loss: 1613.7471
Epoch [2353/2600] -> Loss: 1614.0364
Epoch [2354/2600] -> Loss: 1614.9590
Epoch [2355/2600] -> Loss: 1620.0702
Epoch [2356/2600] -> Loss: 1613.6394
Epoch [2357/2600] -> Loss: 1613.9248
Epoch [2358/2600] -> Loss: 1614.2448
Epoch [2359/2600] -> Loss: 1621.9140
Epoch [2360/2600] -> Loss: 1606.1713
Epoch [2361/2600] -> Loss: 1604.6567
Epoch [2362/2600] -> Loss: 1619.1780
Epoch [2363/2600] -> Loss: 1608.2944
Epoch [2364/2600] -> Loss: 1614.3247
Epoch [2365/2600] -> Loss: 1608.3598
Epoch [2366/2600] -> Loss: 1613.8965
Epoch [2367/2600] -> Loss: 1616.8155
Epoch [2368/2600] -> Loss: 1614.8273
Epoch [2369/2600] -> Loss: 1613.3373
Epoch [2370/2600] -> Loss: 1609.2165
Epoch [2371/2600] -> Loss: 1615.7294
Epoch [2372/2600] -> Loss: 1605.3851
Epoch [2373/2600] -> Loss: 1616.7170
Epoch [2374/2600] -> Loss: 1624.9842
Epoch [2375/2600] -> Loss: 1626.1772
Epoch [2376/2600] -> Loss: 1613.1301
Epoch [2377/2600] -> Loss: 1609.5352
Epoch [2378/2600] -> Loss: 1610.9420
Epoch [2379/2600] -> Loss: 1603.4137
Epoch [2380/2600] -> Loss: 1621.1891
Epoch [2381/2600] -> Loss: 1617.7718
Epoch [2382/2600] -> Loss: 1605.9322
Epoch [2383/2600] -> Loss: 1609.1427
Epoch [2384/2600] -> Loss: 1611.5688
Epoch [2385/2600] -> Loss: 1617.2051
Epoch [2386/2600] -> Loss: 1622.0076
Epoch [2387/2600] -> Loss: 1614.7630
Epoch [2388/2600] -> Loss: 1606.9863
Epoch [2389/2600] -> Loss: 1612.1405
Epoch [2390/2600] -> Loss: 1609.2956
Epoch [2391/2600] -> Loss: 1618.4813
Epoch [2392/2600] -> Loss: 1617.3306
Epoch [2393/2600] -> Loss: 1614.6215
Epoch [2394/2600] -> Loss: 1610.1920
Epoch [2395/2600] -> Loss: 1606.3581
Epoch [2396/2600] -> Loss: 1621.2172
Epoch [2397/2600] -> Loss: 1614.8458
Epoch [2398/2600] -> Loss: 1613.6481
Epoch [2399/2600] -> Loss: 1612.7617
--------------------------------------------------
Model checkpoint saved as FFNN_2400.pth
--------------------------------------------------
Epoch [2400/2600] -> Loss: 1617.9822
Epoch [2401/2600] -> Loss: 1607.6001
Epoch [2402/2600] -> Loss: 1610.6938
Epoch [2403/2600] -> Loss: 1620.0875
Epoch [2404/2600] -> Loss: 1606.2865
Epoch [2405/2600] -> Loss: 1609.1774
Epoch [2406/2600] -> Loss: 1612.8213
Epoch [2407/2600] -> Loss: 1609.8573
Epoch [2408/2600] -> Loss: 1605.4930
Epoch [2409/2600] -> Loss: 1613.0135
Epoch [2410/2600] -> Loss: 1605.2605
Epoch [2411/2600] -> Loss: 1611.4057
Epoch [2412/2600] -> Loss: 1609.7773
Epoch [2413/2600] -> Loss: 1616.3051
Epoch [2414/2600] -> Loss: 1605.7187
Epoch [2415/2600] -> Loss: 1617.3362
Epoch [2416/2600] -> Loss: 1613.9687
Epoch [2417/2600] -> Loss: 1618.1380
Epoch [2418/2600] -> Loss: 1614.9881
Epoch [2419/2600] -> Loss: 1610.6248
Epoch [2420/2600] -> Loss: 1612.8379
Epoch [2421/2600] -> Loss: 1623.8714
Epoch [2422/2600] -> Loss: 1602.9844
Epoch [2423/2600] -> Loss: 1612.3152
Epoch [2424/2600] -> Loss: 1615.5091
Epoch [2425/2600] -> Loss: 1610.4735
Epoch [2426/2600] -> Loss: 1610.3054
Epoch [2427/2600] -> Loss: 1607.8035
Epoch [2428/2600] -> Loss: 1623.2249
Epoch [2429/2600] -> Loss: 1608.6906
Epoch [2430/2600] -> Loss: 1607.7075
Epoch [2431/2600] -> Loss: 1605.9133
Epoch [2432/2600] -> Loss: 1608.5723
Epoch [2433/2600] -> Loss: 1620.6842
Epoch [2434/2600] -> Loss: 1610.6182
Epoch [2435/2600] -> Loss: 1615.6302
Epoch [2436/2600] -> Loss: 1605.2095
Epoch [2437/2600] -> Loss: 1616.2054
Epoch [2438/2600] -> Loss: 1632.3537
Epoch [2439/2600] -> Loss: 1610.0643
Epoch [2440/2600] -> Loss: 1617.4247
Epoch [2441/2600] -> Loss: 1621.2344
Epoch [2442/2600] -> Loss: 1610.1553
Epoch [2443/2600] -> Loss: 1613.2281
Epoch [2444/2600] -> Loss: 1616.5840
Epoch [2445/2600] -> Loss: 1608.6042
Epoch [2446/2600] -> Loss: 1624.2103
Epoch [2447/2600] -> Loss: 1620.5847
Epoch [2448/2600] -> Loss: 1625.0708
Epoch [2449/2600] -> Loss: 1613.4874
Epoch [2450/2600] -> Loss: 1617.9291
Epoch [2451/2600] -> Loss: 1617.2754
Epoch [2452/2600] -> Loss: 1613.4414
Epoch [2453/2600] -> Loss: 1613.5924
Epoch [2454/2600] -> Loss: 1612.9377
Epoch [2455/2600] -> Loss: 1612.1680
Epoch [2456/2600] -> Loss: 1616.6002
Epoch [2457/2600] -> Loss: 1615.8088
Epoch [2458/2600] -> Loss: 1606.3026
Epoch [2459/2600] -> Loss: 1614.9593
Epoch [2460/2600] -> Loss: 1616.8424
Epoch [2461/2600] -> Loss: 1618.0527
Epoch [2462/2600] -> Loss: 1613.8342
Epoch [2463/2600] -> Loss: 1613.2096
Epoch [2464/2600] -> Loss: 1619.3409
Epoch [2465/2600] -> Loss: 1609.4314
Epoch [2466/2600] -> Loss: 1604.3179
Epoch [2467/2600] -> Loss: 1607.3969
Epoch [2468/2600] -> Loss: 1613.6067
Epoch [2469/2600] -> Loss: 1610.5930
Epoch [2470/2600] -> Loss: 1608.5877
Epoch [2471/2600] -> Loss: 1610.3070
Epoch [2472/2600] -> Loss: 1615.4618
Epoch [2473/2600] -> Loss: 1614.3067
Epoch [2474/2600] -> Loss: 1621.5075
Epoch [2475/2600] -> Loss: 1616.9955
Epoch [2476/2600] -> Loss: 1614.6129
Epoch [2477/2600] -> Loss: 1608.6462
Epoch [2478/2600] -> Loss: 1612.2199
Epoch [2479/2600] -> Loss: 1612.8608
Epoch [2480/2600] -> Loss: 1605.6531
Epoch [2481/2600] -> Loss: 1606.7716
Epoch [2482/2600] -> Loss: 1619.0575
Epoch [2483/2600] -> Loss: 1613.5984
Epoch [2484/2600] -> Loss: 1615.4716
Epoch [2485/2600] -> Loss: 1608.4594
Epoch [2486/2600] -> Loss: 1608.7276
Epoch [2487/2600] -> Loss: 1608.4590
Epoch [2488/2600] -> Loss: 1609.9085
Epoch [2489/2600] -> Loss: 1610.6000
Epoch [2490/2600] -> Loss: 1600.8876
Epoch [2491/2600] -> Loss: 1614.9942
Epoch [2492/2600] -> Loss: 1613.3776
Epoch [2493/2600] -> Loss: 1610.8936
Epoch [2494/2600] -> Loss: 1608.6040
Epoch [2495/2600] -> Loss: 1611.2806
Epoch [2496/2600] -> Loss: 1612.9941
Epoch [2497/2600] -> Loss: 1611.6608
Epoch [2498/2600] -> Loss: 1612.6336
Epoch [2499/2600] -> Loss: 1615.1206
Epoch [2500/2600] -> Loss: 1609.4885
Epoch [2501/2600] -> Loss: 1616.5698
Epoch [2502/2600] -> Loss: 1612.2940
Epoch [2503/2600] -> Loss: 1618.6478
Epoch [2504/2600] -> Loss: 1615.6171
Epoch [2505/2600] -> Loss: 1621.8221
Epoch [2506/2600] -> Loss: 1616.0898
Epoch [2507/2600] -> Loss: 1617.5430
Epoch [2508/2600] -> Loss: 1613.6899
Epoch [2509/2600] -> Loss: 1610.4528
Epoch [2510/2600] -> Loss: 1615.1809
Epoch [2511/2600] -> Loss: 1619.0072
Epoch [2512/2600] -> Loss: 1624.3581
Epoch [2513/2600] -> Loss: 1614.9856
Epoch [2514/2600] -> Loss: 1616.8377
Epoch [2515/2600] -> Loss: 1610.9888
Epoch [2516/2600] -> Loss: 1621.0034
Epoch [2517/2600] -> Loss: 1609.7177
Epoch [2518/2600] -> Loss: 1618.6809
Epoch [2519/2600] -> Loss: 1614.7248
Epoch [2520/2600] -> Loss: 1600.3346
Epoch [2521/2600] -> Loss: 1617.1372
Epoch [2522/2600] -> Loss: 1623.8030
Epoch [2523/2600] -> Loss: 1618.9023
Epoch [2524/2600] -> Loss: 1605.8175
Epoch [2525/2600] -> Loss: 1612.7695
Epoch [2526/2600] -> Loss: 1614.4901
Epoch [2527/2600] -> Loss: 1609.1246
Epoch [2528/2600] -> Loss: 1614.0032
Epoch [2529/2600] -> Loss: 1622.2017
Epoch [2530/2600] -> Loss: 1610.6899
Epoch [2531/2600] -> Loss: 1606.2858
Epoch [2532/2600] -> Loss: 1611.0900
Epoch [2533/2600] -> Loss: 1621.4777
Epoch [2534/2600] -> Loss: 1611.7305
Epoch [2535/2600] -> Loss: 1613.3948
Epoch [2536/2600] -> Loss: 1607.3084
Epoch [2537/2600] -> Loss: 1620.5557
Epoch [2538/2600] -> Loss: 1610.6301
Epoch [2539/2600] -> Loss: 1605.6514
Epoch [2540/2600] -> Loss: 1613.8429
Epoch [2541/2600] -> Loss: 1609.8609
Epoch [2542/2600] -> Loss: 1610.5759
Epoch [2543/2600] -> Loss: 1617.6272
Epoch [2544/2600] -> Loss: 1623.9487
Epoch [2545/2600] -> Loss: 1604.2656
Epoch [2546/2600] -> Loss: 1603.8866
Epoch [2547/2600] -> Loss: 1608.7423
Epoch [2548/2600] -> Loss: 1625.2335
Epoch [2549/2600] -> Loss: 1614.3225
Epoch [2550/2600] -> Loss: 1616.6004
Epoch [2551/2600] -> Loss: 1615.4221
Epoch [2552/2600] -> Loss: 1616.2829
Epoch [2553/2600] -> Loss: 1612.4124
Epoch [2554/2600] -> Loss: 1620.3071
Epoch [2555/2600] -> Loss: 1607.2269
Epoch [2556/2600] -> Loss: 1619.2738
Epoch [2557/2600] -> Loss: 1607.5529
Epoch [2558/2600] -> Loss: 1622.8018
Epoch [2559/2600] -> Loss: 1614.8692
Epoch [2560/2600] -> Loss: 1612.3412
Epoch [2561/2600] -> Loss: 1609.6000
Epoch [2562/2600] -> Loss: 1621.8817
Epoch [2563/2600] -> Loss: 1610.8241
Epoch [2564/2600] -> Loss: 1611.7008
Epoch [2565/2600] -> Loss: 1610.8085
Epoch [2566/2600] -> Loss: 1614.3485
Epoch [2567/2600] -> Loss: 1613.6627
Epoch [2568/2600] -> Loss: 1617.0129
Epoch [2569/2600] -> Loss: 1614.9354
Epoch [2570/2600] -> Loss: 1613.9053
Epoch [2571/2600] -> Loss: 1608.6656
Epoch [2572/2600] -> Loss: 1609.1645
Epoch [2573/2600] -> Loss: 1620.3342
Epoch [2574/2600] -> Loss: 1612.9141
Epoch [2575/2600] -> Loss: 1614.7439
Epoch [2576/2600] -> Loss: 1609.4764
Epoch [2577/2600] -> Loss: 1615.5423
Epoch [2578/2600] -> Loss: 1608.0639
Epoch [2579/2600] -> Loss: 1622.1945
Epoch [2580/2600] -> Loss: 1612.5957
Epoch [2581/2600] -> Loss: 1627.4592
Epoch [2582/2600] -> Loss: 1621.7944
Epoch [2583/2600] -> Loss: 1624.4836
Epoch [2584/2600] -> Loss: 1609.8049
Epoch [2585/2600] -> Loss: 1606.3926
Epoch [2586/2600] -> Loss: 1624.2247
Epoch [2587/2600] -> Loss: 1616.6124
Epoch [2588/2600] -> Loss: 1616.1596
Epoch [2589/2600] -> Loss: 1614.0363
Epoch [2590/2600] -> Loss: 1622.6271
Epoch [2591/2600] -> Loss: 1611.9421
Epoch [2592/2600] -> Loss: 1618.8109
Epoch [2593/2600] -> Loss: 1612.3583
Epoch [2594/2600] -> Loss: 1612.1265
Epoch [2595/2600] -> Loss: 1616.3745
Epoch [2596/2600] -> Loss: 1621.4950
Epoch [2597/2600] -> Loss: 1627.4642
Epoch [2598/2600] -> Loss: 1613.1596
Epoch [2599/2600] -> Loss: 1617.2389
--------------------------------------------------
Model checkpoint saved as FFNN_2600.pth
--------------------------------------------------
Epoch [2600/2600] -> Loss: 1610.7517
--------------------------------------------------
Training finished successfully.
        Saved model checkpoints can be found in: /home/extern/Documents/Research/scripts/models/
        Saved data/loss graphs can be found in: /home/extern/Documents/Research/scripts/graphs/

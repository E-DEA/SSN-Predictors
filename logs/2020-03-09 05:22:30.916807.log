--------------------------------------------------
Code running on device: cuda
--------------------------------------------------
File location :
    SSN - /home/extern/Documents/Research/scripts/data/SILSO/TSN/SN_m_tot_V2.0.txt
    AA - /home/extern/Documents/Research/scripts/data/ISGI/aa_1869-01-01_2018-12-31_D.dat
--------------------------------------------------
Selected model: FFNN(
  (model): Sequential(
    (0): Linear(in_features=6, out_features=6, bias=True)
    (1): LeakyReLU(negative_slope=0.01, inplace=True)
    (2): Linear(in_features=6, out_features=6, bias=True)
    (3): LeakyReLU(negative_slope=0.01, inplace=True)
    (4): Linear(in_features=6, out_features=1, bias=True)
  )
)    Training mode: True    Testing mode: False
--------------------------------------------------
No pre-trained models available, initializing model weights
--------------------------------------------------
Training model with: num_epochs=1800, start_lr=0.0005
Epoch [   1/1800] -> Loss: 12657.3761
Epoch [   2/1800] -> Loss: 8002.9905
Epoch [   3/1800] -> Loss: 3736.3571
Epoch [   4/1800] -> Loss: 3089.6489
Epoch [   5/1800] -> Loss: 3072.0813
Epoch [   6/1800] -> Loss: 3071.4123
Epoch [   7/1800] -> Loss: 3054.0456
Epoch [   8/1800] -> Loss: 3042.5209
Epoch [   9/1800] -> Loss: 3041.1514
Epoch [  10/1800] -> Loss: 3035.6936
Epoch [  11/1800] -> Loss: 3026.5805
Epoch [  12/1800] -> Loss: 3014.8925
Epoch [  13/1800] -> Loss: 2995.4645
Epoch [  14/1800] -> Loss: 2988.8024
Epoch [  15/1800] -> Loss: 2974.8584
Epoch [  16/1800] -> Loss: 2964.0431
Epoch [  17/1800] -> Loss: 2953.6151
Epoch [  18/1800] -> Loss: 2936.2336
Epoch [  19/1800] -> Loss: 2933.6802
Epoch [  20/1800] -> Loss: 2917.3702
Epoch [  21/1800] -> Loss: 2911.2358
Epoch [  22/1800] -> Loss: 2873.7576
Epoch [  23/1800] -> Loss: 2856.7898
Epoch [  24/1800] -> Loss: 2836.2948
Epoch [  25/1800] -> Loss: 2810.8182
Epoch [  26/1800] -> Loss: 2789.5332
Epoch [  27/1800] -> Loss: 2772.4903
Epoch [  28/1800] -> Loss: 2740.5518
Epoch [  29/1800] -> Loss: 2728.6208
Epoch [  30/1800] -> Loss: 2692.3373
Epoch [  31/1800] -> Loss: 2667.4275
Epoch [  32/1800] -> Loss: 2659.8341
Epoch [  33/1800] -> Loss: 2614.4887
Epoch [  34/1800] -> Loss: 2586.7156
Epoch [  35/1800] -> Loss: 2568.0929
Epoch [  36/1800] -> Loss: 2530.7777
Epoch [  37/1800] -> Loss: 2506.1430
Epoch [  38/1800] -> Loss: 2481.5778
Epoch [  39/1800] -> Loss: 2438.1241
Epoch [  40/1800] -> Loss: 2429.8995
Epoch [  41/1800] -> Loss: 2388.4311
Epoch [  42/1800] -> Loss: 2364.9968
Epoch [  43/1800] -> Loss: 2329.3036
Epoch [  44/1800] -> Loss: 2311.6370
Epoch [  45/1800] -> Loss: 2277.3169
Epoch [  46/1800] -> Loss: 2254.1333
Epoch [  47/1800] -> Loss: 2233.6116
Epoch [  48/1800] -> Loss: 2207.3561
Epoch [  49/1800] -> Loss: 2177.6043
Epoch [  50/1800] -> Loss: 2155.0134
Epoch [  51/1800] -> Loss: 2136.5981
Epoch [  52/1800] -> Loss: 2113.2899
Epoch [  53/1800] -> Loss: 2084.0839
Epoch [  54/1800] -> Loss: 2072.1636
Epoch [  55/1800] -> Loss: 2047.8814
Epoch [  56/1800] -> Loss: 2029.1869
Epoch [  57/1800] -> Loss: 2005.5961
Epoch [  58/1800] -> Loss: 1993.6315
Epoch [  59/1800] -> Loss: 1982.5402
Epoch [  60/1800] -> Loss: 1953.2502
Epoch [  61/1800] -> Loss: 1943.5932
Epoch [  62/1800] -> Loss: 1934.9843
Epoch [  63/1800] -> Loss: 1924.3489
Epoch [  64/1800] -> Loss: 1891.9149
Epoch [  65/1800] -> Loss: 1869.5776
Epoch [  66/1800] -> Loss: 1872.4583
Epoch [  67/1800] -> Loss: 1842.9357
Epoch [  68/1800] -> Loss: 1832.1231
Epoch [  69/1800] -> Loss: 1830.1316
Epoch [  70/1800] -> Loss: 1801.1624
Epoch [  71/1800] -> Loss: 1802.5783
Epoch [  72/1800] -> Loss: 1782.2973
Epoch [  73/1800] -> Loss: 1773.4417
Epoch [  74/1800] -> Loss: 1762.0952
Epoch [  75/1800] -> Loss: 1763.3135
Epoch [  76/1800] -> Loss: 1741.6202
Epoch [  77/1800] -> Loss: 1751.3618
Epoch [  78/1800] -> Loss: 1727.1338
Epoch [  79/1800] -> Loss: 1717.1995
Epoch [  80/1800] -> Loss: 1719.7389
Epoch [  81/1800] -> Loss: 1707.8841
Epoch [  82/1800] -> Loss: 1698.8352
Epoch [  83/1800] -> Loss: 1689.3443
Epoch [  84/1800] -> Loss: 1683.8494
Epoch [  85/1800] -> Loss: 1688.9650
Epoch [  86/1800] -> Loss: 1667.2448
Epoch [  87/1800] -> Loss: 1671.3288
Epoch [  88/1800] -> Loss: 1659.9411
Epoch [  89/1800] -> Loss: 1653.2956
Epoch [  90/1800] -> Loss: 1652.2109
Epoch [  91/1800] -> Loss: 1637.8403
Epoch [  92/1800] -> Loss: 1649.7437
Epoch [  93/1800] -> Loss: 1636.7877
Epoch [  94/1800] -> Loss: 1636.9506
Epoch [  95/1800] -> Loss: 1618.0845
Epoch [  96/1800] -> Loss: 1624.6195
Epoch [  97/1800] -> Loss: 1621.2442
Epoch [  98/1800] -> Loss: 1618.5220
Epoch [  99/1800] -> Loss: 1615.2165
--------------------------------------------------
Model checkpoint saved as FFNN_100.pth
--------------------------------------------------
Epoch [ 100/1800] -> Loss: 1633.0658
Epoch [ 101/1800] -> Loss: 1611.5311
Epoch [ 102/1800] -> Loss: 1603.1320
Epoch [ 103/1800] -> Loss: 1605.1078
Epoch [ 104/1800] -> Loss: 1610.3471
Epoch [ 105/1800] -> Loss: 1595.8162
Epoch [ 106/1800] -> Loss: 1595.2664
Epoch [ 107/1800] -> Loss: 1603.0582
Epoch [ 108/1800] -> Loss: 1598.0537
Epoch [ 109/1800] -> Loss: 1584.0106
Epoch [ 110/1800] -> Loss: 1583.1817
Epoch [ 111/1800] -> Loss: 1586.7822
Epoch [ 112/1800] -> Loss: 1575.5259
Epoch [ 113/1800] -> Loss: 1583.8708
Epoch [ 114/1800] -> Loss: 1583.4575
Epoch [ 115/1800] -> Loss: 1571.9658
Epoch [ 116/1800] -> Loss: 1576.4574
Epoch [ 117/1800] -> Loss: 1577.4581
Epoch [ 118/1800] -> Loss: 1570.0588
Epoch [ 119/1800] -> Loss: 1570.8217
Epoch [ 120/1800] -> Loss: 1575.7783
Epoch [ 121/1800] -> Loss: 1581.2460
Epoch [ 122/1800] -> Loss: 1563.4573
Epoch [ 123/1800] -> Loss: 1570.2722
Epoch [ 124/1800] -> Loss: 1564.3550
Epoch [ 125/1800] -> Loss: 1576.7504
Epoch [ 126/1800] -> Loss: 1578.2190
Epoch [ 127/1800] -> Loss: 1566.6157
Epoch [ 128/1800] -> Loss: 1566.2547
Epoch [ 129/1800] -> Loss: 1567.7560
Epoch [ 130/1800] -> Loss: 1572.0367
Epoch [ 131/1800] -> Loss: 1558.4305
Epoch [ 132/1800] -> Loss: 1565.3415
Epoch [ 133/1800] -> Loss: 1568.9486
Epoch [ 134/1800] -> Loss: 1551.8665
Epoch [ 135/1800] -> Loss: 1566.6661
Epoch [ 136/1800] -> Loss: 1566.1487
Epoch [ 137/1800] -> Loss: 1564.7527
Epoch [ 138/1800] -> Loss: 1546.9212
Epoch [ 139/1800] -> Loss: 1561.0879
Epoch [ 140/1800] -> Loss: 1553.6063
Epoch [ 141/1800] -> Loss: 1552.8293
Epoch [ 142/1800] -> Loss: 1560.0990
Epoch [ 143/1800] -> Loss: 1551.7675
Epoch [ 144/1800] -> Loss: 1552.2837
Epoch [ 145/1800] -> Loss: 1556.4168
Epoch [ 146/1800] -> Loss: 1552.3605
Epoch [ 147/1800] -> Loss: 1559.4420
Epoch [ 148/1800] -> Loss: 1549.7498
Epoch   149: reducing learning rate of group 0 to 2.5000e-04.
Epoch [ 149/1800] -> Loss: 1550.0244
Epoch [ 150/1800] -> Loss: 1542.5707
Epoch [ 151/1800] -> Loss: 1543.9158
Epoch [ 152/1800] -> Loss: 1543.2731
Epoch [ 153/1800] -> Loss: 1542.8528
Epoch [ 154/1800] -> Loss: 1547.6617
Epoch [ 155/1800] -> Loss: 1538.4619
Epoch [ 156/1800] -> Loss: 1547.9738
Epoch [ 157/1800] -> Loss: 1544.1131
Epoch [ 158/1800] -> Loss: 1543.1341
Epoch [ 159/1800] -> Loss: 1549.1792
Epoch [ 160/1800] -> Loss: 1541.0852
Epoch [ 161/1800] -> Loss: 1549.9227
Epoch [ 162/1800] -> Loss: 1542.1326
Epoch [ 163/1800] -> Loss: 1541.5463
Epoch [ 164/1800] -> Loss: 1544.2353
Epoch [ 165/1800] -> Loss: 1542.7585
Epoch [ 166/1800] -> Loss: 1534.9519
Epoch [ 167/1800] -> Loss: 1543.0602
Epoch [ 168/1800] -> Loss: 1537.1488
Epoch [ 169/1800] -> Loss: 1537.8316
Epoch [ 170/1800] -> Loss: 1538.4581
Epoch [ 171/1800] -> Loss: 1528.4426
Epoch [ 172/1800] -> Loss: 1536.3700
Epoch [ 173/1800] -> Loss: 1533.1186
Epoch [ 174/1800] -> Loss: 1549.3884
Epoch [ 175/1800] -> Loss: 1545.0769
Epoch [ 176/1800] -> Loss: 1534.6219
Epoch [ 177/1800] -> Loss: 1540.9520
Epoch [ 178/1800] -> Loss: 1537.1251
Epoch [ 179/1800] -> Loss: 1541.7649
Epoch [ 180/1800] -> Loss: 1540.1394
Epoch [ 181/1800] -> Loss: 1529.6998
Epoch   182: reducing learning rate of group 0 to 1.2500e-04.
Epoch [ 182/1800] -> Loss: 1536.3314
Epoch [ 183/1800] -> Loss: 1529.9880
Epoch [ 184/1800] -> Loss: 1530.6928
Epoch [ 185/1800] -> Loss: 1530.0687
Epoch [ 186/1800] -> Loss: 1528.9191
Epoch [ 187/1800] -> Loss: 1528.2304
Epoch [ 188/1800] -> Loss: 1534.5479
Epoch [ 189/1800] -> Loss: 1532.1247
Epoch [ 190/1800] -> Loss: 1526.3551
Epoch [ 191/1800] -> Loss: 1534.4649
Epoch [ 192/1800] -> Loss: 1534.5055
Epoch [ 193/1800] -> Loss: 1531.0011
Epoch [ 194/1800] -> Loss: 1533.0087
Epoch [ 195/1800] -> Loss: 1529.7703
Epoch [ 196/1800] -> Loss: 1529.1264
Epoch [ 197/1800] -> Loss: 1527.2996
Epoch [ 198/1800] -> Loss: 1529.4356
Epoch [ 199/1800] -> Loss: 1530.6016
--------------------------------------------------
Model checkpoint saved as FFNN_200.pth
--------------------------------------------------
Epoch [ 200/1800] -> Loss: 1529.1247
Epoch   201: reducing learning rate of group 0 to 6.2500e-05.
Epoch [ 201/1800] -> Loss: 1534.5703
Epoch [ 202/1800] -> Loss: 1529.9576
Epoch [ 203/1800] -> Loss: 1529.4796
Epoch [ 204/1800] -> Loss: 1528.9101
Epoch [ 205/1800] -> Loss: 1527.7561
Epoch [ 206/1800] -> Loss: 1530.3883
Epoch [ 207/1800] -> Loss: 1529.5615
Epoch [ 208/1800] -> Loss: 1531.0884
Epoch [ 209/1800] -> Loss: 1527.8276
Epoch [ 210/1800] -> Loss: 1527.0014
Epoch [ 211/1800] -> Loss: 1527.3542
Epoch   212: reducing learning rate of group 0 to 3.1250e-05.
Epoch [ 212/1800] -> Loss: 1527.0081
Epoch [ 213/1800] -> Loss: 1525.7894
Epoch [ 214/1800] -> Loss: 1524.6163
Epoch [ 215/1800] -> Loss: 1528.0175
Epoch [ 216/1800] -> Loss: 1529.9613
Epoch [ 217/1800] -> Loss: 1525.8997
Epoch [ 218/1800] -> Loss: 1530.0734
Epoch [ 219/1800] -> Loss: 1524.1700
Epoch [ 220/1800] -> Loss: 1527.3224
Epoch [ 221/1800] -> Loss: 1525.5020
Epoch [ 222/1800] -> Loss: 1525.1747
Epoch [ 223/1800] -> Loss: 1523.9776
Epoch [ 224/1800] -> Loss: 1527.1094
Epoch [ 225/1800] -> Loss: 1530.0271
Epoch [ 226/1800] -> Loss: 1528.7268
Epoch [ 227/1800] -> Loss: 1523.7678
Epoch [ 228/1800] -> Loss: 1529.7940
Epoch [ 229/1800] -> Loss: 1535.6658
Epoch [ 230/1800] -> Loss: 1524.0142
Epoch [ 231/1800] -> Loss: 1526.2049
Epoch [ 232/1800] -> Loss: 1524.2222
Epoch [ 233/1800] -> Loss: 1525.5849
Epoch [ 234/1800] -> Loss: 1529.2176
Epoch [ 235/1800] -> Loss: 1534.4166
Epoch [ 236/1800] -> Loss: 1526.4344
Epoch [ 237/1800] -> Loss: 1524.5748
Epoch   238: reducing learning rate of group 0 to 1.5625e-05.
Epoch [ 238/1800] -> Loss: 1525.8721
Epoch [ 239/1800] -> Loss: 1524.3162
Epoch [ 240/1800] -> Loss: 1531.0677
Epoch [ 241/1800] -> Loss: 1524.4567
Epoch [ 242/1800] -> Loss: 1525.5998
Epoch [ 243/1800] -> Loss: 1524.5435
Epoch [ 244/1800] -> Loss: 1524.5336
Epoch [ 245/1800] -> Loss: 1526.9592
Epoch [ 246/1800] -> Loss: 1522.5669
Epoch [ 247/1800] -> Loss: 1523.8043
Epoch [ 248/1800] -> Loss: 1523.3535
Epoch [ 249/1800] -> Loss: 1522.6428
Epoch [ 250/1800] -> Loss: 1523.2002
Epoch [ 251/1800] -> Loss: 1527.5951
Epoch [ 252/1800] -> Loss: 1523.4518
Epoch [ 253/1800] -> Loss: 1525.0843
Epoch [ 254/1800] -> Loss: 1523.1865
Epoch [ 255/1800] -> Loss: 1524.2424
Epoch [ 256/1800] -> Loss: 1523.3041
Epoch   257: reducing learning rate of group 0 to 7.8125e-06.
Epoch [ 257/1800] -> Loss: 1522.6426
Epoch [ 258/1800] -> Loss: 1531.0546
Epoch [ 259/1800] -> Loss: 1527.1869
Epoch [ 260/1800] -> Loss: 1522.3492
Epoch [ 261/1800] -> Loss: 1523.5387
Epoch [ 262/1800] -> Loss: 1522.7225
Epoch [ 263/1800] -> Loss: 1523.4764
Epoch [ 264/1800] -> Loss: 1525.1166
Epoch [ 265/1800] -> Loss: 1523.2050
Epoch [ 266/1800] -> Loss: 1523.3023
Epoch [ 267/1800] -> Loss: 1523.3916
Epoch [ 268/1800] -> Loss: 1522.6930
Epoch [ 269/1800] -> Loss: 1523.3221
Epoch [ 270/1800] -> Loss: 1522.8117
Epoch   271: reducing learning rate of group 0 to 3.9063e-06.
Epoch [ 271/1800] -> Loss: 1522.8060
Epoch [ 272/1800] -> Loss: 1537.0071
Epoch [ 273/1800] -> Loss: 1537.0939
Epoch [ 274/1800] -> Loss: 1523.2637
Epoch [ 275/1800] -> Loss: 1529.1742
Epoch [ 276/1800] -> Loss: 1522.1098
Epoch [ 277/1800] -> Loss: 1524.7174
Epoch [ 278/1800] -> Loss: 1526.2181
Epoch [ 279/1800] -> Loss: 1530.5618
Epoch [ 280/1800] -> Loss: 1522.2643
Epoch [ 281/1800] -> Loss: 1522.9667
Epoch [ 282/1800] -> Loss: 1526.8641
Epoch [ 283/1800] -> Loss: 1528.1437
Epoch [ 284/1800] -> Loss: 1531.3358
Epoch [ 285/1800] -> Loss: 1525.3961
Epoch [ 286/1800] -> Loss: 1523.0439
Epoch   287: reducing learning rate of group 0 to 1.9531e-06.
Epoch [ 287/1800] -> Loss: 1523.4451
Epoch [ 288/1800] -> Loss: 1523.8057
Epoch [ 289/1800] -> Loss: 1528.6980
Epoch [ 290/1800] -> Loss: 1525.8735
Epoch [ 291/1800] -> Loss: 1528.5009
Epoch [ 292/1800] -> Loss: 1522.6043
Epoch [ 293/1800] -> Loss: 1525.9446
Epoch [ 294/1800] -> Loss: 1527.5483
Epoch [ 295/1800] -> Loss: 1525.2272
Epoch [ 296/1800] -> Loss: 1522.9261
Epoch [ 297/1800] -> Loss: 1523.5988
Epoch   298: reducing learning rate of group 0 to 9.7656e-07.
Epoch [ 298/1800] -> Loss: 1525.1670
Epoch [ 299/1800] -> Loss: 1522.6320
--------------------------------------------------
Model checkpoint saved as FFNN_300.pth
--------------------------------------------------
Epoch [ 300/1800] -> Loss: 1523.4383
Epoch [ 301/1800] -> Loss: 1523.5013
Epoch [ 302/1800] -> Loss: 1524.2516
Epoch [ 303/1800] -> Loss: 1525.2050
Epoch [ 304/1800] -> Loss: 1527.6019
Epoch [ 305/1800] -> Loss: 1529.1528
Epoch [ 306/1800] -> Loss: 1522.6714
Epoch [ 307/1800] -> Loss: 1536.0489
Epoch [ 308/1800] -> Loss: 1522.8215
Epoch   309: reducing learning rate of group 0 to 4.8828e-07.
Epoch [ 309/1800] -> Loss: 1522.2942
Epoch [ 310/1800] -> Loss: 1522.5408
Epoch [ 311/1800] -> Loss: 1522.3010
Epoch [ 312/1800] -> Loss: 1524.0749
Epoch [ 313/1800] -> Loss: 1521.7841
Epoch [ 314/1800] -> Loss: 1523.0396
Epoch [ 315/1800] -> Loss: 1522.2031
Epoch [ 316/1800] -> Loss: 1522.9557
Epoch [ 317/1800] -> Loss: 1526.3224
Epoch [ 318/1800] -> Loss: 1524.1786
Epoch [ 319/1800] -> Loss: 1522.0766
Epoch [ 320/1800] -> Loss: 1522.5044
Epoch [ 321/1800] -> Loss: 1525.6141
Epoch [ 322/1800] -> Loss: 1521.8760
Epoch [ 323/1800] -> Loss: 1522.1164
Epoch   324: reducing learning rate of group 0 to 2.4414e-07.
Epoch [ 324/1800] -> Loss: 1523.7236
Epoch [ 325/1800] -> Loss: 1522.3133
Epoch [ 326/1800] -> Loss: 1524.1772
Epoch [ 327/1800] -> Loss: 1522.9911
Epoch [ 328/1800] -> Loss: 1521.8020
Epoch [ 329/1800] -> Loss: 1523.8208
Epoch [ 330/1800] -> Loss: 1522.1262
Epoch [ 331/1800] -> Loss: 1522.6766
Epoch [ 332/1800] -> Loss: 1524.3044
Epoch [ 333/1800] -> Loss: 1524.5379
Epoch [ 334/1800] -> Loss: 1523.6414
Epoch   335: reducing learning rate of group 0 to 1.2207e-07.
Epoch [ 335/1800] -> Loss: 1521.9878
Epoch [ 336/1800] -> Loss: 1524.7602
Epoch [ 337/1800] -> Loss: 1521.6363
Epoch [ 338/1800] -> Loss: 1525.6500
Epoch [ 339/1800] -> Loss: 1527.7088
Epoch [ 340/1800] -> Loss: 1525.9555
Epoch [ 341/1800] -> Loss: 1523.6743
Epoch [ 342/1800] -> Loss: 1525.7958
Epoch [ 343/1800] -> Loss: 1526.8657
Epoch [ 344/1800] -> Loss: 1522.0972
Epoch [ 345/1800] -> Loss: 1522.1099
Epoch   346: reducing learning rate of group 0 to 6.1035e-08.
Epoch [ 346/1800] -> Loss: 1523.9089
Epoch [ 347/1800] -> Loss: 1527.0687
Epoch [ 348/1800] -> Loss: 1524.3333
Epoch [ 349/1800] -> Loss: 1521.6714
Epoch [ 350/1800] -> Loss: 1525.8778
Epoch [ 351/1800] -> Loss: 1522.7334
Epoch [ 352/1800] -> Loss: 1524.0737
Epoch [ 353/1800] -> Loss: 1521.7875
Epoch [ 354/1800] -> Loss: 1522.6466
Epoch [ 355/1800] -> Loss: 1522.8881
Epoch [ 356/1800] -> Loss: 1522.0453
Epoch   357: reducing learning rate of group 0 to 3.0518e-08.
Epoch [ 357/1800] -> Loss: 1522.7217
Epoch [ 358/1800] -> Loss: 1524.9042
Epoch [ 359/1800] -> Loss: 1527.8259
Epoch [ 360/1800] -> Loss: 1525.8971
Epoch [ 361/1800] -> Loss: 1522.6075
Epoch [ 362/1800] -> Loss: 1525.0043
Epoch [ 363/1800] -> Loss: 1523.7024
Epoch [ 364/1800] -> Loss: 1523.3806
Epoch [ 365/1800] -> Loss: 1521.6765
Epoch [ 366/1800] -> Loss: 1523.2596
Epoch [ 367/1800] -> Loss: 1523.5584
Epoch   368: reducing learning rate of group 0 to 1.5259e-08.
Epoch [ 368/1800] -> Loss: 1530.5846
Epoch [ 369/1800] -> Loss: 1522.0002
Epoch [ 370/1800] -> Loss: 1523.5852
Epoch [ 371/1800] -> Loss: 1526.6135
Epoch [ 372/1800] -> Loss: 1526.9118
Epoch [ 373/1800] -> Loss: 1525.6837
Epoch [ 374/1800] -> Loss: 1522.9190
Epoch [ 375/1800] -> Loss: 1524.8806
Epoch [ 376/1800] -> Loss: 1523.3080
Epoch [ 377/1800] -> Loss: 1527.2886
Epoch [ 378/1800] -> Loss: 1525.3076
Epoch [ 379/1800] -> Loss: 1524.2733
Epoch [ 380/1800] -> Loss: 1523.9463
Epoch [ 381/1800] -> Loss: 1522.4099
Epoch [ 382/1800] -> Loss: 1526.0785
Epoch [ 383/1800] -> Loss: 1524.6364
Epoch [ 384/1800] -> Loss: 1523.9904
Epoch [ 385/1800] -> Loss: 1522.2341
Epoch [ 386/1800] -> Loss: 1522.6048
Epoch [ 387/1800] -> Loss: 1524.1880
Epoch [ 388/1800] -> Loss: 1524.0310
Epoch [ 389/1800] -> Loss: 1524.0678
Epoch [ 390/1800] -> Loss: 1525.5197
Epoch [ 391/1800] -> Loss: 1527.9111
Epoch [ 392/1800] -> Loss: 1530.5248
Epoch [ 393/1800] -> Loss: 1525.5705
Epoch [ 394/1800] -> Loss: 1523.0084
Epoch [ 395/1800] -> Loss: 1523.6776
Epoch [ 396/1800] -> Loss: 1522.2607
Epoch [ 397/1800] -> Loss: 1527.6828
Epoch [ 398/1800] -> Loss: 1531.6847
Epoch [ 399/1800] -> Loss: 1532.4520
--------------------------------------------------
Model checkpoint saved as FFNN_400.pth
--------------------------------------------------
Epoch [ 400/1800] -> Loss: 1522.5464
Epoch [ 401/1800] -> Loss: 1521.8505
Epoch [ 402/1800] -> Loss: 1522.8397
Epoch [ 403/1800] -> Loss: 1525.4693
Epoch [ 404/1800] -> Loss: 1525.6824
Epoch [ 405/1800] -> Loss: 1525.3427
Epoch [ 406/1800] -> Loss: 1522.0257
Epoch [ 407/1800] -> Loss: 1535.1733
Epoch [ 408/1800] -> Loss: 1523.0329
Epoch [ 409/1800] -> Loss: 1521.9278
Epoch [ 410/1800] -> Loss: 1528.4496
Epoch [ 411/1800] -> Loss: 1523.8805
Epoch [ 412/1800] -> Loss: 1522.1637
Epoch [ 413/1800] -> Loss: 1523.9058
Epoch [ 414/1800] -> Loss: 1525.1726
Epoch [ 415/1800] -> Loss: 1524.0793
Epoch [ 416/1800] -> Loss: 1527.1801
Epoch [ 417/1800] -> Loss: 1525.4229
Epoch [ 418/1800] -> Loss: 1525.0182
Epoch [ 419/1800] -> Loss: 1523.7638
Epoch [ 420/1800] -> Loss: 1523.3101
Epoch [ 421/1800] -> Loss: 1524.3410
Epoch [ 422/1800] -> Loss: 1521.7428
Epoch [ 423/1800] -> Loss: 1522.4973
Epoch [ 424/1800] -> Loss: 1525.0173
Epoch [ 425/1800] -> Loss: 1524.0466
Epoch [ 426/1800] -> Loss: 1526.4871
Epoch [ 427/1800] -> Loss: 1522.4340
Epoch [ 428/1800] -> Loss: 1523.6686
Epoch [ 429/1800] -> Loss: 1524.3766
Epoch [ 430/1800] -> Loss: 1524.4354
Epoch [ 431/1800] -> Loss: 1523.4874
Epoch [ 432/1800] -> Loss: 1525.7033
Epoch [ 433/1800] -> Loss: 1523.7343
Epoch [ 434/1800] -> Loss: 1522.2666
Epoch [ 435/1800] -> Loss: 1522.9268
Epoch [ 436/1800] -> Loss: 1523.0319
Epoch [ 437/1800] -> Loss: 1525.0224
Epoch [ 438/1800] -> Loss: 1524.9138
Epoch [ 439/1800] -> Loss: 1522.6309
Epoch [ 440/1800] -> Loss: 1525.3644
Epoch [ 441/1800] -> Loss: 1527.4973
Epoch [ 442/1800] -> Loss: 1526.0280
Epoch [ 443/1800] -> Loss: 1523.1839
Epoch [ 444/1800] -> Loss: 1527.2040
Epoch [ 445/1800] -> Loss: 1523.3600
Epoch [ 446/1800] -> Loss: 1522.4894
Epoch [ 447/1800] -> Loss: 1529.4340
Epoch [ 448/1800] -> Loss: 1524.8587
Epoch [ 449/1800] -> Loss: 1522.8211
Epoch [ 450/1800] -> Loss: 1531.6263
Epoch [ 451/1800] -> Loss: 1542.7141
Epoch [ 452/1800] -> Loss: 1522.6034
Epoch [ 453/1800] -> Loss: 1524.8447
Epoch [ 454/1800] -> Loss: 1523.3214
Epoch [ 455/1800] -> Loss: 1521.8575
Epoch [ 456/1800] -> Loss: 1527.7190
Epoch [ 457/1800] -> Loss: 1523.7248
Epoch [ 458/1800] -> Loss: 1527.1520
Epoch [ 459/1800] -> Loss: 1533.7599
Epoch [ 460/1800] -> Loss: 1523.0594
Epoch [ 461/1800] -> Loss: 1524.1926
Epoch [ 462/1800] -> Loss: 1522.3631
Epoch [ 463/1800] -> Loss: 1540.6476
Epoch [ 464/1800] -> Loss: 1522.1254
Epoch [ 465/1800] -> Loss: 1524.2047
Epoch [ 466/1800] -> Loss: 1524.8311
Epoch [ 467/1800] -> Loss: 1523.2415
Epoch [ 468/1800] -> Loss: 1524.9644
Epoch [ 469/1800] -> Loss: 1528.5745
Epoch [ 470/1800] -> Loss: 1521.7782
Epoch [ 471/1800] -> Loss: 1522.5419
Epoch [ 472/1800] -> Loss: 1525.9139
Epoch [ 473/1800] -> Loss: 1524.8117
Epoch [ 474/1800] -> Loss: 1524.2302
Epoch [ 475/1800] -> Loss: 1523.1583
Epoch [ 476/1800] -> Loss: 1522.1414
Epoch [ 477/1800] -> Loss: 1521.7994
Epoch [ 478/1800] -> Loss: 1529.8201
Epoch [ 479/1800] -> Loss: 1523.4487
Epoch [ 480/1800] -> Loss: 1522.2975
Epoch [ 481/1800] -> Loss: 1523.5922
Epoch [ 482/1800] -> Loss: 1524.7590
Epoch [ 483/1800] -> Loss: 1523.7483
Epoch [ 484/1800] -> Loss: 1524.1156
Epoch [ 485/1800] -> Loss: 1525.7198
Epoch [ 486/1800] -> Loss: 1524.7707
Epoch [ 487/1800] -> Loss: 1530.0210
Epoch [ 488/1800] -> Loss: 1522.5621
Epoch [ 489/1800] -> Loss: 1523.2029
Epoch [ 490/1800] -> Loss: 1521.9240
Epoch [ 491/1800] -> Loss: 1522.2597
Epoch [ 492/1800] -> Loss: 1525.3937
Epoch [ 493/1800] -> Loss: 1528.4885
Epoch [ 494/1800] -> Loss: 1521.8497
Epoch [ 495/1800] -> Loss: 1522.9077
Epoch [ 496/1800] -> Loss: 1527.6505
Epoch [ 497/1800] -> Loss: 1525.0388
Epoch [ 498/1800] -> Loss: 1522.0054
Epoch [ 499/1800] -> Loss: 1524.3676
--------------------------------------------------
Model checkpoint saved as FFNN_500.pth
--------------------------------------------------
Epoch [ 500/1800] -> Loss: 1523.7289
Epoch [ 501/1800] -> Loss: 1523.5392
Epoch [ 502/1800] -> Loss: 1522.6474
Epoch [ 503/1800] -> Loss: 1522.2973
Epoch [ 504/1800] -> Loss: 1530.4882
Epoch [ 505/1800] -> Loss: 1531.4457
Epoch [ 506/1800] -> Loss: 1521.8111
Epoch [ 507/1800] -> Loss: 1529.8770
Epoch [ 508/1800] -> Loss: 1522.6457
Epoch [ 509/1800] -> Loss: 1524.4941
Epoch [ 510/1800] -> Loss: 1537.7356
Epoch [ 511/1800] -> Loss: 1549.2743
Epoch [ 512/1800] -> Loss: 1522.2220
Epoch [ 513/1800] -> Loss: 1522.2288
Epoch [ 514/1800] -> Loss: 1525.3071
Epoch [ 515/1800] -> Loss: 1525.3989
Epoch [ 516/1800] -> Loss: 1523.1489
Epoch [ 517/1800] -> Loss: 1523.6510
Epoch [ 518/1800] -> Loss: 1535.8816
Epoch [ 519/1800] -> Loss: 1525.5321
Epoch [ 520/1800] -> Loss: 1523.0081
Epoch [ 521/1800] -> Loss: 1522.6811
Epoch [ 522/1800] -> Loss: 1522.8041
Epoch [ 523/1800] -> Loss: 1523.3652
Epoch [ 524/1800] -> Loss: 1527.7611
Epoch [ 525/1800] -> Loss: 1531.9373
Epoch [ 526/1800] -> Loss: 1540.4651
Epoch [ 527/1800] -> Loss: 1528.5274
Epoch [ 528/1800] -> Loss: 1536.4933
Epoch [ 529/1800] -> Loss: 1522.8180
Epoch [ 530/1800] -> Loss: 1525.0681
Epoch [ 531/1800] -> Loss: 1522.6916
Epoch [ 532/1800] -> Loss: 1526.0803
Epoch [ 533/1800] -> Loss: 1524.7920
Epoch [ 534/1800] -> Loss: 1522.1982
Epoch [ 535/1800] -> Loss: 1521.7024
Epoch [ 536/1800] -> Loss: 1522.4605
Epoch [ 537/1800] -> Loss: 1522.1732
Epoch [ 538/1800] -> Loss: 1526.3231
Epoch [ 539/1800] -> Loss: 1522.2603
Epoch [ 540/1800] -> Loss: 1522.8677
Epoch [ 541/1800] -> Loss: 1521.9305
Epoch [ 542/1800] -> Loss: 1532.5441
Epoch [ 543/1800] -> Loss: 1528.7298
Epoch [ 544/1800] -> Loss: 1523.9700
Epoch [ 545/1800] -> Loss: 1521.7613
Epoch [ 546/1800] -> Loss: 1526.0520
Epoch [ 547/1800] -> Loss: 1522.2553
Epoch [ 548/1800] -> Loss: 1522.3179
Epoch [ 549/1800] -> Loss: 1528.6401
Epoch [ 550/1800] -> Loss: 1524.6401
Epoch [ 551/1800] -> Loss: 1524.7979
Epoch [ 552/1800] -> Loss: 1521.7523
Epoch [ 553/1800] -> Loss: 1521.8291
Epoch [ 554/1800] -> Loss: 1532.4169
Epoch [ 555/1800] -> Loss: 1524.8670
Epoch [ 556/1800] -> Loss: 1522.2592
Epoch [ 557/1800] -> Loss: 1521.9122
Epoch [ 558/1800] -> Loss: 1524.1991
Epoch [ 559/1800] -> Loss: 1527.8809
Epoch [ 560/1800] -> Loss: 1522.9601
Epoch [ 561/1800] -> Loss: 1529.0280
Epoch [ 562/1800] -> Loss: 1523.7524
Epoch [ 563/1800] -> Loss: 1541.1156
Epoch [ 564/1800] -> Loss: 1524.0782
Epoch [ 565/1800] -> Loss: 1526.1153
Epoch [ 566/1800] -> Loss: 1522.4187
Epoch [ 567/1800] -> Loss: 1522.3699
Epoch [ 568/1800] -> Loss: 1527.4808
Epoch [ 569/1800] -> Loss: 1534.8084
Epoch [ 570/1800] -> Loss: 1524.2395
Epoch [ 571/1800] -> Loss: 1533.9719
Epoch [ 572/1800] -> Loss: 1521.7631
Epoch [ 573/1800] -> Loss: 1524.7405
Epoch [ 574/1800] -> Loss: 1525.6843
Epoch [ 575/1800] -> Loss: 1522.9840
Epoch [ 576/1800] -> Loss: 1522.0068
Epoch [ 577/1800] -> Loss: 1523.0048
Epoch [ 578/1800] -> Loss: 1524.4139
Epoch [ 579/1800] -> Loss: 1523.2404
Epoch [ 580/1800] -> Loss: 1524.4323
Epoch [ 581/1800] -> Loss: 1525.7730
Epoch [ 582/1800] -> Loss: 1524.3583
Epoch [ 583/1800] -> Loss: 1526.4094
Epoch [ 584/1800] -> Loss: 1526.4356
Epoch [ 585/1800] -> Loss: 1523.2757
Epoch [ 586/1800] -> Loss: 1522.0831
Epoch [ 587/1800] -> Loss: 1522.8246
Epoch [ 588/1800] -> Loss: 1522.2792
Epoch [ 589/1800] -> Loss: 1523.3996
Epoch [ 590/1800] -> Loss: 1524.4765
Epoch [ 591/1800] -> Loss: 1522.1484
Epoch [ 592/1800] -> Loss: 1525.9327
Epoch [ 593/1800] -> Loss: 1522.1474
Epoch [ 594/1800] -> Loss: 1531.3095
Epoch [ 595/1800] -> Loss: 1531.5528
Epoch [ 596/1800] -> Loss: 1526.2748
Epoch [ 597/1800] -> Loss: 1524.7358
Epoch [ 598/1800] -> Loss: 1521.7904
Epoch [ 599/1800] -> Loss: 1523.1384
--------------------------------------------------
Model checkpoint saved as FFNN_600.pth
--------------------------------------------------
Epoch [ 600/1800] -> Loss: 1522.6068
Epoch [ 601/1800] -> Loss: 1525.0246
Epoch [ 602/1800] -> Loss: 1524.5264
Epoch [ 603/1800] -> Loss: 1529.8841
Epoch [ 604/1800] -> Loss: 1525.7119
Epoch [ 605/1800] -> Loss: 1529.2155
Epoch [ 606/1800] -> Loss: 1525.3039
Epoch [ 607/1800] -> Loss: 1522.6358
Epoch [ 608/1800] -> Loss: 1535.6956
Epoch [ 609/1800] -> Loss: 1524.7181
Epoch [ 610/1800] -> Loss: 1523.4486
Epoch [ 611/1800] -> Loss: 1524.8193
Epoch [ 612/1800] -> Loss: 1521.9719
Epoch [ 613/1800] -> Loss: 1522.4433
Epoch [ 614/1800] -> Loss: 1524.0527
Epoch [ 615/1800] -> Loss: 1525.5333
Epoch [ 616/1800] -> Loss: 1523.4867
Epoch [ 617/1800] -> Loss: 1524.7032
Epoch [ 618/1800] -> Loss: 1528.4466
Epoch [ 619/1800] -> Loss: 1522.1986
Epoch [ 620/1800] -> Loss: 1523.1856
Epoch [ 621/1800] -> Loss: 1527.1545
Epoch [ 622/1800] -> Loss: 1531.2356
Epoch [ 623/1800] -> Loss: 1521.8920
Epoch [ 624/1800] -> Loss: 1522.5435
Epoch [ 625/1800] -> Loss: 1523.0162
Epoch [ 626/1800] -> Loss: 1524.9261
Epoch [ 627/1800] -> Loss: 1534.0603
Epoch [ 628/1800] -> Loss: 1528.2159
Epoch [ 629/1800] -> Loss: 1532.4592
Epoch [ 630/1800] -> Loss: 1533.1952
Epoch [ 631/1800] -> Loss: 1524.4059
Epoch [ 632/1800] -> Loss: 1526.6522
Epoch [ 633/1800] -> Loss: 1526.5043
Epoch [ 634/1800] -> Loss: 1524.8454
Epoch [ 635/1800] -> Loss: 1523.0852
Epoch [ 636/1800] -> Loss: 1529.8246
Epoch [ 637/1800] -> Loss: 1523.9423
Epoch [ 638/1800] -> Loss: 1522.6092
Epoch [ 639/1800] -> Loss: 1524.5081
Epoch [ 640/1800] -> Loss: 1522.8667
Epoch [ 641/1800] -> Loss: 1529.4322
Epoch [ 642/1800] -> Loss: 1522.9448
Epoch [ 643/1800] -> Loss: 1522.1625
Epoch [ 644/1800] -> Loss: 1525.1750
Epoch [ 645/1800] -> Loss: 1522.0139
Epoch [ 646/1800] -> Loss: 1531.7475
Epoch [ 647/1800] -> Loss: 1521.6737
Epoch [ 648/1800] -> Loss: 1529.8981
Epoch [ 649/1800] -> Loss: 1522.2346
Epoch [ 650/1800] -> Loss: 1522.9383
Epoch [ 651/1800] -> Loss: 1526.6236
Epoch [ 652/1800] -> Loss: 1529.6871
Epoch [ 653/1800] -> Loss: 1526.8031
Epoch [ 654/1800] -> Loss: 1522.0455
Epoch [ 655/1800] -> Loss: 1524.4801
Epoch [ 656/1800] -> Loss: 1528.0617
Epoch [ 657/1800] -> Loss: 1522.2143
Epoch [ 658/1800] -> Loss: 1528.3090
Epoch [ 659/1800] -> Loss: 1524.1292
Epoch [ 660/1800] -> Loss: 1524.1743
Epoch [ 661/1800] -> Loss: 1525.4978
Epoch [ 662/1800] -> Loss: 1521.8853
Epoch [ 663/1800] -> Loss: 1525.3743
Epoch [ 664/1800] -> Loss: 1526.4475
Epoch [ 665/1800] -> Loss: 1526.7744
Epoch [ 666/1800] -> Loss: 1523.0603
Epoch [ 667/1800] -> Loss: 1523.3822
Epoch [ 668/1800] -> Loss: 1523.0742
Epoch [ 669/1800] -> Loss: 1523.1474
Epoch [ 670/1800] -> Loss: 1528.0681
Epoch [ 671/1800] -> Loss: 1523.8776
Epoch [ 672/1800] -> Loss: 1527.1375
Epoch [ 673/1800] -> Loss: 1525.3730
Epoch [ 674/1800] -> Loss: 1522.2973
Epoch [ 675/1800] -> Loss: 1524.0575
Epoch [ 676/1800] -> Loss: 1529.4341
Epoch [ 677/1800] -> Loss: 1529.1487
Epoch [ 678/1800] -> Loss: 1522.1132
Epoch [ 679/1800] -> Loss: 1524.0983
Epoch [ 680/1800] -> Loss: 1522.9181
Epoch [ 681/1800] -> Loss: 1527.1857
Epoch [ 682/1800] -> Loss: 1522.0173
Epoch [ 683/1800] -> Loss: 1529.2575
Epoch [ 684/1800] -> Loss: 1541.5707
Epoch [ 685/1800] -> Loss: 1523.0867
Epoch [ 686/1800] -> Loss: 1521.9925
Epoch [ 687/1800] -> Loss: 1527.2022
Epoch [ 688/1800] -> Loss: 1523.9357
Epoch [ 689/1800] -> Loss: 1525.0326
Epoch [ 690/1800] -> Loss: 1522.5556
Epoch [ 691/1800] -> Loss: 1522.2369
Epoch [ 692/1800] -> Loss: 1522.7236
Epoch [ 693/1800] -> Loss: 1523.7568
Epoch [ 694/1800] -> Loss: 1522.9981
Epoch [ 695/1800] -> Loss: 1528.0488
Epoch [ 696/1800] -> Loss: 1523.3034
Epoch [ 697/1800] -> Loss: 1524.0281
Epoch [ 698/1800] -> Loss: 1523.0442
Epoch [ 699/1800] -> Loss: 1525.9962
--------------------------------------------------
Model checkpoint saved as FFNN_700.pth
--------------------------------------------------
Epoch [ 700/1800] -> Loss: 1522.9099
Epoch [ 701/1800] -> Loss: 1529.0168
Epoch [ 702/1800] -> Loss: 1525.4792
Epoch [ 703/1800] -> Loss: 1522.0359
Epoch [ 704/1800] -> Loss: 1522.1663
Epoch [ 705/1800] -> Loss: 1522.4714
Epoch [ 706/1800] -> Loss: 1525.8335
Epoch [ 707/1800] -> Loss: 1524.0972
Epoch [ 708/1800] -> Loss: 1522.4132
Epoch [ 709/1800] -> Loss: 1544.5385
Epoch [ 710/1800] -> Loss: 1522.5918
Epoch [ 711/1800] -> Loss: 1536.9698
Epoch [ 712/1800] -> Loss: 1523.1187
Epoch [ 713/1800] -> Loss: 1536.3391
Epoch [ 714/1800] -> Loss: 1521.6557
Epoch [ 715/1800] -> Loss: 1522.2672
Epoch [ 716/1800] -> Loss: 1527.0081
Epoch [ 717/1800] -> Loss: 1521.6706
Epoch [ 718/1800] -> Loss: 1525.1951
Epoch [ 719/1800] -> Loss: 1522.3316
Epoch [ 720/1800] -> Loss: 1524.5746
Epoch [ 721/1800] -> Loss: 1524.7831
Epoch [ 722/1800] -> Loss: 1522.7074
Epoch [ 723/1800] -> Loss: 1528.4743
Epoch [ 724/1800] -> Loss: 1522.4287
Epoch [ 725/1800] -> Loss: 1526.5654
Epoch [ 726/1800] -> Loss: 1523.0932
Epoch [ 727/1800] -> Loss: 1523.7065
Epoch [ 728/1800] -> Loss: 1525.8969
Epoch [ 729/1800] -> Loss: 1527.2392
Epoch [ 730/1800] -> Loss: 1522.3909
Epoch [ 731/1800] -> Loss: 1521.7525
Epoch [ 732/1800] -> Loss: 1523.2430
Epoch [ 733/1800] -> Loss: 1522.0152
Epoch [ 734/1800] -> Loss: 1533.0659
Epoch [ 735/1800] -> Loss: 1524.3124
Epoch [ 736/1800] -> Loss: 1521.7885
Epoch [ 737/1800] -> Loss: 1522.7802
Epoch [ 738/1800] -> Loss: 1524.4508
Epoch [ 739/1800] -> Loss: 1525.9585
Epoch [ 740/1800] -> Loss: 1523.6490
Epoch [ 741/1800] -> Loss: 1525.5516
Epoch [ 742/1800] -> Loss: 1532.3883
Epoch [ 743/1800] -> Loss: 1523.2312
Epoch [ 744/1800] -> Loss: 1523.4885
Epoch [ 745/1800] -> Loss: 1524.0352
Epoch [ 746/1800] -> Loss: 1522.5413
Epoch [ 747/1800] -> Loss: 1523.3331
Epoch [ 748/1800] -> Loss: 1523.0576
Epoch [ 749/1800] -> Loss: 1540.5077
Epoch [ 750/1800] -> Loss: 1527.6339
Epoch [ 751/1800] -> Loss: 1523.0810
Epoch [ 752/1800] -> Loss: 1536.6575
Epoch [ 753/1800] -> Loss: 1528.1413
Epoch [ 754/1800] -> Loss: 1522.3316
Epoch [ 755/1800] -> Loss: 1522.4163
Epoch [ 756/1800] -> Loss: 1522.9212
Epoch [ 757/1800] -> Loss: 1524.3051
Epoch [ 758/1800] -> Loss: 1522.9747
Epoch [ 759/1800] -> Loss: 1527.5001
Epoch [ 760/1800] -> Loss: 1523.9978
Epoch [ 761/1800] -> Loss: 1523.2714
Epoch [ 762/1800] -> Loss: 1522.4313
Epoch [ 763/1800] -> Loss: 1521.9343
Epoch [ 764/1800] -> Loss: 1525.9401
Epoch [ 765/1800] -> Loss: 1521.6562
Epoch [ 766/1800] -> Loss: 1523.1444
Epoch [ 767/1800] -> Loss: 1522.0197
Epoch [ 768/1800] -> Loss: 1524.9757
Epoch [ 769/1800] -> Loss: 1523.3035
Epoch [ 770/1800] -> Loss: 1526.3688
Epoch [ 771/1800] -> Loss: 1524.2743
Epoch [ 772/1800] -> Loss: 1523.2003
Epoch [ 773/1800] -> Loss: 1524.7018
Epoch [ 774/1800] -> Loss: 1525.0242
Epoch [ 775/1800] -> Loss: 1526.7987
Epoch [ 776/1800] -> Loss: 1532.9122
Epoch [ 777/1800] -> Loss: 1523.9625
Epoch [ 778/1800] -> Loss: 1525.6472
Epoch [ 779/1800] -> Loss: 1525.5952
Epoch [ 780/1800] -> Loss: 1521.7087
Epoch [ 781/1800] -> Loss: 1523.2530
Epoch [ 782/1800] -> Loss: 1524.6102
Epoch [ 783/1800] -> Loss: 1522.2698
Epoch [ 784/1800] -> Loss: 1526.4076
Epoch [ 785/1800] -> Loss: 1524.6967
Epoch [ 786/1800] -> Loss: 1523.8895
Epoch [ 787/1800] -> Loss: 1523.7640
Epoch [ 788/1800] -> Loss: 1529.1303
Epoch [ 789/1800] -> Loss: 1524.7482
Epoch [ 790/1800] -> Loss: 1532.0655
Epoch [ 791/1800] -> Loss: 1521.7264
Epoch [ 792/1800] -> Loss: 1525.3397
Epoch [ 793/1800] -> Loss: 1522.3547
Epoch [ 794/1800] -> Loss: 1523.2770
Epoch [ 795/1800] -> Loss: 1527.8477
Epoch [ 796/1800] -> Loss: 1521.6893
Epoch [ 797/1800] -> Loss: 1523.6130
Epoch [ 798/1800] -> Loss: 1522.7897
Epoch [ 799/1800] -> Loss: 1522.2141
--------------------------------------------------
Model checkpoint saved as FFNN_800.pth
--------------------------------------------------
Epoch [ 800/1800] -> Loss: 1521.8134
Epoch [ 801/1800] -> Loss: 1523.1188
Epoch [ 802/1800] -> Loss: 1525.0527
Epoch [ 803/1800] -> Loss: 1522.8036
Epoch [ 804/1800] -> Loss: 1526.7566
Epoch [ 805/1800] -> Loss: 1532.2582
Epoch [ 806/1800] -> Loss: 1524.1221
Epoch [ 807/1800] -> Loss: 1522.3193
Epoch [ 808/1800] -> Loss: 1529.0027
Epoch [ 809/1800] -> Loss: 1523.3233
Epoch [ 810/1800] -> Loss: 1524.0110
Epoch [ 811/1800] -> Loss: 1522.9019
Epoch [ 812/1800] -> Loss: 1526.5983
Epoch [ 813/1800] -> Loss: 1523.0494
Epoch [ 814/1800] -> Loss: 1522.3927
Epoch [ 815/1800] -> Loss: 1522.0910
Epoch [ 816/1800] -> Loss: 1522.0533
Epoch [ 817/1800] -> Loss: 1527.2832
Epoch [ 818/1800] -> Loss: 1529.1206
Epoch [ 819/1800] -> Loss: 1525.7739
Epoch [ 820/1800] -> Loss: 1526.9711
Epoch [ 821/1800] -> Loss: 1523.3818
Epoch [ 822/1800] -> Loss: 1532.4252
Epoch [ 823/1800] -> Loss: 1527.3148
Epoch [ 824/1800] -> Loss: 1523.7026
Epoch [ 825/1800] -> Loss: 1529.5674
Epoch [ 826/1800] -> Loss: 1522.5053
Epoch [ 827/1800] -> Loss: 1523.3326
Epoch [ 828/1800] -> Loss: 1526.4166
Epoch [ 829/1800] -> Loss: 1523.4176
Epoch [ 830/1800] -> Loss: 1522.9158
Epoch [ 831/1800] -> Loss: 1524.0170
Epoch [ 832/1800] -> Loss: 1522.3584
Epoch [ 833/1800] -> Loss: 1522.1154
Epoch [ 834/1800] -> Loss: 1523.1054
Epoch [ 835/1800] -> Loss: 1522.0061
Epoch [ 836/1800] -> Loss: 1524.5768
Epoch [ 837/1800] -> Loss: 1523.1717
Epoch [ 838/1800] -> Loss: 1523.3199
Epoch [ 839/1800] -> Loss: 1526.2328
Epoch [ 840/1800] -> Loss: 1522.8253
Epoch [ 841/1800] -> Loss: 1521.7678
Epoch [ 842/1800] -> Loss: 1527.0432
Epoch [ 843/1800] -> Loss: 1523.3459
Epoch [ 844/1800] -> Loss: 1522.9769
Epoch [ 845/1800] -> Loss: 1523.7035
Epoch [ 846/1800] -> Loss: 1529.6959
Epoch [ 847/1800] -> Loss: 1523.1037
Epoch [ 848/1800] -> Loss: 1527.3176
Epoch [ 849/1800] -> Loss: 1522.9177
Epoch [ 850/1800] -> Loss: 1523.6896
Epoch [ 851/1800] -> Loss: 1523.4724
Epoch [ 852/1800] -> Loss: 1527.3749
Epoch [ 853/1800] -> Loss: 1526.6861
Epoch [ 854/1800] -> Loss: 1522.0637
Epoch [ 855/1800] -> Loss: 1526.0377
Epoch [ 856/1800] -> Loss: 1521.9240
Epoch [ 857/1800] -> Loss: 1523.3658
Epoch [ 858/1800] -> Loss: 1528.1854
Epoch [ 859/1800] -> Loss: 1521.6718
Epoch [ 860/1800] -> Loss: 1522.5540
Epoch [ 861/1800] -> Loss: 1521.7900
Epoch [ 862/1800] -> Loss: 1522.2042
Epoch [ 863/1800] -> Loss: 1521.6674
Epoch [ 864/1800] -> Loss: 1521.8695
Epoch [ 865/1800] -> Loss: 1523.8060
Epoch [ 866/1800] -> Loss: 1521.9603
Epoch [ 867/1800] -> Loss: 1525.8393
Epoch [ 868/1800] -> Loss: 1539.7201
Epoch [ 869/1800] -> Loss: 1523.2455
Epoch [ 870/1800] -> Loss: 1523.2048
Epoch [ 871/1800] -> Loss: 1522.6579
Epoch [ 872/1800] -> Loss: 1525.8964
Epoch [ 873/1800] -> Loss: 1522.0276
Epoch [ 874/1800] -> Loss: 1523.3308
Epoch [ 875/1800] -> Loss: 1524.7725
Epoch [ 876/1800] -> Loss: 1524.8862
Epoch [ 877/1800] -> Loss: 1535.8601
Epoch [ 878/1800] -> Loss: 1523.5588
Epoch [ 879/1800] -> Loss: 1524.3728
Epoch [ 880/1800] -> Loss: 1522.4020
Epoch [ 881/1800] -> Loss: 1521.7121
Epoch [ 882/1800] -> Loss: 1521.9456
Epoch [ 883/1800] -> Loss: 1531.0395
Epoch [ 884/1800] -> Loss: 1524.6500
Epoch [ 885/1800] -> Loss: 1522.4641
Epoch [ 886/1800] -> Loss: 1523.7118
Epoch [ 887/1800] -> Loss: 1522.0555
Epoch [ 888/1800] -> Loss: 1522.7411
Epoch [ 889/1800] -> Loss: 1523.2502
Epoch [ 890/1800] -> Loss: 1525.3463
Epoch [ 891/1800] -> Loss: 1523.5170
Epoch [ 892/1800] -> Loss: 1521.7163
Epoch [ 893/1800] -> Loss: 1522.8188
Epoch [ 894/1800] -> Loss: 1525.9742
Epoch [ 895/1800] -> Loss: 1523.1323
Epoch [ 896/1800] -> Loss: 1526.4695
Epoch [ 897/1800] -> Loss: 1522.3364
Epoch [ 898/1800] -> Loss: 1529.1323
Epoch [ 899/1800] -> Loss: 1523.5736
--------------------------------------------------
Model checkpoint saved as FFNN_900.pth
--------------------------------------------------
Epoch [ 900/1800] -> Loss: 1522.0448
Epoch [ 901/1800] -> Loss: 1522.5473
Epoch [ 902/1800] -> Loss: 1521.6508
Epoch [ 903/1800] -> Loss: 1524.9310
Epoch [ 904/1800] -> Loss: 1523.6037
Epoch [ 905/1800] -> Loss: 1526.1446
Epoch [ 906/1800] -> Loss: 1529.3945
Epoch [ 907/1800] -> Loss: 1521.9539
Epoch [ 908/1800] -> Loss: 1521.9900
Epoch [ 909/1800] -> Loss: 1526.6954
Epoch [ 910/1800] -> Loss: 1531.4143
Epoch [ 911/1800] -> Loss: 1524.9232
Epoch [ 912/1800] -> Loss: 1524.7635
Epoch [ 913/1800] -> Loss: 1530.9439
Epoch [ 914/1800] -> Loss: 1524.9464
Epoch [ 915/1800] -> Loss: 1524.7882
Epoch [ 916/1800] -> Loss: 1524.7343
Epoch [ 917/1800] -> Loss: 1521.8667
Epoch [ 918/1800] -> Loss: 1523.0278
Epoch [ 919/1800] -> Loss: 1524.3042
Epoch [ 920/1800] -> Loss: 1522.2914
Epoch [ 921/1800] -> Loss: 1524.8140
Epoch [ 922/1800] -> Loss: 1521.7602
Epoch [ 923/1800] -> Loss: 1522.4651
Epoch [ 924/1800] -> Loss: 1521.7601
Epoch [ 925/1800] -> Loss: 1523.6879
Epoch [ 926/1800] -> Loss: 1524.8655
Epoch [ 927/1800] -> Loss: 1524.3655
Epoch [ 928/1800] -> Loss: 1521.7785
Epoch [ 929/1800] -> Loss: 1526.5199
Epoch [ 930/1800] -> Loss: 1526.3586
Epoch [ 931/1800] -> Loss: 1524.2727
Epoch [ 932/1800] -> Loss: 1525.8986
Epoch [ 933/1800] -> Loss: 1526.4082
Epoch [ 934/1800] -> Loss: 1521.6493
Epoch [ 935/1800] -> Loss: 1529.3690
Epoch [ 936/1800] -> Loss: 1522.6684
Epoch [ 937/1800] -> Loss: 1524.4619
Epoch [ 938/1800] -> Loss: 1524.7021
Epoch [ 939/1800] -> Loss: 1522.7781
Epoch [ 940/1800] -> Loss: 1524.8750
Epoch [ 941/1800] -> Loss: 1522.0961
Epoch [ 942/1800] -> Loss: 1522.5096
Epoch [ 943/1800] -> Loss: 1524.0931
Epoch [ 944/1800] -> Loss: 1534.0217
Epoch [ 945/1800] -> Loss: 1522.5278
Epoch [ 946/1800] -> Loss: 1524.6240
Epoch [ 947/1800] -> Loss: 1521.9393
Epoch [ 948/1800] -> Loss: 1522.8040
Epoch [ 949/1800] -> Loss: 1528.8136
Epoch [ 950/1800] -> Loss: 1521.8525
Epoch [ 951/1800] -> Loss: 1527.8676
Epoch [ 952/1800] -> Loss: 1524.2038
Epoch [ 953/1800] -> Loss: 1521.6615
Epoch [ 954/1800] -> Loss: 1527.6393
Epoch [ 955/1800] -> Loss: 1525.2227
Epoch [ 956/1800] -> Loss: 1530.5545
Epoch [ 957/1800] -> Loss: 1525.0360
Epoch [ 958/1800] -> Loss: 1523.1238
Epoch [ 959/1800] -> Loss: 1521.9554
Epoch [ 960/1800] -> Loss: 1524.0741
Epoch [ 961/1800] -> Loss: 1522.0291
Epoch [ 962/1800] -> Loss: 1528.5381
Epoch [ 963/1800] -> Loss: 1524.3702
Epoch [ 964/1800] -> Loss: 1525.4064
Epoch [ 965/1800] -> Loss: 1524.3520
Epoch [ 966/1800] -> Loss: 1524.1637
Epoch [ 967/1800] -> Loss: 1529.5013
Epoch [ 968/1800] -> Loss: 1523.1977
Epoch [ 969/1800] -> Loss: 1542.0149
Epoch [ 970/1800] -> Loss: 1524.1866
Epoch [ 971/1800] -> Loss: 1522.8104
Epoch [ 972/1800] -> Loss: 1524.3798
Epoch [ 973/1800] -> Loss: 1528.0098
Epoch [ 974/1800] -> Loss: 1522.6216
Epoch [ 975/1800] -> Loss: 1523.8859
Epoch [ 976/1800] -> Loss: 1524.3931
Epoch [ 977/1800] -> Loss: 1521.9168
Epoch [ 978/1800] -> Loss: 1523.7422
Epoch [ 979/1800] -> Loss: 1522.1764
Epoch [ 980/1800] -> Loss: 1525.9171
Epoch [ 981/1800] -> Loss: 1522.3436
Epoch [ 982/1800] -> Loss: 1522.8016
Epoch [ 983/1800] -> Loss: 1523.2812
Epoch [ 984/1800] -> Loss: 1526.1908
Epoch [ 985/1800] -> Loss: 1525.5958
Epoch [ 986/1800] -> Loss: 1523.6087
Epoch [ 987/1800] -> Loss: 1525.1197
Epoch [ 988/1800] -> Loss: 1524.8881
Epoch [ 989/1800] -> Loss: 1521.8543
Epoch [ 990/1800] -> Loss: 1521.9819
Epoch [ 991/1800] -> Loss: 1521.7404
Epoch [ 992/1800] -> Loss: 1526.5511
Epoch [ 993/1800] -> Loss: 1524.5118
Epoch [ 994/1800] -> Loss: 1528.1026
Epoch [ 995/1800] -> Loss: 1524.3367
Epoch [ 996/1800] -> Loss: 1527.0876
Epoch [ 997/1800] -> Loss: 1521.7722
Epoch [ 998/1800] -> Loss: 1521.8192
Epoch [ 999/1800] -> Loss: 1521.7409
--------------------------------------------------
Model checkpoint saved as FFNN_1000.pth
--------------------------------------------------
Epoch [1000/1800] -> Loss: 1522.4561
Epoch [1001/1800] -> Loss: 1523.5939
Epoch [1002/1800] -> Loss: 1521.9898
Epoch [1003/1800] -> Loss: 1527.7594
Epoch [1004/1800] -> Loss: 1527.7775
Epoch [1005/1800] -> Loss: 1523.3805
Epoch [1006/1800] -> Loss: 1522.1877
Epoch [1007/1800] -> Loss: 1532.4863
Epoch [1008/1800] -> Loss: 1524.0492
Epoch [1009/1800] -> Loss: 1522.3776
Epoch [1010/1800] -> Loss: 1531.1080
Epoch [1011/1800] -> Loss: 1534.1162
Epoch [1012/1800] -> Loss: 1523.3591
Epoch [1013/1800] -> Loss: 1522.4759
Epoch [1014/1800] -> Loss: 1523.2290
Epoch [1015/1800] -> Loss: 1523.1232
Epoch [1016/1800] -> Loss: 1522.0825
Epoch [1017/1800] -> Loss: 1526.0301
Epoch [1018/1800] -> Loss: 1523.5235
Epoch [1019/1800] -> Loss: 1521.9194
Epoch [1020/1800] -> Loss: 1524.5983
Epoch [1021/1800] -> Loss: 1540.9717
Epoch [1022/1800] -> Loss: 1524.0293
Epoch [1023/1800] -> Loss: 1523.2607
Epoch [1024/1800] -> Loss: 1539.6691
Epoch [1025/1800] -> Loss: 1523.8330
Epoch [1026/1800] -> Loss: 1525.4826
Epoch [1027/1800] -> Loss: 1524.5555
Epoch [1028/1800] -> Loss: 1521.9621
Epoch [1029/1800] -> Loss: 1526.1814
Epoch [1030/1800] -> Loss: 1523.8112
Epoch [1031/1800] -> Loss: 1525.6692
Epoch [1032/1800] -> Loss: 1524.4858
Epoch [1033/1800] -> Loss: 1522.9140
Epoch [1034/1800] -> Loss: 1524.0720
Epoch [1035/1800] -> Loss: 1522.2951
Epoch [1036/1800] -> Loss: 1527.1531
Epoch [1037/1800] -> Loss: 1524.8322
Epoch [1038/1800] -> Loss: 1524.3828
Epoch [1039/1800] -> Loss: 1524.6092
Epoch [1040/1800] -> Loss: 1524.3248
Epoch [1041/1800] -> Loss: 1524.0633
Epoch [1042/1800] -> Loss: 1539.9335
Epoch [1043/1800] -> Loss: 1526.3540
Epoch [1044/1800] -> Loss: 1523.6065
Epoch [1045/1800] -> Loss: 1539.2637
Epoch [1046/1800] -> Loss: 1523.0670
Epoch [1047/1800] -> Loss: 1524.2052
Epoch [1048/1800] -> Loss: 1524.8995
Epoch [1049/1800] -> Loss: 1522.3783
Epoch [1050/1800] -> Loss: 1523.6347
Epoch [1051/1800] -> Loss: 1527.4754
Epoch [1052/1800] -> Loss: 1532.7710
Epoch [1053/1800] -> Loss: 1522.0336
Epoch [1054/1800] -> Loss: 1524.6126
Epoch [1055/1800] -> Loss: 1527.1111
Epoch [1056/1800] -> Loss: 1524.8545
Epoch [1057/1800] -> Loss: 1526.3479
Epoch [1058/1800] -> Loss: 1521.8441
Epoch [1059/1800] -> Loss: 1524.0755
Epoch [1060/1800] -> Loss: 1522.8194
Epoch [1061/1800] -> Loss: 1528.5177
Epoch [1062/1800] -> Loss: 1521.9009
Epoch [1063/1800] -> Loss: 1524.3278
Epoch [1064/1800] -> Loss: 1523.3231
Epoch [1065/1800] -> Loss: 1523.6880
Epoch [1066/1800] -> Loss: 1524.1894
Epoch [1067/1800] -> Loss: 1522.1414
Epoch [1068/1800] -> Loss: 1524.1981
Epoch [1069/1800] -> Loss: 1521.8946
Epoch [1070/1800] -> Loss: 1523.3295
Epoch [1071/1800] -> Loss: 1523.5887
Epoch [1072/1800] -> Loss: 1522.7573
Epoch [1073/1800] -> Loss: 1527.1185
Epoch [1074/1800] -> Loss: 1522.6020
Epoch [1075/1800] -> Loss: 1523.9683
Epoch [1076/1800] -> Loss: 1531.2673
Epoch [1077/1800] -> Loss: 1524.1843
Epoch [1078/1800] -> Loss: 1528.2471
Epoch [1079/1800] -> Loss: 1526.2644
Epoch [1080/1800] -> Loss: 1526.4377
Epoch [1081/1800] -> Loss: 1523.7178
Epoch [1082/1800] -> Loss: 1522.2322
Epoch [1083/1800] -> Loss: 1524.6111
Epoch [1084/1800] -> Loss: 1521.8111
Epoch [1085/1800] -> Loss: 1524.6459
Epoch [1086/1800] -> Loss: 1522.5350
Epoch [1087/1800] -> Loss: 1522.3552
Epoch [1088/1800] -> Loss: 1527.3817
Epoch [1089/1800] -> Loss: 1533.5717
Epoch [1090/1800] -> Loss: 1521.8960
Epoch [1091/1800] -> Loss: 1522.6455
Epoch [1092/1800] -> Loss: 1534.1542
Epoch [1093/1800] -> Loss: 1525.1710
Epoch [1094/1800] -> Loss: 1530.3100
Epoch [1095/1800] -> Loss: 1521.8102
Epoch [1096/1800] -> Loss: 1524.9606
Epoch [1097/1800] -> Loss: 1526.1862
Epoch [1098/1800] -> Loss: 1528.2800
Epoch [1099/1800] -> Loss: 1522.9512
--------------------------------------------------
Model checkpoint saved as FFNN_1100.pth
--------------------------------------------------
Epoch [1100/1800] -> Loss: 1525.6083
Epoch [1101/1800] -> Loss: 1524.6662
Epoch [1102/1800] -> Loss: 1523.8749
Epoch [1103/1800] -> Loss: 1521.6358
Epoch [1104/1800] -> Loss: 1524.5255
Epoch [1105/1800] -> Loss: 1526.1671
Epoch [1106/1800] -> Loss: 1522.2328
Epoch [1107/1800] -> Loss: 1523.7200
Epoch [1108/1800] -> Loss: 1524.2798
Epoch [1109/1800] -> Loss: 1524.3226
Epoch [1110/1800] -> Loss: 1523.1994
Epoch [1111/1800] -> Loss: 1523.1398
Epoch [1112/1800] -> Loss: 1523.4019
Epoch [1113/1800] -> Loss: 1522.2624
Epoch [1114/1800] -> Loss: 1524.8318
Epoch [1115/1800] -> Loss: 1530.0456
Epoch [1116/1800] -> Loss: 1521.6762
Epoch [1117/1800] -> Loss: 1525.6207
Epoch [1118/1800] -> Loss: 1527.5782
Epoch [1119/1800] -> Loss: 1524.4767
Epoch [1120/1800] -> Loss: 1526.3287
Epoch [1121/1800] -> Loss: 1523.5640
Epoch [1122/1800] -> Loss: 1524.6408
Epoch [1123/1800] -> Loss: 1523.4518
Epoch [1124/1800] -> Loss: 1529.6108
Epoch [1125/1800] -> Loss: 1523.6226
Epoch [1126/1800] -> Loss: 1523.9457
Epoch [1127/1800] -> Loss: 1542.5439
Epoch [1128/1800] -> Loss: 1529.0473
Epoch [1129/1800] -> Loss: 1522.6174
Epoch [1130/1800] -> Loss: 1523.2185
Epoch [1131/1800] -> Loss: 1521.7431
Epoch [1132/1800] -> Loss: 1530.4647
Epoch [1133/1800] -> Loss: 1523.3454
Epoch [1134/1800] -> Loss: 1522.8110
Epoch [1135/1800] -> Loss: 1524.8377
Epoch [1136/1800] -> Loss: 1526.9920
Epoch [1137/1800] -> Loss: 1522.0008
Epoch [1138/1800] -> Loss: 1524.6802
Epoch [1139/1800] -> Loss: 1522.7976
Epoch [1140/1800] -> Loss: 1523.1206
Epoch [1141/1800] -> Loss: 1523.6505
Epoch [1142/1800] -> Loss: 1529.3815
Epoch [1143/1800] -> Loss: 1523.3854
Epoch [1144/1800] -> Loss: 1522.9587
Epoch [1145/1800] -> Loss: 1522.2157
Epoch [1146/1800] -> Loss: 1534.1208
Epoch [1147/1800] -> Loss: 1524.3854
Epoch [1148/1800] -> Loss: 1527.6485
Epoch [1149/1800] -> Loss: 1531.6380
Epoch [1150/1800] -> Loss: 1522.3442
Epoch [1151/1800] -> Loss: 1522.7896
Epoch [1152/1800] -> Loss: 1523.4537
Epoch [1153/1800] -> Loss: 1524.1421
Epoch [1154/1800] -> Loss: 1533.6480
Epoch [1155/1800] -> Loss: 1524.4211
Epoch [1156/1800] -> Loss: 1523.8509
Epoch [1157/1800] -> Loss: 1523.6402
Epoch [1158/1800] -> Loss: 1523.0661
Epoch [1159/1800] -> Loss: 1529.8308
Epoch [1160/1800] -> Loss: 1523.6547
Epoch [1161/1800] -> Loss: 1529.9807
Epoch [1162/1800] -> Loss: 1522.0526
Epoch [1163/1800] -> Loss: 1521.7785
Epoch [1164/1800] -> Loss: 1524.5594
Epoch [1165/1800] -> Loss: 1522.2741
Epoch [1166/1800] -> Loss: 1528.2786
Epoch [1167/1800] -> Loss: 1525.1264
Epoch [1168/1800] -> Loss: 1522.7383
Epoch [1169/1800] -> Loss: 1529.9840
Epoch [1170/1800] -> Loss: 1531.3437
Epoch [1171/1800] -> Loss: 1526.2565
Epoch [1172/1800] -> Loss: 1523.3896
Epoch [1173/1800] -> Loss: 1522.2224
Epoch [1174/1800] -> Loss: 1523.5065
Epoch [1175/1800] -> Loss: 1522.5026
Epoch [1176/1800] -> Loss: 1522.0276
Epoch [1177/1800] -> Loss: 1521.8745
Epoch [1178/1800] -> Loss: 1522.6764
Epoch [1179/1800] -> Loss: 1523.6188
Epoch [1180/1800] -> Loss: 1522.1569
Epoch [1181/1800] -> Loss: 1522.6851
Epoch [1182/1800] -> Loss: 1528.4504
Epoch [1183/1800] -> Loss: 1524.5540
Epoch [1184/1800] -> Loss: 1523.5406
Epoch [1185/1800] -> Loss: 1522.6871
Epoch [1186/1800] -> Loss: 1524.8638
Epoch [1187/1800] -> Loss: 1524.6197
Epoch [1188/1800] -> Loss: 1524.8101
Epoch [1189/1800] -> Loss: 1522.6163
Epoch [1190/1800] -> Loss: 1525.1504
Epoch [1191/1800] -> Loss: 1521.7093
Epoch [1192/1800] -> Loss: 1522.6985
Epoch [1193/1800] -> Loss: 1527.0557
Epoch [1194/1800] -> Loss: 1524.8368
Epoch [1195/1800] -> Loss: 1527.2815
Epoch [1196/1800] -> Loss: 1522.2223
Epoch [1197/1800] -> Loss: 1524.2486
Epoch [1198/1800] -> Loss: 1523.1195
Epoch [1199/1800] -> Loss: 1529.2931
--------------------------------------------------
Model checkpoint saved as FFNN_1200.pth
--------------------------------------------------
Epoch [1200/1800] -> Loss: 1521.8393
Epoch [1201/1800] -> Loss: 1522.7541
Epoch [1202/1800] -> Loss: 1526.1225
Epoch [1203/1800] -> Loss: 1522.3324
Epoch [1204/1800] -> Loss: 1524.5481
Epoch [1205/1800] -> Loss: 1522.1166
Epoch [1206/1800] -> Loss: 1521.8815
Epoch [1207/1800] -> Loss: 1529.6669
Epoch [1208/1800] -> Loss: 1522.0145
Epoch [1209/1800] -> Loss: 1521.9725
Epoch [1210/1800] -> Loss: 1523.0452
Epoch [1211/1800] -> Loss: 1523.1013
Epoch [1212/1800] -> Loss: 1524.5101
Epoch [1213/1800] -> Loss: 1522.9673
Epoch [1214/1800] -> Loss: 1525.7325
Epoch [1215/1800] -> Loss: 1522.4825
Epoch [1216/1800] -> Loss: 1524.2422
Epoch [1217/1800] -> Loss: 1524.8699
Epoch [1218/1800] -> Loss: 1522.6630
Epoch [1219/1800] -> Loss: 1524.9516
Epoch [1220/1800] -> Loss: 1523.3913
Epoch [1221/1800] -> Loss: 1531.3602
Epoch [1222/1800] -> Loss: 1521.7203
Epoch [1223/1800] -> Loss: 1521.8756
Epoch [1224/1800] -> Loss: 1542.0483
Epoch [1225/1800] -> Loss: 1523.7197
Epoch [1226/1800] -> Loss: 1525.6584
Epoch [1227/1800] -> Loss: 1523.6523
Epoch [1228/1800] -> Loss: 1522.4869
Epoch [1229/1800] -> Loss: 1522.7390
Epoch [1230/1800] -> Loss: 1526.8681
Epoch [1231/1800] -> Loss: 1525.5724
Epoch [1232/1800] -> Loss: 1524.7101
Epoch [1233/1800] -> Loss: 1529.6969
Epoch [1234/1800] -> Loss: 1523.8645
Epoch [1235/1800] -> Loss: 1530.5189
Epoch [1236/1800] -> Loss: 1525.7337
Epoch [1237/1800] -> Loss: 1523.0132
Epoch [1238/1800] -> Loss: 1524.2797
Epoch [1239/1800] -> Loss: 1522.1920
Epoch [1240/1800] -> Loss: 1525.6600
Epoch [1241/1800] -> Loss: 1523.1834
Epoch [1242/1800] -> Loss: 1522.3804
Epoch [1243/1800] -> Loss: 1532.0427
Epoch [1244/1800] -> Loss: 1524.4088
Epoch [1245/1800] -> Loss: 1522.5293
Epoch [1246/1800] -> Loss: 1522.9581
Epoch [1247/1800] -> Loss: 1526.3782
Epoch [1248/1800] -> Loss: 1524.8549
Epoch [1249/1800] -> Loss: 1528.2158
Epoch [1250/1800] -> Loss: 1522.4550
Epoch [1251/1800] -> Loss: 1521.8441
Epoch [1252/1800] -> Loss: 1521.8241
Epoch [1253/1800] -> Loss: 1523.6129
Epoch [1254/1800] -> Loss: 1524.2030
Epoch [1255/1800] -> Loss: 1522.0545
Epoch [1256/1800] -> Loss: 1528.9668
Epoch [1257/1800] -> Loss: 1522.2358
Epoch [1258/1800] -> Loss: 1524.4529
Epoch [1259/1800] -> Loss: 1524.0029
Epoch [1260/1800] -> Loss: 1522.9904
Epoch [1261/1800] -> Loss: 1521.8782
Epoch [1262/1800] -> Loss: 1521.7789
Epoch [1263/1800] -> Loss: 1530.1589
Epoch [1264/1800] -> Loss: 1524.3962
Epoch [1265/1800] -> Loss: 1521.9743
Epoch [1266/1800] -> Loss: 1527.3686
Epoch [1267/1800] -> Loss: 1524.5397
Epoch [1268/1800] -> Loss: 1528.1447
Epoch [1269/1800] -> Loss: 1525.1275
Epoch [1270/1800] -> Loss: 1522.8814
Epoch [1271/1800] -> Loss: 1522.2779
Epoch [1272/1800] -> Loss: 1522.9188
Epoch [1273/1800] -> Loss: 1526.2116
Epoch [1274/1800] -> Loss: 1522.3482
Epoch [1275/1800] -> Loss: 1525.5879
Epoch [1276/1800] -> Loss: 1525.3803
Epoch [1277/1800] -> Loss: 1522.3750
Epoch [1278/1800] -> Loss: 1522.4091
Epoch [1279/1800] -> Loss: 1528.4525
Epoch [1280/1800] -> Loss: 1521.6909
Epoch [1281/1800] -> Loss: 1525.0374
Epoch [1282/1800] -> Loss: 1524.6516
Epoch [1283/1800] -> Loss: 1522.9906
Epoch [1284/1800] -> Loss: 1526.1756
Epoch [1285/1800] -> Loss: 1526.4963
Epoch [1286/1800] -> Loss: 1527.8627
Epoch [1287/1800] -> Loss: 1523.4316
Epoch [1288/1800] -> Loss: 1522.9958
Epoch [1289/1800] -> Loss: 1523.0471
Epoch [1290/1800] -> Loss: 1522.2881
Epoch [1291/1800] -> Loss: 1521.6800
Epoch [1292/1800] -> Loss: 1547.6763
Epoch [1293/1800] -> Loss: 1522.9127
Epoch [1294/1800] -> Loss: 1522.9972
Epoch [1295/1800] -> Loss: 1522.2679
Epoch [1296/1800] -> Loss: 1522.2396
Epoch [1297/1800] -> Loss: 1523.0679
Epoch [1298/1800] -> Loss: 1524.0712
Epoch [1299/1800] -> Loss: 1523.6766
--------------------------------------------------
Model checkpoint saved as FFNN_1300.pth
--------------------------------------------------
Epoch [1300/1800] -> Loss: 1525.0986
Epoch [1301/1800] -> Loss: 1523.1826
Epoch [1302/1800] -> Loss: 1524.4849
Epoch [1303/1800] -> Loss: 1521.7762
Epoch [1304/1800] -> Loss: 1525.7095
Epoch [1305/1800] -> Loss: 1528.7514
Epoch [1306/1800] -> Loss: 1522.4590
Epoch [1307/1800] -> Loss: 1521.6291
Epoch [1308/1800] -> Loss: 1523.9851
Epoch [1309/1800] -> Loss: 1531.5082
Epoch [1310/1800] -> Loss: 1522.8898
Epoch [1311/1800] -> Loss: 1521.7774
Epoch [1312/1800] -> Loss: 1532.6544
Epoch [1313/1800] -> Loss: 1526.1305
Epoch [1314/1800] -> Loss: 1529.1638
Epoch [1315/1800] -> Loss: 1531.9981
Epoch [1316/1800] -> Loss: 1526.3626
Epoch [1317/1800] -> Loss: 1523.8384
Epoch [1318/1800] -> Loss: 1521.9418
Epoch [1319/1800] -> Loss: 1523.0835
Epoch [1320/1800] -> Loss: 1522.0606
Epoch [1321/1800] -> Loss: 1522.5031
Epoch [1322/1800] -> Loss: 1525.1904
Epoch [1323/1800] -> Loss: 1523.2825
Epoch [1324/1800] -> Loss: 1522.5777
Epoch [1325/1800] -> Loss: 1522.4178
Epoch [1326/1800] -> Loss: 1522.8520
Epoch [1327/1800] -> Loss: 1522.5986
Epoch [1328/1800] -> Loss: 1521.8588
Epoch [1329/1800] -> Loss: 1525.1821
Epoch [1330/1800] -> Loss: 1527.5210
Epoch [1331/1800] -> Loss: 1521.9502
Epoch [1332/1800] -> Loss: 1523.8932
Epoch [1333/1800] -> Loss: 1523.6845
Epoch [1334/1800] -> Loss: 1522.6118
Epoch [1335/1800] -> Loss: 1527.5730
Epoch [1336/1800] -> Loss: 1526.6889
Epoch [1337/1800] -> Loss: 1523.8457
Epoch [1338/1800] -> Loss: 1525.5896
Epoch [1339/1800] -> Loss: 1523.1908
Epoch [1340/1800] -> Loss: 1522.8264
Epoch [1341/1800] -> Loss: 1528.4297
Epoch [1342/1800] -> Loss: 1525.7244
Epoch [1343/1800] -> Loss: 1523.3248
Epoch [1344/1800] -> Loss: 1524.4599
Epoch [1345/1800] -> Loss: 1526.6171
Epoch [1346/1800] -> Loss: 1523.0966
Epoch [1347/1800] -> Loss: 1523.0772
Epoch [1348/1800] -> Loss: 1522.8962
Epoch [1349/1800] -> Loss: 1523.4552
Epoch [1350/1800] -> Loss: 1525.6635
Epoch [1351/1800] -> Loss: 1524.5105
Epoch [1352/1800] -> Loss: 1523.8041
Epoch [1353/1800] -> Loss: 1524.0696
Epoch [1354/1800] -> Loss: 1522.8779
Epoch [1355/1800] -> Loss: 1532.0058
Epoch [1356/1800] -> Loss: 1530.5866
Epoch [1357/1800] -> Loss: 1528.3609
Epoch [1358/1800] -> Loss: 1528.1954
Epoch [1359/1800] -> Loss: 1533.4678
Epoch [1360/1800] -> Loss: 1527.4519
Epoch [1361/1800] -> Loss: 1523.3443
Epoch [1362/1800] -> Loss: 1526.6195
Epoch [1363/1800] -> Loss: 1522.5707
Epoch [1364/1800] -> Loss: 1522.1130
Epoch [1365/1800] -> Loss: 1523.4187
Epoch [1366/1800] -> Loss: 1523.0908
Epoch [1367/1800] -> Loss: 1522.2288
Epoch [1368/1800] -> Loss: 1529.6120
Epoch [1369/1800] -> Loss: 1523.5368
Epoch [1370/1800] -> Loss: 1527.2737
Epoch [1371/1800] -> Loss: 1527.1308
Epoch [1372/1800] -> Loss: 1525.7789
Epoch [1373/1800] -> Loss: 1521.8728
Epoch [1374/1800] -> Loss: 1526.5166
Epoch [1375/1800] -> Loss: 1523.7165
Epoch [1376/1800] -> Loss: 1521.7904
Epoch [1377/1800] -> Loss: 1533.2804
Epoch [1378/1800] -> Loss: 1522.2677
Epoch [1379/1800] -> Loss: 1525.9043
Epoch [1380/1800] -> Loss: 1526.1575
Epoch [1381/1800] -> Loss: 1529.4062
Epoch [1382/1800] -> Loss: 1522.3898
Epoch [1383/1800] -> Loss: 1521.6976
Epoch [1384/1800] -> Loss: 1522.1113
Epoch [1385/1800] -> Loss: 1521.8495
Epoch [1386/1800] -> Loss: 1522.3334
Epoch [1387/1800] -> Loss: 1527.5385
Epoch [1388/1800] -> Loss: 1531.0326
Epoch [1389/1800] -> Loss: 1524.6953
Epoch [1390/1800] -> Loss: 1532.1341
Epoch [1391/1800] -> Loss: 1526.4410
Epoch [1392/1800] -> Loss: 1528.5901
Epoch [1393/1800] -> Loss: 1523.3850
Epoch [1394/1800] -> Loss: 1523.3842
Epoch [1395/1800] -> Loss: 1524.6559
Epoch [1396/1800] -> Loss: 1529.1290
Epoch [1397/1800] -> Loss: 1525.6044
Epoch [1398/1800] -> Loss: 1523.2707
Epoch [1399/1800] -> Loss: 1522.4392
--------------------------------------------------
Model checkpoint saved as FFNN_1400.pth
--------------------------------------------------
Epoch [1400/1800] -> Loss: 1522.7292
Epoch [1401/1800] -> Loss: 1522.4116
Epoch [1402/1800] -> Loss: 1530.6546
Epoch [1403/1800] -> Loss: 1522.5577
Epoch [1404/1800] -> Loss: 1529.0849
Epoch [1405/1800] -> Loss: 1521.8913
Epoch [1406/1800] -> Loss: 1531.6619
Epoch [1407/1800] -> Loss: 1522.9946
Epoch [1408/1800] -> Loss: 1522.9909
Epoch [1409/1800] -> Loss: 1522.2654
Epoch [1410/1800] -> Loss: 1521.8790
Epoch [1411/1800] -> Loss: 1521.8283
Epoch [1412/1800] -> Loss: 1522.5374
Epoch [1413/1800] -> Loss: 1523.9013
Epoch [1414/1800] -> Loss: 1523.7265
Epoch [1415/1800] -> Loss: 1527.2985
Epoch [1416/1800] -> Loss: 1528.5858
Epoch [1417/1800] -> Loss: 1527.7819
Epoch [1418/1800] -> Loss: 1523.6480
Epoch [1419/1800] -> Loss: 1524.8931
Epoch [1420/1800] -> Loss: 1524.9589
Epoch [1421/1800] -> Loss: 1523.9042
Epoch [1422/1800] -> Loss: 1526.2561
Epoch [1423/1800] -> Loss: 1523.3717
Epoch [1424/1800] -> Loss: 1522.8214
Epoch [1425/1800] -> Loss: 1524.5174
Epoch [1426/1800] -> Loss: 1523.9770
Epoch [1427/1800] -> Loss: 1525.4267
Epoch [1428/1800] -> Loss: 1526.0224
Epoch [1429/1800] -> Loss: 1521.8086
Epoch [1430/1800] -> Loss: 1523.1374
Epoch [1431/1800] -> Loss: 1528.8933
Epoch [1432/1800] -> Loss: 1526.3249
Epoch [1433/1800] -> Loss: 1526.2351
Epoch [1434/1800] -> Loss: 1521.9673
Epoch [1435/1800] -> Loss: 1525.1668
Epoch [1436/1800] -> Loss: 1521.8390
Epoch [1437/1800] -> Loss: 1523.0644
Epoch [1438/1800] -> Loss: 1521.9702
Epoch [1439/1800] -> Loss: 1521.9593
Epoch [1440/1800] -> Loss: 1522.0610
Epoch [1441/1800] -> Loss: 1530.4154
Epoch [1442/1800] -> Loss: 1531.3516
Epoch [1443/1800] -> Loss: 1521.7765
Epoch [1444/1800] -> Loss: 1524.2151
Epoch [1445/1800] -> Loss: 1525.1184
Epoch [1446/1800] -> Loss: 1523.3767
Epoch [1447/1800] -> Loss: 1529.7201
Epoch [1448/1800] -> Loss: 1523.6317
Epoch [1449/1800] -> Loss: 1522.3515
Epoch [1450/1800] -> Loss: 1521.8395
Epoch [1451/1800] -> Loss: 1523.5742
Epoch [1452/1800] -> Loss: 1523.8681
Epoch [1453/1800] -> Loss: 1525.5772
Epoch [1454/1800] -> Loss: 1529.6161
Epoch [1455/1800] -> Loss: 1523.8437
Epoch [1456/1800] -> Loss: 1522.0902
Epoch [1457/1800] -> Loss: 1523.6469
Epoch [1458/1800] -> Loss: 1522.1428
Epoch [1459/1800] -> Loss: 1528.7042
Epoch [1460/1800] -> Loss: 1522.3469
Epoch [1461/1800] -> Loss: 1522.3089
Epoch [1462/1800] -> Loss: 1524.5786
Epoch [1463/1800] -> Loss: 1522.5824
Epoch [1464/1800] -> Loss: 1522.9320
Epoch [1465/1800] -> Loss: 1521.9268
Epoch [1466/1800] -> Loss: 1522.8326
Epoch [1467/1800] -> Loss: 1521.9855
Epoch [1468/1800] -> Loss: 1522.5801
Epoch [1469/1800] -> Loss: 1523.9799
Epoch [1470/1800] -> Loss: 1524.6824
Epoch [1471/1800] -> Loss: 1525.2129
Epoch [1472/1800] -> Loss: 1521.8845
Epoch [1473/1800] -> Loss: 1522.8546
Epoch [1474/1800] -> Loss: 1527.5567
Epoch [1475/1800] -> Loss: 1525.0187
Epoch [1476/1800] -> Loss: 1523.5145
Epoch [1477/1800] -> Loss: 1521.8259
Epoch [1478/1800] -> Loss: 1524.4561
Epoch [1479/1800] -> Loss: 1526.6892
Epoch [1480/1800] -> Loss: 1531.0430
Epoch [1481/1800] -> Loss: 1522.4157
Epoch [1482/1800] -> Loss: 1523.7120
Epoch [1483/1800] -> Loss: 1522.2468
Epoch [1484/1800] -> Loss: 1522.4466
Epoch [1485/1800] -> Loss: 1532.4337
Epoch [1486/1800] -> Loss: 1523.7618
Epoch [1487/1800] -> Loss: 1522.5461
Epoch [1488/1800] -> Loss: 1523.7474
Epoch [1489/1800] -> Loss: 1521.7204
Epoch [1490/1800] -> Loss: 1526.0516
Epoch [1491/1800] -> Loss: 1523.5459
Epoch [1492/1800] -> Loss: 1527.1675
Epoch [1493/1800] -> Loss: 1522.4714
Epoch [1494/1800] -> Loss: 1525.0788
Epoch [1495/1800] -> Loss: 1525.6134
Epoch [1496/1800] -> Loss: 1521.9947
Epoch [1497/1800] -> Loss: 1523.0755
Epoch [1498/1800] -> Loss: 1531.2985
Epoch [1499/1800] -> Loss: 1522.3153
--------------------------------------------------
Model checkpoint saved as FFNN_1500.pth
--------------------------------------------------
Epoch [1500/1800] -> Loss: 1523.1753
Epoch [1501/1800] -> Loss: 1525.2699
Epoch [1502/1800] -> Loss: 1523.3501
Epoch [1503/1800] -> Loss: 1525.9576
Epoch [1504/1800] -> Loss: 1524.2735
Epoch [1505/1800] -> Loss: 1523.6841
Epoch [1506/1800] -> Loss: 1526.5470
Epoch [1507/1800] -> Loss: 1523.3393
Epoch [1508/1800] -> Loss: 1522.6527
Epoch [1509/1800] -> Loss: 1524.3679
Epoch [1510/1800] -> Loss: 1523.7348
Epoch [1511/1800] -> Loss: 1522.0034
Epoch [1512/1800] -> Loss: 1523.8194
Epoch [1513/1800] -> Loss: 1524.4081
Epoch [1514/1800] -> Loss: 1523.0789
Epoch [1515/1800] -> Loss: 1521.9358
Epoch [1516/1800] -> Loss: 1522.5823
Epoch [1517/1800] -> Loss: 1522.4692
Epoch [1518/1800] -> Loss: 1521.9364
Epoch [1519/1800] -> Loss: 1526.5362
Epoch [1520/1800] -> Loss: 1527.4661
Epoch [1521/1800] -> Loss: 1532.9510
Epoch [1522/1800] -> Loss: 1526.0936
Epoch [1523/1800] -> Loss: 1529.0319
Epoch [1524/1800] -> Loss: 1526.5642
Epoch [1525/1800] -> Loss: 1523.8734
Epoch [1526/1800] -> Loss: 1534.3781
Epoch [1527/1800] -> Loss: 1527.4329
Epoch [1528/1800] -> Loss: 1522.2785
Epoch [1529/1800] -> Loss: 1522.2393
Epoch [1530/1800] -> Loss: 1522.1044
Epoch [1531/1800] -> Loss: 1523.0491
Epoch [1532/1800] -> Loss: 1522.4294
Epoch [1533/1800] -> Loss: 1525.8091
Epoch [1534/1800] -> Loss: 1524.0973
Epoch [1535/1800] -> Loss: 1524.6260
Epoch [1536/1800] -> Loss: 1525.5641
Epoch [1537/1800] -> Loss: 1525.1627
Epoch [1538/1800] -> Loss: 1522.1755
Epoch [1539/1800] -> Loss: 1522.6552
Epoch [1540/1800] -> Loss: 1524.5270
Epoch [1541/1800] -> Loss: 1522.1659
Epoch [1542/1800] -> Loss: 1541.7718
Epoch [1543/1800] -> Loss: 1523.2506
Epoch [1544/1800] -> Loss: 1521.8142
Epoch [1545/1800] -> Loss: 1523.4816
Epoch [1546/1800] -> Loss: 1521.9796
Epoch [1547/1800] -> Loss: 1521.8949
Epoch [1548/1800] -> Loss: 1524.7937
Epoch [1549/1800] -> Loss: 1527.7781
Epoch [1550/1800] -> Loss: 1532.1195
Epoch [1551/1800] -> Loss: 1522.7418
Epoch [1552/1800] -> Loss: 1524.1379
Epoch [1553/1800] -> Loss: 1523.1797
Epoch [1554/1800] -> Loss: 1522.3334
Epoch [1555/1800] -> Loss: 1523.5441
Epoch [1556/1800] -> Loss: 1525.2109
Epoch [1557/1800] -> Loss: 1524.7900
Epoch [1558/1800] -> Loss: 1522.8788
Epoch [1559/1800] -> Loss: 1523.1347
Epoch [1560/1800] -> Loss: 1524.0463
Epoch [1561/1800] -> Loss: 1523.6694
Epoch [1562/1800] -> Loss: 1523.3065
Epoch [1563/1800] -> Loss: 1527.1276
Epoch [1564/1800] -> Loss: 1524.7702
Epoch [1565/1800] -> Loss: 1530.6082
Epoch [1566/1800] -> Loss: 1523.3507
Epoch [1567/1800] -> Loss: 1523.5882
Epoch [1568/1800] -> Loss: 1524.1220
Epoch [1569/1800] -> Loss: 1522.7900
Epoch [1570/1800] -> Loss: 1522.5277
Epoch [1571/1800] -> Loss: 1524.8310
Epoch [1572/1800] -> Loss: 1523.7161
Epoch [1573/1800] -> Loss: 1524.4116
Epoch [1574/1800] -> Loss: 1523.7853
Epoch [1575/1800] -> Loss: 1528.8223
Epoch [1576/1800] -> Loss: 1522.1699
Epoch [1577/1800] -> Loss: 1521.9468
Epoch [1578/1800] -> Loss: 1521.9397
Epoch [1579/1800] -> Loss: 1522.4870
Epoch [1580/1800] -> Loss: 1523.8849
Epoch [1581/1800] -> Loss: 1521.6268
Epoch [1582/1800] -> Loss: 1523.1432
Epoch [1583/1800] -> Loss: 1522.2811
Epoch [1584/1800] -> Loss: 1526.7331
Epoch [1585/1800] -> Loss: 1539.4338
Epoch [1586/1800] -> Loss: 1527.2112
Epoch [1587/1800] -> Loss: 1522.3336
Epoch [1588/1800] -> Loss: 1524.3969
Epoch [1589/1800] -> Loss: 1530.7982
Epoch [1590/1800] -> Loss: 1521.8569
Epoch [1591/1800] -> Loss: 1529.5790
Epoch [1592/1800] -> Loss: 1528.6445
Epoch [1593/1800] -> Loss: 1527.6577
Epoch [1594/1800] -> Loss: 1524.2942
Epoch [1595/1800] -> Loss: 1524.5967
Epoch [1596/1800] -> Loss: 1522.3261
Epoch [1597/1800] -> Loss: 1522.3283
Epoch [1598/1800] -> Loss: 1525.8575
Epoch [1599/1800] -> Loss: 1529.0411
--------------------------------------------------
Model checkpoint saved as FFNN_1600.pth
--------------------------------------------------
Epoch [1600/1800] -> Loss: 1522.6148
Epoch [1601/1800] -> Loss: 1526.6928
Epoch [1602/1800] -> Loss: 1525.4119
Epoch [1603/1800] -> Loss: 1522.3320
Epoch [1604/1800] -> Loss: 1523.8548
Epoch [1605/1800] -> Loss: 1527.9564
Epoch [1606/1800] -> Loss: 1523.8425
Epoch [1607/1800] -> Loss: 1529.6718
Epoch [1608/1800] -> Loss: 1523.6997
Epoch [1609/1800] -> Loss: 1526.8553
Epoch [1610/1800] -> Loss: 1522.5491
Epoch [1611/1800] -> Loss: 1526.8297
Epoch [1612/1800] -> Loss: 1521.8370
Epoch [1613/1800] -> Loss: 1524.8906
Epoch [1614/1800] -> Loss: 1523.7687
Epoch [1615/1800] -> Loss: 1522.6331
Epoch [1616/1800] -> Loss: 1521.9745
Epoch [1617/1800] -> Loss: 1523.7394
Epoch [1618/1800] -> Loss: 1529.0673
Epoch [1619/1800] -> Loss: 1521.9920
Epoch [1620/1800] -> Loss: 1522.8913
Epoch [1621/1800] -> Loss: 1522.4122
Epoch [1622/1800] -> Loss: 1524.1617
Epoch [1623/1800] -> Loss: 1522.1767
Epoch [1624/1800] -> Loss: 1522.4337
Epoch [1625/1800] -> Loss: 1525.0650
Epoch [1626/1800] -> Loss: 1523.4760
Epoch [1627/1800] -> Loss: 1522.8035
Epoch [1628/1800] -> Loss: 1521.9869
Epoch [1629/1800] -> Loss: 1521.9947
Epoch [1630/1800] -> Loss: 1522.1816
Epoch [1631/1800] -> Loss: 1521.8185
Epoch [1632/1800] -> Loss: 1524.9711
Epoch [1633/1800] -> Loss: 1522.2304
Epoch [1634/1800] -> Loss: 1530.2043
Epoch [1635/1800] -> Loss: 1522.5738
Epoch [1636/1800] -> Loss: 1524.8460
Epoch [1637/1800] -> Loss: 1525.3567
Epoch [1638/1800] -> Loss: 1523.5547
Epoch [1639/1800] -> Loss: 1524.8691
Epoch [1640/1800] -> Loss: 1523.4949
Epoch [1641/1800] -> Loss: 1524.1592
Epoch [1642/1800] -> Loss: 1539.0882
Epoch [1643/1800] -> Loss: 1523.0625
Epoch [1644/1800] -> Loss: 1524.8748
Epoch [1645/1800] -> Loss: 1523.9928
Epoch [1646/1800] -> Loss: 1521.9975
Epoch [1647/1800] -> Loss: 1522.2974
Epoch [1648/1800] -> Loss: 1522.4810
Epoch [1649/1800] -> Loss: 1527.2175
Epoch [1650/1800] -> Loss: 1523.3417
Epoch [1651/1800] -> Loss: 1527.2441
Epoch [1652/1800] -> Loss: 1525.4705
Epoch [1653/1800] -> Loss: 1522.5103
Epoch [1654/1800] -> Loss: 1522.3487
Epoch [1655/1800] -> Loss: 1531.4213
Epoch [1656/1800] -> Loss: 1525.5977
Epoch [1657/1800] -> Loss: 1521.8940
Epoch [1658/1800] -> Loss: 1523.3049
Epoch [1659/1800] -> Loss: 1523.5882
Epoch [1660/1800] -> Loss: 1522.1527
Epoch [1661/1800] -> Loss: 1522.8038
Epoch [1662/1800] -> Loss: 1523.7065
Epoch [1663/1800] -> Loss: 1522.2356
Epoch [1664/1800] -> Loss: 1524.0144
Epoch [1665/1800] -> Loss: 1522.5351
Epoch [1666/1800] -> Loss: 1524.8899
Epoch [1667/1800] -> Loss: 1522.7664
Epoch [1668/1800] -> Loss: 1540.6632
Epoch [1669/1800] -> Loss: 1524.9425
Epoch [1670/1800] -> Loss: 1522.5670
Epoch [1671/1800] -> Loss: 1524.3923
Epoch [1672/1800] -> Loss: 1524.3517
Epoch [1673/1800] -> Loss: 1531.5615
Epoch [1674/1800] -> Loss: 1528.2111
Epoch [1675/1800] -> Loss: 1524.1747
Epoch [1676/1800] -> Loss: 1522.1663
Epoch [1677/1800] -> Loss: 1527.7691
Epoch [1678/1800] -> Loss: 1524.3956
Epoch [1679/1800] -> Loss: 1524.1099
Epoch [1680/1800] -> Loss: 1523.8688
Epoch [1681/1800] -> Loss: 1523.8024
Epoch [1682/1800] -> Loss: 1521.7183
Epoch [1683/1800] -> Loss: 1522.1884
Epoch [1684/1800] -> Loss: 1523.4397
Epoch [1685/1800] -> Loss: 1522.0259
Epoch [1686/1800] -> Loss: 1524.0990
Epoch [1687/1800] -> Loss: 1522.8333
Epoch [1688/1800] -> Loss: 1523.8090
Epoch [1689/1800] -> Loss: 1525.4082
Epoch [1690/1800] -> Loss: 1522.9508
Epoch [1691/1800] -> Loss: 1522.6702
Epoch [1692/1800] -> Loss: 1536.0925
Epoch [1693/1800] -> Loss: 1521.6413
Epoch [1694/1800] -> Loss: 1526.6035
Epoch [1695/1800] -> Loss: 1525.3689
Epoch [1696/1800] -> Loss: 1524.0629
Epoch [1697/1800] -> Loss: 1522.6717
Epoch [1698/1800] -> Loss: 1523.9217
Epoch [1699/1800] -> Loss: 1522.3145
--------------------------------------------------
Model checkpoint saved as FFNN_1700.pth
--------------------------------------------------
Epoch [1700/1800] -> Loss: 1524.9767
Epoch [1701/1800] -> Loss: 1528.2861
Epoch [1702/1800] -> Loss: 1521.8495
Epoch [1703/1800] -> Loss: 1523.6634
Epoch [1704/1800] -> Loss: 1526.0789
Epoch [1705/1800] -> Loss: 1526.0201
Epoch [1706/1800] -> Loss: 1522.9151
Epoch [1707/1800] -> Loss: 1523.4447
Epoch [1708/1800] -> Loss: 1522.2256
Epoch [1709/1800] -> Loss: 1523.7715
Epoch [1710/1800] -> Loss: 1522.0140
Epoch [1711/1800] -> Loss: 1525.0791
Epoch [1712/1800] -> Loss: 1521.9010
Epoch [1713/1800] -> Loss: 1523.7463
Epoch [1714/1800] -> Loss: 1527.8364
Epoch [1715/1800] -> Loss: 1538.9880
Epoch [1716/1800] -> Loss: 1527.4320
Epoch [1717/1800] -> Loss: 1523.8383
Epoch [1718/1800] -> Loss: 1522.8763
Epoch [1719/1800] -> Loss: 1522.9723
Epoch [1720/1800] -> Loss: 1523.1197
Epoch [1721/1800] -> Loss: 1523.0668
Epoch [1722/1800] -> Loss: 1523.3247
Epoch [1723/1800] -> Loss: 1522.2422
Epoch [1724/1800] -> Loss: 1521.6657
Epoch [1725/1800] -> Loss: 1531.2332
Epoch [1726/1800] -> Loss: 1521.8991
Epoch [1727/1800] -> Loss: 1522.0443
Epoch [1728/1800] -> Loss: 1523.6960
Epoch [1729/1800] -> Loss: 1521.6534
Epoch [1730/1800] -> Loss: 1524.1181
Epoch [1731/1800] -> Loss: 1522.6612
Epoch [1732/1800] -> Loss: 1522.7124
Epoch [1733/1800] -> Loss: 1523.3009
Epoch [1734/1800] -> Loss: 1525.4383
Epoch [1735/1800] -> Loss: 1524.8101
Epoch [1736/1800] -> Loss: 1523.0639
Epoch [1737/1800] -> Loss: 1523.7066
Epoch [1738/1800] -> Loss: 1525.1501
Epoch [1739/1800] -> Loss: 1522.4874
Epoch [1740/1800] -> Loss: 1528.8205
Epoch [1741/1800] -> Loss: 1523.6146
Epoch [1742/1800] -> Loss: 1529.7954
Epoch [1743/1800] -> Loss: 1521.9376
Epoch [1744/1800] -> Loss: 1522.2906
Epoch [1745/1800] -> Loss: 1521.8665
Epoch [1746/1800] -> Loss: 1523.8086
Epoch [1747/1800] -> Loss: 1523.2836
Epoch [1748/1800] -> Loss: 1525.2176
Epoch [1749/1800] -> Loss: 1547.9526
Epoch [1750/1800] -> Loss: 1523.3331
Epoch [1751/1800] -> Loss: 1533.0983
Epoch [1752/1800] -> Loss: 1522.6728
Epoch [1753/1800] -> Loss: 1523.8254
Epoch [1754/1800] -> Loss: 1522.5555
Epoch [1755/1800] -> Loss: 1527.2393
Epoch [1756/1800] -> Loss: 1523.5626
Epoch [1757/1800] -> Loss: 1523.4201
Epoch [1758/1800] -> Loss: 1522.5642
Epoch [1759/1800] -> Loss: 1528.0564
Epoch [1760/1800] -> Loss: 1522.0147
Epoch [1761/1800] -> Loss: 1532.2769
Epoch [1762/1800] -> Loss: 1522.8078
Epoch [1763/1800] -> Loss: 1523.8497
Epoch [1764/1800] -> Loss: 1523.3807
Epoch [1765/1800] -> Loss: 1521.6543
Epoch [1766/1800] -> Loss: 1522.8512
Epoch [1767/1800] -> Loss: 1528.1299
Epoch [1768/1800] -> Loss: 1528.9053
Epoch [1769/1800] -> Loss: 1521.7514
Epoch [1770/1800] -> Loss: 1536.3951
Epoch [1771/1800] -> Loss: 1524.5945
Epoch [1772/1800] -> Loss: 1523.4297
Epoch [1773/1800] -> Loss: 1528.1355
Epoch [1774/1800] -> Loss: 1524.1661
Epoch [1775/1800] -> Loss: 1529.1867
Epoch [1776/1800] -> Loss: 1522.7909
Epoch [1777/1800] -> Loss: 1522.7367
Epoch [1778/1800] -> Loss: 1523.9125
Epoch [1779/1800] -> Loss: 1527.0573
Epoch [1780/1800] -> Loss: 1521.9958
Epoch [1781/1800] -> Loss: 1530.5053
Epoch [1782/1800] -> Loss: 1523.7909
Epoch [1783/1800] -> Loss: 1522.7280
Epoch [1784/1800] -> Loss: 1526.9075
Epoch [1785/1800] -> Loss: 1521.9401
Epoch [1786/1800] -> Loss: 1524.4799
Epoch [1787/1800] -> Loss: 1528.3784
Epoch [1788/1800] -> Loss: 1526.4667
Epoch [1789/1800] -> Loss: 1524.4855
Epoch [1790/1800] -> Loss: 1521.9072
Epoch [1791/1800] -> Loss: 1523.1675
Epoch [1792/1800] -> Loss: 1528.2251
Epoch [1793/1800] -> Loss: 1531.2526
Epoch [1794/1800] -> Loss: 1525.8478
Epoch [1795/1800] -> Loss: 1524.0240
Epoch [1796/1800] -> Loss: 1522.2468
Epoch [1797/1800] -> Loss: 1523.7136
Epoch [1798/1800] -> Loss: 1522.3784
Epoch [1799/1800] -> Loss: 1523.0373
--------------------------------------------------
Model checkpoint saved as FFNN_1800.pth
--------------------------------------------------
Epoch [1800/1800] -> Loss: 1523.9839
--------------------------------------------------
Training finished successfully.
        Saved model checkpoints can be found in: /home/extern/Documents/Research/scripts/models/
        Saved data/loss graphs can be found in: /home/extern/Documents/Research/scripts/graphs/

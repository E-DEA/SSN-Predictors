--------------------------------------------------
Code running on device: cuda
--------------------------------------------------
Dataset source : NOAA, ISGI
File location :
    SSN - /home/extern/Documents/Research/data/NOAA/table_international-sunspot-numbers_monthly.txt
    AA - /home/extern/Documents/Research/data/ISGI/aa_1869-08-01_2017-12-31_D.dat
--------------------------------------------------
Selected model: FFNN(
  (model): Sequential(
    (0): Linear(in_features=6, out_features=6, bias=True)
    (1): LeakyReLU(negative_slope=0.01, inplace)
    (2): Linear(in_features=6, out_features=6, bias=True)
    (3): LeakyReLU(negative_slope=0.01, inplace)
    (4): Linear(in_features=6, out_features=1, bias=True)
  )
)    Training mode: True    Testing mode: False
--------------------------------------------------
Pre-trained model available, loading model weights
--------------------------------------------------
Training model with: num_epochs=1800, start_lr=0.0005
Epoch [   1/1800] -> Loss: 572.9200
Epoch [   2/1800] -> Loss: 480.6067
Epoch [   3/1800] -> Loss: 440.2086
Epoch [   4/1800] -> Loss: 418.1964
Epoch [   5/1800] -> Loss: 404.2611
Epoch [   6/1800] -> Loss: 392.5852
Epoch [   7/1800] -> Loss: 383.9232
Epoch [   8/1800] -> Loss: 374.2284
Epoch [   9/1800] -> Loss: 366.9508
Epoch [  10/1800] -> Loss: 361.9612
Epoch [  11/1800] -> Loss: 353.8634
Epoch [  12/1800] -> Loss: 350.0773
Epoch [  13/1800] -> Loss: 343.9353
Epoch [  14/1800] -> Loss: 340.0098
Epoch [  15/1800] -> Loss: 337.0478
Epoch [  16/1800] -> Loss: 331.7254
Epoch [  17/1800] -> Loss: 327.0655
Epoch [  18/1800] -> Loss: 325.2901
Epoch [  19/1800] -> Loss: 322.8865
Epoch [  20/1800] -> Loss: 321.1519
Epoch [  21/1800] -> Loss: 321.0276
Epoch [  22/1800] -> Loss: 317.6662
Epoch [  23/1800] -> Loss: 316.8483
Epoch [  24/1800] -> Loss: 315.7039
Epoch [  25/1800] -> Loss: 315.6519
Epoch [  26/1800] -> Loss: 315.0502
Epoch [  27/1800] -> Loss: 313.8683
Epoch [  28/1800] -> Loss: 312.5840
Epoch [  29/1800] -> Loss: 311.5312
Epoch [  30/1800] -> Loss: 314.1730
Epoch [  31/1800] -> Loss: 310.8890
Epoch [  32/1800] -> Loss: 311.7449
Epoch [  33/1800] -> Loss: 310.8125
Epoch [  34/1800] -> Loss: 309.9560
Epoch [  35/1800] -> Loss: 309.6245
Epoch [  36/1800] -> Loss: 309.6254
Epoch [  37/1800] -> Loss: 309.3708
Epoch [  38/1800] -> Loss: 308.3308
Epoch [  39/1800] -> Loss: 307.9492
Epoch [  40/1800] -> Loss: 307.0925
Epoch [  41/1800] -> Loss: 307.7384
Epoch [  42/1800] -> Loss: 307.2331
Epoch [  43/1800] -> Loss: 307.5402
Epoch [  44/1800] -> Loss: 307.0270
Epoch [  45/1800] -> Loss: 307.1634
Epoch [  46/1800] -> Loss: 306.6617
Epoch [  47/1800] -> Loss: 306.6974
Epoch [  48/1800] -> Loss: 306.5420
Epoch [  49/1800] -> Loss: 306.2156
--------------------------------------------------
Model checkpoint saved as FFNN_50.pth
--------------------------------------------------
Epoch [  50/1800] -> Loss: 305.9998
Epoch [  51/1800] -> Loss: 306.3377
Epoch [  52/1800] -> Loss: 305.5967
Epoch [  53/1800] -> Loss: 305.2770
Epoch [  54/1800] -> Loss: 305.0081
Epoch [  55/1800] -> Loss: 305.2192
Epoch [  56/1800] -> Loss: 306.7513
Epoch [  57/1800] -> Loss: 304.4470
Epoch [  58/1800] -> Loss: 304.4080
Epoch [  59/1800] -> Loss: 304.5923
Epoch [  60/1800] -> Loss: 303.8770
Epoch [  61/1800] -> Loss: 304.6444
Epoch [  62/1800] -> Loss: 303.8814
Epoch [  63/1800] -> Loss: 303.7469
Epoch [  64/1800] -> Loss: 304.2213
Epoch [  65/1800] -> Loss: 304.1580
Epoch [  66/1800] -> Loss: 303.9623
Epoch [  67/1800] -> Loss: 303.7861
Epoch [  68/1800] -> Loss: 304.5472
Epoch [  69/1800] -> Loss: 303.2042
Epoch [  70/1800] -> Loss: 303.6704
Epoch [  71/1800] -> Loss: 303.0585
Epoch [  72/1800] -> Loss: 302.2840
Epoch [  73/1800] -> Loss: 303.7287
Epoch [  74/1800] -> Loss: 303.1414
Epoch [  75/1800] -> Loss: 303.8424
Epoch [  76/1800] -> Loss: 302.2460
Epoch [  77/1800] -> Loss: 302.6617
Epoch [  78/1800] -> Loss: 302.7018
Epoch [  79/1800] -> Loss: 302.2418
Epoch [  80/1800] -> Loss: 303.7525
Epoch [  81/1800] -> Loss: 301.9596
Epoch [  82/1800] -> Loss: 302.1397
Epoch [  83/1800] -> Loss: 301.7254
Epoch [  84/1800] -> Loss: 301.8076
Epoch [  85/1800] -> Loss: 301.7518
Epoch [  86/1800] -> Loss: 302.4789
Epoch [  87/1800] -> Loss: 301.5958
Epoch [  88/1800] -> Loss: 302.6405
Epoch [  89/1800] -> Loss: 302.3285
Epoch [  90/1800] -> Loss: 301.7002
Epoch [  91/1800] -> Loss: 301.6723
Epoch [  92/1800] -> Loss: 302.1495
Epoch [  93/1800] -> Loss: 302.6270
Epoch [  94/1800] -> Loss: 302.5372
Epoch [  95/1800] -> Loss: 301.5403
Epoch [  96/1800] -> Loss: 301.6039
Epoch [  97/1800] -> Loss: 301.8012
Epoch [  98/1800] -> Loss: 301.5977
Epoch [  99/1800] -> Loss: 301.5513
--------------------------------------------------
Model checkpoint saved as FFNN_100.pth
--------------------------------------------------
Epoch [ 100/1800] -> Loss: 301.0741
Epoch [ 101/1800] -> Loss: 301.7111
Epoch [ 102/1800] -> Loss: 301.3050
Epoch [ 103/1800] -> Loss: 301.4804
Epoch [ 104/1800] -> Loss: 300.8784
Epoch [ 105/1800] -> Loss: 301.5133
Epoch [ 106/1800] -> Loss: 301.8398
Epoch [ 107/1800] -> Loss: 302.0766
Epoch [ 108/1800] -> Loss: 300.8801
Epoch [ 109/1800] -> Loss: 300.8266
Epoch [ 110/1800] -> Loss: 301.9643
Epoch [ 111/1800] -> Loss: 300.9057
Epoch [ 112/1800] -> Loss: 301.7453
Epoch [ 113/1800] -> Loss: 302.4062
Epoch [ 114/1800] -> Loss: 300.7365
Epoch [ 115/1800] -> Loss: 300.9502
Epoch [ 116/1800] -> Loss: 301.3609
Epoch [ 117/1800] -> Loss: 300.4665
Epoch [ 118/1800] -> Loss: 301.6434
Epoch [ 119/1800] -> Loss: 301.8466
Epoch [ 120/1800] -> Loss: 300.6423
Epoch [ 121/1800] -> Loss: 301.1957
Epoch [ 122/1800] -> Loss: 300.8493
Epoch [ 123/1800] -> Loss: 301.1123
Epoch [ 124/1800] -> Loss: 300.7755
Epoch [ 125/1800] -> Loss: 300.8151
Epoch [ 126/1800] -> Loss: 301.1375
Epoch [ 127/1800] -> Loss: 301.1891
Epoch [ 128/1800] -> Loss: 300.2897
Epoch [ 129/1800] -> Loss: 300.6000
Epoch [ 130/1800] -> Loss: 300.8650
Epoch [ 131/1800] -> Loss: 300.8660
Epoch [ 132/1800] -> Loss: 300.7330
Epoch [ 133/1800] -> Loss: 300.5033
Epoch [ 134/1800] -> Loss: 300.2074
Epoch [ 135/1800] -> Loss: 301.9161
Epoch [ 136/1800] -> Loss: 300.6196
Epoch [ 137/1800] -> Loss: 301.5216
Epoch [ 138/1800] -> Loss: 302.0928
Epoch [ 139/1800] -> Loss: 300.8500
Epoch [ 140/1800] -> Loss: 300.5265
Epoch [ 141/1800] -> Loss: 300.6560
Epoch [ 142/1800] -> Loss: 302.3564
Epoch [ 143/1800] -> Loss: 300.6249
Epoch [ 144/1800] -> Loss: 300.6524
Epoch [ 145/1800] -> Loss: 299.2112
Epoch [ 146/1800] -> Loss: 300.5074
Epoch [ 147/1800] -> Loss: 300.6990
Epoch [ 148/1800] -> Loss: 300.8185
Epoch [ 149/1800] -> Loss: 300.1938
--------------------------------------------------
Model checkpoint saved as FFNN_150.pth
--------------------------------------------------
Epoch [ 150/1800] -> Loss: 300.4444
Epoch [ 151/1800] -> Loss: 300.3335
Epoch [ 152/1800] -> Loss: 299.8118
Epoch [ 153/1800] -> Loss: 300.5466
Epoch [ 154/1800] -> Loss: 300.1338
Epoch [ 155/1800] -> Loss: 301.3166
Epoch   155: reducing learning rate of group 0 to 2.5000e-04.
Epoch [ 156/1800] -> Loss: 300.3172
Epoch [ 157/1800] -> Loss: 299.7076
Epoch [ 158/1800] -> Loss: 299.4111
Epoch [ 159/1800] -> Loss: 299.4541
Epoch [ 160/1800] -> Loss: 300.0819
Epoch [ 161/1800] -> Loss: 299.7021
Epoch [ 162/1800] -> Loss: 300.1154
Epoch [ 163/1800] -> Loss: 299.5924
Epoch [ 164/1800] -> Loss: 300.1233
Epoch [ 165/1800] -> Loss: 299.7447
Epoch [ 166/1800] -> Loss: 299.4883
Epoch   166: reducing learning rate of group 0 to 1.2500e-04.
Epoch [ 167/1800] -> Loss: 299.9502
Epoch [ 168/1800] -> Loss: 299.5209
Epoch [ 169/1800] -> Loss: 299.1639
Epoch [ 170/1800] -> Loss: 299.2446
Epoch [ 171/1800] -> Loss: 299.3144
Epoch [ 172/1800] -> Loss: 299.1374
Epoch [ 173/1800] -> Loss: 299.0409
Epoch [ 174/1800] -> Loss: 299.3863
Epoch [ 175/1800] -> Loss: 299.2056
Epoch [ 176/1800] -> Loss: 299.1995
Epoch [ 177/1800] -> Loss: 299.2744
Epoch [ 178/1800] -> Loss: 299.2401
Epoch [ 179/1800] -> Loss: 299.2187
Epoch [ 180/1800] -> Loss: 299.4345
Epoch [ 181/1800] -> Loss: 299.5074
Epoch [ 182/1800] -> Loss: 299.2847
Epoch [ 183/1800] -> Loss: 299.2369
Epoch   183: reducing learning rate of group 0 to 6.2500e-05.
Epoch [ 184/1800] -> Loss: 299.3721
Epoch [ 185/1800] -> Loss: 299.1527
Epoch [ 186/1800] -> Loss: 299.0350
Epoch [ 187/1800] -> Loss: 299.0406
Epoch [ 188/1800] -> Loss: 299.1278
Epoch [ 189/1800] -> Loss: 299.1542
Epoch [ 190/1800] -> Loss: 298.9768
Epoch [ 191/1800] -> Loss: 299.1285
Epoch [ 192/1800] -> Loss: 299.0106
Epoch [ 193/1800] -> Loss: 299.0210
Epoch [ 194/1800] -> Loss: 298.9981
Epoch [ 195/1800] -> Loss: 299.0094
Epoch [ 196/1800] -> Loss: 299.0691
Epoch [ 197/1800] -> Loss: 299.1030
Epoch [ 198/1800] -> Loss: 299.0789
Epoch [ 199/1800] -> Loss: 298.9963
--------------------------------------------------
Model checkpoint saved as FFNN_200.pth
--------------------------------------------------
Epoch [ 200/1800] -> Loss: 298.9666
Epoch   200: reducing learning rate of group 0 to 3.1250e-05.
Epoch [ 201/1800] -> Loss: 298.9607
Epoch [ 202/1800] -> Loss: 298.9583
Epoch [ 203/1800] -> Loss: 298.9717
Epoch [ 204/1800] -> Loss: 298.9753
Epoch [ 205/1800] -> Loss: 298.9433
Epoch [ 206/1800] -> Loss: 298.9149
Epoch [ 207/1800] -> Loss: 298.9231
Epoch [ 208/1800] -> Loss: 298.9132
Epoch [ 209/1800] -> Loss: 298.9312
Epoch [ 210/1800] -> Loss: 298.9180
Epoch [ 211/1800] -> Loss: 298.9206
Epoch [ 212/1800] -> Loss: 298.8968
Epoch [ 213/1800] -> Loss: 298.9535
Epoch [ 214/1800] -> Loss: 298.8935
Epoch [ 215/1800] -> Loss: 298.9460
Epoch [ 216/1800] -> Loss: 298.9567
Epoch [ 217/1800] -> Loss: 298.9078
Epoch [ 218/1800] -> Loss: 298.8864
Epoch   218: reducing learning rate of group 0 to 1.5625e-05.
Epoch [ 219/1800] -> Loss: 298.8983
Epoch [ 220/1800] -> Loss: 298.9158
Epoch [ 221/1800] -> Loss: 298.9350
Epoch [ 222/1800] -> Loss: 298.8501
Epoch [ 223/1800] -> Loss: 298.8712
Epoch [ 224/1800] -> Loss: 298.9226
Epoch [ 225/1800] -> Loss: 298.8576
Epoch [ 226/1800] -> Loss: 298.9091
Epoch [ 227/1800] -> Loss: 298.8338
Epoch [ 228/1800] -> Loss: 298.8535
Epoch [ 229/1800] -> Loss: 298.8433
Epoch [ 230/1800] -> Loss: 298.8617
Epoch [ 231/1800] -> Loss: 298.8688
Epoch [ 232/1800] -> Loss: 298.8516
Epoch   232: reducing learning rate of group 0 to 7.8125e-06.
Epoch [ 233/1800] -> Loss: 298.8845
Epoch [ 234/1800] -> Loss: 298.8181
Epoch [ 235/1800] -> Loss: 298.8222
Epoch [ 236/1800] -> Loss: 298.8287
Epoch [ 237/1800] -> Loss: 298.8380
Epoch [ 238/1800] -> Loss: 298.8151
Epoch [ 239/1800] -> Loss: 298.8148
Epoch [ 240/1800] -> Loss: 298.8247
Epoch [ 241/1800] -> Loss: 298.8305
Epoch [ 242/1800] -> Loss: 298.8149
Epoch [ 243/1800] -> Loss: 298.8204
Epoch [ 244/1800] -> Loss: 298.8217
Epoch   244: reducing learning rate of group 0 to 3.9063e-06.
Epoch [ 245/1800] -> Loss: 298.8204
Epoch [ 246/1800] -> Loss: 298.8062
Epoch [ 247/1800] -> Loss: 298.8073
Epoch [ 248/1800] -> Loss: 298.8167
Epoch [ 249/1800] -> Loss: 298.8098
--------------------------------------------------
Model checkpoint saved as FFNN_250.pth
--------------------------------------------------
Epoch [ 250/1800] -> Loss: 298.8023
Epoch [ 251/1800] -> Loss: 298.8053
Epoch [ 252/1800] -> Loss: 298.8093
Epoch [ 253/1800] -> Loss: 298.8109
Epoch [ 254/1800] -> Loss: 298.8021
Epoch [ 255/1800] -> Loss: 298.8018
Epoch   255: reducing learning rate of group 0 to 1.9531e-06.
Epoch [ 256/1800] -> Loss: 298.8092
Epoch [ 257/1800] -> Loss: 298.7995
Epoch [ 258/1800] -> Loss: 298.7968
Epoch [ 259/1800] -> Loss: 298.7961
Epoch [ 260/1800] -> Loss: 298.7970
Epoch [ 261/1800] -> Loss: 298.8044
Epoch [ 262/1800] -> Loss: 298.8009
Epoch [ 263/1800] -> Loss: 298.8050
Epoch [ 264/1800] -> Loss: 298.7983
Epoch [ 265/1800] -> Loss: 298.8057
Epoch [ 266/1800] -> Loss: 298.7968
Epoch   266: reducing learning rate of group 0 to 9.7656e-07.
Epoch [ 267/1800] -> Loss: 298.7971
Epoch [ 268/1800] -> Loss: 298.7953
Epoch [ 269/1800] -> Loss: 298.7944
Epoch [ 270/1800] -> Loss: 298.7943
Epoch [ 271/1800] -> Loss: 298.7964
Epoch [ 272/1800] -> Loss: 298.7941
Epoch [ 273/1800] -> Loss: 298.7938
Epoch [ 274/1800] -> Loss: 298.7982
Epoch [ 275/1800] -> Loss: 298.7952
Epoch [ 276/1800] -> Loss: 298.7987
Epoch [ 277/1800] -> Loss: 298.7974
Epoch   277: reducing learning rate of group 0 to 4.8828e-07.
Epoch [ 278/1800] -> Loss: 298.7947
Epoch [ 279/1800] -> Loss: 298.7929
Epoch [ 280/1800] -> Loss: 298.7930
Epoch [ 281/1800] -> Loss: 298.7927
Epoch [ 282/1800] -> Loss: 298.7930
Epoch [ 283/1800] -> Loss: 298.7929
Epoch [ 284/1800] -> Loss: 298.7939
Epoch [ 285/1800] -> Loss: 298.7937
Epoch [ 286/1800] -> Loss: 298.7942
Epoch [ 287/1800] -> Loss: 298.7944
Epoch [ 288/1800] -> Loss: 298.7944
Epoch   288: reducing learning rate of group 0 to 2.4414e-07.
Epoch [ 289/1800] -> Loss: 298.7929
Epoch [ 290/1800] -> Loss: 298.7925
Epoch [ 291/1800] -> Loss: 298.7925
Epoch [ 292/1800] -> Loss: 298.7924
Epoch [ 293/1800] -> Loss: 298.7923
Epoch [ 294/1800] -> Loss: 298.7923
Epoch [ 295/1800] -> Loss: 298.7928
Epoch [ 296/1800] -> Loss: 298.7923
Epoch [ 297/1800] -> Loss: 298.7921
Epoch [ 298/1800] -> Loss: 298.7922
Epoch [ 299/1800] -> Loss: 298.7925
Epoch   299: reducing learning rate of group 0 to 1.2207e-07.
--------------------------------------------------
Model checkpoint saved as FFNN_300.pth
--------------------------------------------------
Epoch [ 300/1800] -> Loss: 298.7924
Epoch [ 301/1800] -> Loss: 298.7918
Epoch [ 302/1800] -> Loss: 298.7920
Epoch [ 303/1800] -> Loss: 298.7918
Epoch [ 304/1800] -> Loss: 298.7920
Epoch [ 305/1800] -> Loss: 298.7918
Epoch [ 306/1800] -> Loss: 298.7921
Epoch [ 307/1800] -> Loss: 298.7919
Epoch [ 308/1800] -> Loss: 298.7916
Epoch [ 309/1800] -> Loss: 298.7919
Epoch [ 310/1800] -> Loss: 298.7923
Epoch   310: reducing learning rate of group 0 to 6.1035e-08.
Epoch [ 311/1800] -> Loss: 298.7918
Epoch [ 312/1800] -> Loss: 298.7915
Epoch [ 313/1800] -> Loss: 298.7921
Epoch [ 314/1800] -> Loss: 298.7915
Epoch [ 315/1800] -> Loss: 298.7915
Epoch [ 316/1800] -> Loss: 298.7915
Epoch [ 317/1800] -> Loss: 298.7915
Epoch [ 318/1800] -> Loss: 298.7915
Epoch [ 319/1800] -> Loss: 298.7917
Epoch [ 320/1800] -> Loss: 298.7916
Epoch [ 321/1800] -> Loss: 298.7918
Epoch   321: reducing learning rate of group 0 to 3.0518e-08.
Epoch [ 322/1800] -> Loss: 298.7917
Epoch [ 323/1800] -> Loss: 298.7915
Epoch [ 324/1800] -> Loss: 298.7914
Epoch [ 325/1800] -> Loss: 298.7915
Epoch [ 326/1800] -> Loss: 298.7915
Epoch [ 327/1800] -> Loss: 298.7915
Epoch [ 328/1800] -> Loss: 298.7915
Epoch [ 329/1800] -> Loss: 298.7915
Epoch [ 330/1800] -> Loss: 298.7915
Epoch [ 331/1800] -> Loss: 298.7914
Epoch [ 332/1800] -> Loss: 298.7915
Epoch   332: reducing learning rate of group 0 to 1.5259e-08.
Epoch [ 333/1800] -> Loss: 298.7915
Epoch [ 334/1800] -> Loss: 298.7914
Epoch [ 335/1800] -> Loss: 298.7914
Epoch [ 336/1800] -> Loss: 298.7914
Epoch [ 337/1800] -> Loss: 298.7914
Epoch [ 338/1800] -> Loss: 298.7914
Epoch [ 339/1800] -> Loss: 298.7914
Epoch [ 340/1800] -> Loss: 298.7914
Epoch [ 341/1800] -> Loss: 298.7914
Epoch [ 342/1800] -> Loss: 298.7914
Epoch [ 343/1800] -> Loss: 298.7914
Epoch [ 344/1800] -> Loss: 298.7914
Epoch [ 345/1800] -> Loss: 298.7914
Epoch [ 346/1800] -> Loss: 298.7914
Epoch [ 347/1800] -> Loss: 298.7914
Epoch [ 348/1800] -> Loss: 298.7914
Epoch [ 349/1800] -> Loss: 298.7914
--------------------------------------------------
Model checkpoint saved as FFNN_350.pth
--------------------------------------------------
Epoch [ 350/1800] -> Loss: 298.7914
Epoch [ 351/1800] -> Loss: 298.7914
Epoch [ 352/1800] -> Loss: 298.7914
Epoch [ 353/1800] -> Loss: 298.7914
Epoch [ 354/1800] -> Loss: 298.7914
Epoch [ 355/1800] -> Loss: 298.7914
Epoch [ 356/1800] -> Loss: 298.7914
Epoch [ 357/1800] -> Loss: 298.7914
Epoch [ 358/1800] -> Loss: 298.7914
Epoch [ 359/1800] -> Loss: 298.7914
Epoch [ 360/1800] -> Loss: 298.7914
Epoch [ 361/1800] -> Loss: 298.7914
Epoch [ 362/1800] -> Loss: 298.7914
Epoch [ 363/1800] -> Loss: 298.7914
Epoch [ 364/1800] -> Loss: 298.7914
Epoch [ 365/1800] -> Loss: 298.7914
Epoch [ 366/1800] -> Loss: 298.7914
Epoch [ 367/1800] -> Loss: 298.7914
Epoch [ 368/1800] -> Loss: 298.7914
Epoch [ 369/1800] -> Loss: 298.7914
Epoch [ 370/1800] -> Loss: 298.7914
Epoch [ 371/1800] -> Loss: 298.7914
Epoch [ 372/1800] -> Loss: 298.7914
Epoch [ 373/1800] -> Loss: 298.7914
Epoch [ 374/1800] -> Loss: 298.7914
Epoch [ 375/1800] -> Loss: 298.7914
Epoch [ 376/1800] -> Loss: 298.7914
Epoch [ 377/1800] -> Loss: 298.7914
Epoch [ 378/1800] -> Loss: 298.7914
Epoch [ 379/1800] -> Loss: 298.7914
Epoch [ 380/1800] -> Loss: 298.7914
Epoch [ 381/1800] -> Loss: 298.7914
Epoch [ 382/1800] -> Loss: 298.7914
Epoch [ 383/1800] -> Loss: 298.7914
Epoch [ 384/1800] -> Loss: 298.7915
Epoch [ 385/1800] -> Loss: 298.7914
Epoch [ 386/1800] -> Loss: 298.7914
Epoch [ 387/1800] -> Loss: 298.7914
Epoch [ 388/1800] -> Loss: 298.7914
Epoch [ 389/1800] -> Loss: 298.7914
Epoch [ 390/1800] -> Loss: 298.7914
Epoch [ 391/1800] -> Loss: 298.7914
Epoch [ 392/1800] -> Loss: 298.7914
Epoch [ 393/1800] -> Loss: 298.7914
Epoch [ 394/1800] -> Loss: 298.7914
Epoch [ 395/1800] -> Loss: 298.7914
Epoch [ 396/1800] -> Loss: 298.7914
Epoch [ 397/1800] -> Loss: 298.7914
Epoch [ 398/1800] -> Loss: 298.7914
Epoch [ 399/1800] -> Loss: 298.7914
--------------------------------------------------
Model checkpoint saved as FFNN_400.pth
--------------------------------------------------
Epoch [ 400/1800] -> Loss: 298.7914
Epoch [ 401/1800] -> Loss: 298.7914
Epoch [ 402/1800] -> Loss: 298.7914
Epoch [ 403/1800] -> Loss: 298.7914
Epoch [ 404/1800] -> Loss: 298.7914
Epoch [ 405/1800] -> Loss: 298.7914
Epoch [ 406/1800] -> Loss: 298.7914
Epoch [ 407/1800] -> Loss: 298.7914
Epoch [ 408/1800] -> Loss: 298.7914
Epoch [ 409/1800] -> Loss: 298.7914
Epoch [ 410/1800] -> Loss: 298.7914
Epoch [ 411/1800] -> Loss: 298.7914
Epoch [ 412/1800] -> Loss: 298.7914
Epoch [ 413/1800] -> Loss: 298.7915
Epoch [ 414/1800] -> Loss: 298.7914
Epoch [ 415/1800] -> Loss: 298.7914
Epoch [ 416/1800] -> Loss: 298.7914
Epoch [ 417/1800] -> Loss: 298.7914
Epoch [ 418/1800] -> Loss: 298.7914
Epoch [ 419/1800] -> Loss: 298.7914
Epoch [ 420/1800] -> Loss: 298.7914
Epoch [ 421/1800] -> Loss: 298.7914
Epoch [ 422/1800] -> Loss: 298.7914
Epoch [ 423/1800] -> Loss: 298.7914
Epoch [ 424/1800] -> Loss: 298.7914
Epoch [ 425/1800] -> Loss: 298.7914
Epoch [ 426/1800] -> Loss: 298.7914
Epoch [ 427/1800] -> Loss: 298.7914
Epoch [ 428/1800] -> Loss: 298.7914
Epoch [ 429/1800] -> Loss: 298.7914
Epoch [ 430/1800] -> Loss: 298.7914
Epoch [ 431/1800] -> Loss: 298.7914
Epoch [ 432/1800] -> Loss: 298.7914
Epoch [ 433/1800] -> Loss: 298.7914
Epoch [ 434/1800] -> Loss: 298.7914
Epoch [ 435/1800] -> Loss: 298.7914
Epoch [ 436/1800] -> Loss: 298.7914
Epoch [ 437/1800] -> Loss: 298.7914
Epoch [ 438/1800] -> Loss: 298.7914
Epoch [ 439/1800] -> Loss: 298.7914
Epoch [ 440/1800] -> Loss: 298.7914
Epoch [ 441/1800] -> Loss: 298.7914
Epoch [ 442/1800] -> Loss: 298.7914
Epoch [ 443/1800] -> Loss: 298.7914
Epoch [ 444/1800] -> Loss: 298.7915
Epoch [ 445/1800] -> Loss: 298.7914
Epoch [ 446/1800] -> Loss: 298.7914
Epoch [ 447/1800] -> Loss: 298.7914
Epoch [ 448/1800] -> Loss: 298.7914
Epoch [ 449/1800] -> Loss: 298.7914
--------------------------------------------------
Model checkpoint saved as FFNN_450.pth
--------------------------------------------------
Epoch [ 450/1800] -> Loss: 298.7914
Epoch [ 451/1800] -> Loss: 298.7914
Epoch [ 452/1800] -> Loss: 298.7914
Epoch [ 453/1800] -> Loss: 298.7914
Epoch [ 454/1800] -> Loss: 298.7914
Epoch [ 455/1800] -> Loss: 298.7914
Epoch [ 456/1800] -> Loss: 298.7915
Epoch [ 457/1800] -> Loss: 298.7914
Epoch [ 458/1800] -> Loss: 298.7914
Epoch [ 459/1800] -> Loss: 298.7914
Epoch [ 460/1800] -> Loss: 298.7914
Epoch [ 461/1800] -> Loss: 298.7914
Epoch [ 462/1800] -> Loss: 298.7914
Epoch [ 463/1800] -> Loss: 298.7914
Epoch [ 464/1800] -> Loss: 298.7914
Epoch [ 465/1800] -> Loss: 298.7914
Epoch [ 466/1800] -> Loss: 298.7914
Epoch [ 467/1800] -> Loss: 298.7914
Epoch [ 468/1800] -> Loss: 298.7914
Epoch [ 469/1800] -> Loss: 298.7914
Epoch [ 470/1800] -> Loss: 298.7914
Epoch [ 471/1800] -> Loss: 298.7914
Epoch [ 472/1800] -> Loss: 298.7914
Epoch [ 473/1800] -> Loss: 298.7914
Epoch [ 474/1800] -> Loss: 298.7914
Epoch [ 475/1800] -> Loss: 298.7914
Epoch [ 476/1800] -> Loss: 298.7914
Epoch [ 477/1800] -> Loss: 298.7914
Epoch [ 478/1800] -> Loss: 298.7914
Epoch [ 479/1800] -> Loss: 298.7914
Epoch [ 480/1800] -> Loss: 298.7914
Epoch [ 481/1800] -> Loss: 298.7914
Epoch [ 482/1800] -> Loss: 298.7914
Epoch [ 483/1800] -> Loss: 298.7914
Epoch [ 484/1800] -> Loss: 298.7914
Epoch [ 485/1800] -> Loss: 298.7914
Epoch [ 486/1800] -> Loss: 298.7914
Epoch [ 487/1800] -> Loss: 298.7914
Epoch [ 488/1800] -> Loss: 298.7914
Epoch [ 489/1800] -> Loss: 298.7914
Epoch [ 490/1800] -> Loss: 298.7914
Epoch [ 491/1800] -> Loss: 298.7914
Epoch [ 492/1800] -> Loss: 298.7914
Epoch [ 493/1800] -> Loss: 298.7914
Epoch [ 494/1800] -> Loss: 298.7914
Epoch [ 495/1800] -> Loss: 298.7914
Epoch [ 496/1800] -> Loss: 298.7914
Epoch [ 497/1800] -> Loss: 298.7914
Epoch [ 498/1800] -> Loss: 298.7914
Epoch [ 499/1800] -> Loss: 298.7914
--------------------------------------------------
Model checkpoint saved as FFNN_500.pth
--------------------------------------------------
Epoch [ 500/1800] -> Loss: 298.7914
Epoch [ 501/1800] -> Loss: 298.7914
Epoch [ 502/1800] -> Loss: 298.7914
Epoch [ 503/1800] -> Loss: 298.7914
Epoch [ 504/1800] -> Loss: 298.7914
Epoch [ 505/1800] -> Loss: 298.7914
Epoch [ 506/1800] -> Loss: 298.7914
Epoch [ 507/1800] -> Loss: 298.7914
Epoch [ 508/1800] -> Loss: 298.7914
Epoch [ 509/1800] -> Loss: 298.7914
Epoch [ 510/1800] -> Loss: 298.7914
Epoch [ 511/1800] -> Loss: 298.7914
Epoch [ 512/1800] -> Loss: 298.7914
Epoch [ 513/1800] -> Loss: 298.7914
Epoch [ 514/1800] -> Loss: 298.7914
Epoch [ 515/1800] -> Loss: 298.7914
Epoch [ 516/1800] -> Loss: 298.7914
Epoch [ 517/1800] -> Loss: 298.7914
Epoch [ 518/1800] -> Loss: 298.7914
Epoch [ 519/1800] -> Loss: 298.7914
Epoch [ 520/1800] -> Loss: 298.7914
Epoch [ 521/1800] -> Loss: 298.7914
Epoch [ 522/1800] -> Loss: 298.7914
Epoch [ 523/1800] -> Loss: 298.7914
Epoch [ 524/1800] -> Loss: 298.7914
Epoch [ 525/1800] -> Loss: 298.7914
Epoch [ 526/1800] -> Loss: 298.7914
Epoch [ 527/1800] -> Loss: 298.7914
Epoch [ 528/1800] -> Loss: 298.7914
Epoch [ 529/1800] -> Loss: 298.7914
Epoch [ 530/1800] -> Loss: 298.7914
Epoch [ 531/1800] -> Loss: 298.7914
Epoch [ 532/1800] -> Loss: 298.7914
Epoch [ 533/1800] -> Loss: 298.7914
Epoch [ 534/1800] -> Loss: 298.7914
Epoch [ 535/1800] -> Loss: 298.7914
Epoch [ 536/1800] -> Loss: 298.7914
Epoch [ 537/1800] -> Loss: 298.7914
Epoch [ 538/1800] -> Loss: 298.7914
Epoch [ 539/1800] -> Loss: 298.7914
Epoch [ 540/1800] -> Loss: 298.7914
Epoch [ 541/1800] -> Loss: 298.7914
Epoch [ 542/1800] -> Loss: 298.7914
Epoch [ 543/1800] -> Loss: 298.7914
Epoch [ 544/1800] -> Loss: 298.7914
Epoch [ 545/1800] -> Loss: 298.7914
Epoch [ 546/1800] -> Loss: 298.7914
Epoch [ 547/1800] -> Loss: 298.7914
Epoch [ 548/1800] -> Loss: 298.7914
Epoch [ 549/1800] -> Loss: 298.7914
--------------------------------------------------
Model checkpoint saved as FFNN_550.pth
--------------------------------------------------
Epoch [ 550/1800] -> Loss: 298.7914
Epoch [ 551/1800] -> Loss: 298.7914
Epoch [ 552/1800] -> Loss: 298.7914
Epoch [ 553/1800] -> Loss: 298.7914
Epoch [ 554/1800] -> Loss: 298.7914
Epoch [ 555/1800] -> Loss: 298.7914
Epoch [ 556/1800] -> Loss: 298.7914
Epoch [ 557/1800] -> Loss: 298.7914
Epoch [ 558/1800] -> Loss: 298.7914
Epoch [ 559/1800] -> Loss: 298.7914
Epoch [ 560/1800] -> Loss: 298.7914
Epoch [ 561/1800] -> Loss: 298.7914
Epoch [ 562/1800] -> Loss: 298.7914
Epoch [ 563/1800] -> Loss: 298.7914
Epoch [ 564/1800] -> Loss: 298.7914
Epoch [ 565/1800] -> Loss: 298.7914
Epoch [ 566/1800] -> Loss: 298.7914
Epoch [ 567/1800] -> Loss: 298.7914
Epoch [ 568/1800] -> Loss: 298.7914
Epoch [ 569/1800] -> Loss: 298.7914
Epoch [ 570/1800] -> Loss: 298.7914
Epoch [ 571/1800] -> Loss: 298.7914
Epoch [ 572/1800] -> Loss: 298.7914
Epoch [ 573/1800] -> Loss: 298.7914
Epoch [ 574/1800] -> Loss: 298.7914
Epoch [ 575/1800] -> Loss: 298.7914
Epoch [ 576/1800] -> Loss: 298.7914
Epoch [ 577/1800] -> Loss: 298.7914
Epoch [ 578/1800] -> Loss: 298.7914
Epoch [ 579/1800] -> Loss: 298.7914
Epoch [ 580/1800] -> Loss: 298.7914
Epoch [ 581/1800] -> Loss: 298.7914
Epoch [ 582/1800] -> Loss: 298.7914
Epoch [ 583/1800] -> Loss: 298.7914
Epoch [ 584/1800] -> Loss: 298.7914
Epoch [ 585/1800] -> Loss: 298.7914
Epoch [ 586/1800] -> Loss: 298.7914
Epoch [ 587/1800] -> Loss: 298.7914
Epoch [ 588/1800] -> Loss: 298.7914
Epoch [ 589/1800] -> Loss: 298.7914
Epoch [ 590/1800] -> Loss: 298.7914
Epoch [ 591/1800] -> Loss: 298.7914
Epoch [ 592/1800] -> Loss: 298.7914
Epoch [ 593/1800] -> Loss: 298.7914
Epoch [ 594/1800] -> Loss: 298.7914
Epoch [ 595/1800] -> Loss: 298.7914
Epoch [ 596/1800] -> Loss: 298.7914
Epoch [ 597/1800] -> Loss: 298.7914
Epoch [ 598/1800] -> Loss: 298.7914
Epoch [ 599/1800] -> Loss: 298.7914
--------------------------------------------------
Model checkpoint saved as FFNN_600.pth
--------------------------------------------------
Epoch [ 600/1800] -> Loss: 298.7914
Epoch [ 601/1800] -> Loss: 298.7914
Epoch [ 602/1800] -> Loss: 298.7914
Epoch [ 603/1800] -> Loss: 298.7914
Epoch [ 604/1800] -> Loss: 298.7914
Epoch [ 605/1800] -> Loss: 298.7914
Epoch [ 606/1800] -> Loss: 298.7914
Epoch [ 607/1800] -> Loss: 298.7914
Epoch [ 608/1800] -> Loss: 298.7914
Epoch [ 609/1800] -> Loss: 298.7914
Epoch [ 610/1800] -> Loss: 298.7914
Epoch [ 611/1800] -> Loss: 298.7914
Epoch [ 612/1800] -> Loss: 298.7914
Epoch [ 613/1800] -> Loss: 298.7914
Epoch [ 614/1800] -> Loss: 298.7914
Epoch [ 615/1800] -> Loss: 298.7914
Epoch [ 616/1800] -> Loss: 298.7914
Epoch [ 617/1800] -> Loss: 298.7914
Epoch [ 618/1800] -> Loss: 298.7914
Epoch [ 619/1800] -> Loss: 298.7914
Epoch [ 620/1800] -> Loss: 298.7914
Epoch [ 621/1800] -> Loss: 298.7914
Epoch [ 622/1800] -> Loss: 298.7914
Epoch [ 623/1800] -> Loss: 298.7914
Epoch [ 624/1800] -> Loss: 298.7914
Epoch [ 625/1800] -> Loss: 298.7914
Epoch [ 626/1800] -> Loss: 298.7914
Epoch [ 627/1800] -> Loss: 298.7914
Epoch [ 628/1800] -> Loss: 298.7914
Epoch [ 629/1800] -> Loss: 298.7914
Epoch [ 630/1800] -> Loss: 298.7914
Epoch [ 631/1800] -> Loss: 298.7914
Epoch [ 632/1800] -> Loss: 298.7914
Epoch [ 633/1800] -> Loss: 298.7914
Epoch [ 634/1800] -> Loss: 298.7914
Epoch [ 635/1800] -> Loss: 298.7914
Epoch [ 636/1800] -> Loss: 298.7914
Epoch [ 637/1800] -> Loss: 298.7914
Epoch [ 638/1800] -> Loss: 298.7914
Epoch [ 639/1800] -> Loss: 298.7914
Epoch [ 640/1800] -> Loss: 298.7914
Epoch [ 641/1800] -> Loss: 298.7914
Epoch [ 642/1800] -> Loss: 298.7914
Epoch [ 643/1800] -> Loss: 298.7914
Epoch [ 644/1800] -> Loss: 298.7914
Epoch [ 645/1800] -> Loss: 298.7914
Epoch [ 646/1800] -> Loss: 298.7914
Epoch [ 647/1800] -> Loss: 298.7914
Epoch [ 648/1800] -> Loss: 298.7914
Epoch [ 649/1800] -> Loss: 298.7914
--------------------------------------------------
Model checkpoint saved as FFNN_650.pth
--------------------------------------------------
Epoch [ 650/1800] -> Loss: 298.7914
Epoch [ 651/1800] -> Loss: 298.7914
Epoch [ 652/1800] -> Loss: 298.7914
Epoch [ 653/1800] -> Loss: 298.7914
Epoch [ 654/1800] -> Loss: 298.7914
Epoch [ 655/1800] -> Loss: 298.7914
Epoch [ 656/1800] -> Loss: 298.7914
Epoch [ 657/1800] -> Loss: 298.7914
Epoch [ 658/1800] -> Loss: 298.7914
Epoch [ 659/1800] -> Loss: 298.7914
Epoch [ 660/1800] -> Loss: 298.7914
Epoch [ 661/1800] -> Loss: 298.7914

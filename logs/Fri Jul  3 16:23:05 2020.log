Usage: python3 SSN_predictor.py <path_to_ssn_datafile> <path_to_aa_datafile>
----------------------------------------------------------------
Code running on device: cuda
----------------------------------------------------------------
Data loaded from file locations :
    SSN - /home/extern/Documents/Research/scripts/data/SILSO/TSN/SN_m_tot_V2.0.txt
    AA - /home/extern/Documents/Research/scripts/data/ISGI/aa_1869-01-01_2018-12-31_D.dat
----------------------------------------------------------------
Solar cycle data loaded/saved as: cycle_data.pickle
----------------------------------------------------------------
Selected model: FFNN(
  (model): Sequential(
    (0): Linear(in_features=6, out_features=6, bias=True)
    (1): LeakyReLU(negative_slope=0.01, inplace=True)
    (2): Linear(in_features=6, out_features=3, bias=True)
    (3): LeakyReLU(negative_slope=0.01, inplace=True)
    (4): Linear(in_features=3, out_features=1, bias=True)
  )
)    Training mode: True    Testing mode: False
----------------------------------------------------------------
No pre-trained models available, initializing model weights
----------------------------------------------------------------
Training model with: num_epochs=1200, start_lr=0.0002
Epoch [   1/1200] -> Loss: 114.4366
Epoch [   2/1200] -> Loss: 103.1763
Epoch [   3/1200] -> Loss: 80.0063
Epoch [   4/1200] -> Loss: 58.3964
Epoch [   5/1200] -> Loss: 50.0479
Epoch [   6/1200] -> Loss: 49.2422
Epoch [   7/1200] -> Loss: 48.9014
Epoch [   8/1200] -> Loss: 49.1193
Epoch [   9/1200] -> Loss: 48.9426
Epoch [  10/1200] -> Loss: 48.7049
Epoch [  11/1200] -> Loss: 49.1524
Epoch [  12/1200] -> Loss: 48.8668
Epoch [  13/1200] -> Loss: 48.6498
Epoch [  14/1200] -> Loss: 48.5806
Epoch [  15/1200] -> Loss: 48.7824
Epoch [  16/1200] -> Loss: 48.3827
Epoch [  17/1200] -> Loss: 48.6137
Epoch [  18/1200] -> Loss: 48.3554
Epoch [  19/1200] -> Loss: 48.4814
Epoch [  20/1200] -> Loss: 48.3752
Epoch [  21/1200] -> Loss: 48.3870
Epoch [  22/1200] -> Loss: 48.3786
Epoch [  23/1200] -> Loss: 48.2269
Epoch [  24/1200] -> Loss: 48.0440
Epoch [  25/1200] -> Loss: 48.2395
Epoch [  26/1200] -> Loss: 48.4824
Epoch [  27/1200] -> Loss: 48.0318
Epoch [  28/1200] -> Loss: 47.6729
Epoch [  29/1200] -> Loss: 47.7820
Epoch [  30/1200] -> Loss: 47.6232
Epoch [  31/1200] -> Loss: 47.9566
Epoch [  32/1200] -> Loss: 47.6087
Epoch [  33/1200] -> Loss: 47.9922
Epoch [  34/1200] -> Loss: 47.7465
Epoch [  35/1200] -> Loss: 47.7497
Epoch [  36/1200] -> Loss: 47.7083
Epoch [  37/1200] -> Loss: 47.1204
Epoch [  38/1200] -> Loss: 47.7994
Epoch [  39/1200] -> Loss: 47.4781
Epoch [  40/1200] -> Loss: 47.5538
Epoch [  41/1200] -> Loss: 46.9749
Epoch [  42/1200] -> Loss: 47.4887
Epoch [  43/1200] -> Loss: 46.9863
Epoch [  44/1200] -> Loss: 47.2219
Epoch [  45/1200] -> Loss: 47.2169
Epoch [  46/1200] -> Loss: 46.9314
Epoch [  47/1200] -> Loss: 46.9811
Epoch [  48/1200] -> Loss: 46.9772
Epoch [  49/1200] -> Loss: 47.1116
Epoch [  50/1200] -> Loss: 46.9390
Epoch [  51/1200] -> Loss: 46.7283
Epoch [  52/1200] -> Loss: 46.8031
Epoch [  53/1200] -> Loss: 46.9400
Epoch [  54/1200] -> Loss: 46.6028
Epoch [  55/1200] -> Loss: 46.2321
Epoch [  56/1200] -> Loss: 46.6386
Epoch [  57/1200] -> Loss: 46.4889
Epoch [  58/1200] -> Loss: 45.9789

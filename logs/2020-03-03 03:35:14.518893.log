--------------------------------------------------
Code running on device: cuda
--------------------------------------------------
File location :
    SSN - /home/extern/Documents/Research/scripts/data/SILSO/TSN/SN_m_tot_V2.0.txt
    AA - /home/extern/Documents/Research/scripts/data/ISGI/aa_1869-01-01_2018-12-31_D.dat
--------------------------------------------------
Selected model: FFNN(
  (model): Sequential(
    (0): Linear(in_features=6, out_features=6, bias=True)
    (1): LeakyReLU(negative_slope=0.01, inplace=True)
    (2): Linear(in_features=6, out_features=1, bias=True)
  )
)    Training mode: True    Testing mode: False
--------------------------------------------------
No pre-trained models available, initializing model weights
--------------------------------------------------
Training model with: num_epochs=1800, start_lr=0.0005
Epoch [   1/1800] -> Loss: 5783.4728
Epoch [   2/1800] -> Loss: 3166.7225
Epoch [   3/1800] -> Loss: 3111.5007
Epoch [   4/1800] -> Loss: 3078.7213
Epoch [   5/1800] -> Loss: 3048.4628
Epoch [   6/1800] -> Loss: 3017.9894
Epoch [   7/1800] -> Loss: 2986.6574
Epoch [   8/1800] -> Loss: 2956.3135
Epoch [   9/1800] -> Loss: 2923.9133
Epoch [  10/1800] -> Loss: 2890.9963
Epoch [  11/1800] -> Loss: 2857.0801
Epoch [  12/1800] -> Loss: 2822.9900
Epoch [  13/1800] -> Loss: 2788.4164
Epoch [  14/1800] -> Loss: 2753.1167
Epoch [  15/1800] -> Loss: 2717.7280
Epoch [  16/1800] -> Loss: 2681.7782
Epoch [  17/1800] -> Loss: 2645.4095
Epoch [  18/1800] -> Loss: 2608.8580
Epoch [  19/1800] -> Loss: 2572.6069
Epoch [  20/1800] -> Loss: 2536.0728
Epoch [  21/1800] -> Loss: 2499.8140
Epoch [  22/1800] -> Loss: 2463.9663
Epoch [  23/1800] -> Loss: 2428.7753
Epoch [  24/1800] -> Loss: 2394.0638
Epoch [  25/1800] -> Loss: 2360.6317
Epoch [  26/1800] -> Loss: 2327.9943
Epoch [  27/1800] -> Loss: 2296.1262
Epoch [  28/1800] -> Loss: 2265.1172
Epoch [  29/1800] -> Loss: 2235.2300
Epoch [  30/1800] -> Loss: 2206.3879
Epoch [  31/1800] -> Loss: 2178.5345
Epoch [  32/1800] -> Loss: 2151.7117
Epoch [  33/1800] -> Loss: 2125.9252
Epoch [  34/1800] -> Loss: 2101.0547
Epoch [  35/1800] -> Loss: 2077.2432
Epoch [  36/1800] -> Loss: 2054.4345
Epoch [  37/1800] -> Loss: 2032.6296
Epoch [  38/1800] -> Loss: 2011.7513
Epoch [  39/1800] -> Loss: 1991.6857
Epoch [  40/1800] -> Loss: 1972.5995
Epoch [  41/1800] -> Loss: 1954.2715
Epoch [  42/1800] -> Loss: 1936.7171
Epoch [  43/1800] -> Loss: 1919.8759
Epoch [  44/1800] -> Loss: 1903.7273
Epoch [  45/1800] -> Loss: 1888.0924
Epoch [  46/1800] -> Loss: 1873.3227
Epoch [  47/1800] -> Loss: 1859.1439
Epoch [  48/1800] -> Loss: 1845.5280
Epoch [  49/1800] -> Loss: 1832.4226
Epoch [  50/1800] -> Loss: 1819.8479
Epoch [  51/1800] -> Loss: 1807.6375
Epoch [  52/1800] -> Loss: 1795.8732
Epoch [  53/1800] -> Loss: 1784.5476
Epoch [  54/1800] -> Loss: 1773.6162
Epoch [  55/1800] -> Loss: 1762.9094
Epoch [  56/1800] -> Loss: 1752.7324
Epoch [  57/1800] -> Loss: 1742.9153
Epoch [  58/1800] -> Loss: 1733.4125
Epoch [  59/1800] -> Loss: 1724.2189
Epoch [  60/1800] -> Loss: 1715.3288
Epoch [  61/1800] -> Loss: 1706.7209
Epoch [  62/1800] -> Loss: 1698.3899
Epoch [  63/1800] -> Loss: 1690.2078
Epoch [  64/1800] -> Loss: 1682.3698
Epoch [  65/1800] -> Loss: 1674.7510
Epoch [  66/1800] -> Loss: 1667.3753
Epoch [  67/1800] -> Loss: 1660.2377
Epoch [  68/1800] -> Loss: 1653.3163
Epoch [  69/1800] -> Loss: 1646.5934
Epoch [  70/1800] -> Loss: 1640.0741
Epoch [  71/1800] -> Loss: 1633.7481
Epoch [  72/1800] -> Loss: 1627.7077
Epoch [  73/1800] -> Loss: 1621.7736
Epoch [  74/1800] -> Loss: 1615.9955
Epoch [  75/1800] -> Loss: 1610.3874
Epoch [  76/1800] -> Loss: 1604.9284
Epoch [  77/1800] -> Loss: 1599.6094
Epoch [  78/1800] -> Loss: 1594.4368
Epoch [  79/1800] -> Loss: 1589.4313
Epoch [  80/1800] -> Loss: 1584.5675
Epoch [  81/1800] -> Loss: 1579.8431
Epoch [  82/1800] -> Loss: 1575.2438
Epoch [  83/1800] -> Loss: 1570.7815
Epoch [  84/1800] -> Loss: 1566.4342
Epoch [  85/1800] -> Loss: 1562.3119
Epoch [  86/1800] -> Loss: 1558.1989
Epoch [  87/1800] -> Loss: 1554.2123
Epoch [  88/1800] -> Loss: 1550.3400
Epoch [  89/1800] -> Loss: 1546.5743
Epoch [  90/1800] -> Loss: 1542.9118
Epoch [  91/1800] -> Loss: 1539.3493
Epoch [  92/1800] -> Loss: 1535.8833
Epoch [  93/1800] -> Loss: 1532.5054
Epoch [  94/1800] -> Loss: 1529.2144
Epoch [  95/1800] -> Loss: 1526.0161
Epoch [  96/1800] -> Loss: 1522.8810
Epoch [  97/1800] -> Loss: 1519.7510
Epoch [  98/1800] -> Loss: 1516.7763
Epoch [  99/1800] -> Loss: 1513.8879
Epoch [ 100/1800] -> Loss: 1511.0683
Epoch [ 101/1800] -> Loss: 1508.2602
Epoch [ 102/1800] -> Loss: 1505.4850
Epoch [ 103/1800] -> Loss: 1502.7990
Epoch [ 104/1800] -> Loss: 1500.1815
Epoch [ 105/1800] -> Loss: 1497.4655
Epoch [ 106/1800] -> Loss: 1494.7842
Epoch [ 107/1800] -> Loss: 1492.1099
Epoch [ 108/1800] -> Loss: 1488.9474
Epoch [ 109/1800] -> Loss: 1485.9906
Epoch [ 110/1800] -> Loss: 1479.3704
Epoch [ 111/1800] -> Loss: 1476.3246
Epoch [ 112/1800] -> Loss: 1474.0348
Epoch [ 113/1800] -> Loss: 1470.2948
Epoch [ 114/1800] -> Loss: 1467.7681
Epoch [ 115/1800] -> Loss: 1464.7676
Epoch [ 116/1800] -> Loss: 1462.1028
Epoch [ 117/1800] -> Loss: 1459.0365
Epoch [ 118/1800] -> Loss: 1456.3437
Epoch [ 119/1800] -> Loss: 1453.7425
Epoch [ 120/1800] -> Loss: 1451.3207
Epoch [ 121/1800] -> Loss: 1449.0870
Epoch [ 122/1800] -> Loss: 1446.7925
Epoch [ 123/1800] -> Loss: 1443.5341
Epoch [ 124/1800] -> Loss: 1441.4441
Epoch [ 125/1800] -> Loss: 1438.5366
Epoch [ 126/1800] -> Loss: 1435.9534
Epoch [ 127/1800] -> Loss: 1433.3124
Epoch [ 128/1800] -> Loss: 1430.6662
Epoch [ 129/1800] -> Loss: 1427.9668
Epoch [ 130/1800] -> Loss: 1425.3437
Epoch [ 131/1800] -> Loss: 1422.6581
Epoch [ 132/1800] -> Loss: 1420.0100
Epoch [ 133/1800] -> Loss: 1417.7890
Epoch [ 134/1800] -> Loss: 1415.2751
Epoch [ 135/1800] -> Loss: 1412.7997
Epoch [ 136/1800] -> Loss: 1410.5264
Epoch [ 137/1800] -> Loss: 1407.3737
Epoch [ 138/1800] -> Loss: 1405.4025
Epoch [ 139/1800] -> Loss: 1402.9850
Epoch [ 140/1800] -> Loss: 1399.9436
Epoch [ 141/1800] -> Loss: 1397.8347
Epoch [ 142/1800] -> Loss: 1395.3074
Epoch [ 143/1800] -> Loss: 1393.1262
Epoch [ 144/1800] -> Loss: 1390.9808
Epoch [ 145/1800] -> Loss: 1388.3801
Epoch [ 146/1800] -> Loss: 1386.1710
Epoch [ 147/1800] -> Loss: 1383.9771
Epoch [ 148/1800] -> Loss: 1381.7267
Epoch [ 149/1800] -> Loss: 1379.4492
Epoch [ 150/1800] -> Loss: 1377.9758
Epoch [ 151/1800] -> Loss: 1375.6402
Epoch [ 152/1800] -> Loss: 1373.9596
Epoch [ 153/1800] -> Loss: 1371.3061
Epoch [ 154/1800] -> Loss: 1370.2128
Epoch [ 155/1800] -> Loss: 1367.8686
Epoch [ 156/1800] -> Loss: 1365.2383
Epoch [ 157/1800] -> Loss: 1364.6267
Epoch [ 158/1800] -> Loss: 1362.8491
Epoch [ 159/1800] -> Loss: 1361.4399
Epoch [ 160/1800] -> Loss: 1359.6875
Epoch [ 161/1800] -> Loss: 1357.4633
Epoch [ 162/1800] -> Loss: 1356.8608
Epoch [ 163/1800] -> Loss: 1355.3402
Epoch [ 164/1800] -> Loss: 1353.6390
Epoch [ 165/1800] -> Loss: 1352.0926
Epoch [ 166/1800] -> Loss: 1350.2416
Epoch [ 167/1800] -> Loss: 1349.1712
Epoch [ 168/1800] -> Loss: 1347.4955
Epoch [ 169/1800] -> Loss: 1345.6132
Epoch [ 170/1800] -> Loss: 1345.4193
Epoch [ 171/1800] -> Loss: 1344.2834
Epoch [ 172/1800] -> Loss: 1342.0730
Epoch [ 173/1800] -> Loss: 1341.5731
Epoch [ 174/1800] -> Loss: 1341.5197
Epoch [ 175/1800] -> Loss: 1339.1836
Epoch [ 176/1800] -> Loss: 1338.0404
Epoch [ 177/1800] -> Loss: 1336.9065
Epoch [ 178/1800] -> Loss: 1336.8780
Epoch [ 179/1800] -> Loss: 1335.4434
Epoch [ 180/1800] -> Loss: 1334.5377
Epoch [ 181/1800] -> Loss: 1333.4184
Epoch [ 182/1800] -> Loss: 1332.3590
Epoch [ 183/1800] -> Loss: 1332.2738
Epoch [ 184/1800] -> Loss: 1330.6838
Epoch [ 185/1800] -> Loss: 1330.4047
Epoch [ 186/1800] -> Loss: 1328.4415
Epoch [ 187/1800] -> Loss: 1328.3832
Epoch [ 188/1800] -> Loss: 1326.3137
Epoch [ 189/1800] -> Loss: 1326.1741
Epoch [ 190/1800] -> Loss: 1325.3579
Epoch [ 191/1800] -> Loss: 1323.8949
Epoch [ 192/1800] -> Loss: 1323.8606
Epoch [ 193/1800] -> Loss: 1322.9919
Epoch [ 194/1800] -> Loss: 1322.0921
Epoch [ 195/1800] -> Loss: 1321.4289
Epoch [ 196/1800] -> Loss: 1320.9163
Epoch [ 197/1800] -> Loss: 1320.3755
Epoch [ 198/1800] -> Loss: 1319.6678
Epoch [ 199/1800] -> Loss: 1318.6398
--------------------------------------------------
Model checkpoint saved as FFNN_200.pth
--------------------------------------------------
Epoch [ 200/1800] -> Loss: 1317.9446
Epoch [ 201/1800] -> Loss: 1317.3786
Epoch [ 202/1800] -> Loss: 1316.6165
Epoch [ 203/1800] -> Loss: 1315.7087
Epoch [ 204/1800] -> Loss: 1315.2614
Epoch [ 205/1800] -> Loss: 1314.9572
Epoch [ 206/1800] -> Loss: 1313.8056
Epoch [ 207/1800] -> Loss: 1312.4492
Epoch [ 208/1800] -> Loss: 1311.1800
Epoch [ 209/1800] -> Loss: 1310.0962
Epoch [ 210/1800] -> Loss: 1309.4272
Epoch [ 211/1800] -> Loss: 1308.5828
Epoch [ 212/1800] -> Loss: 1308.0834
Epoch [ 213/1800] -> Loss: 1307.4589
Epoch [ 214/1800] -> Loss: 1306.4946
Epoch [ 215/1800] -> Loss: 1305.8284
Epoch [ 216/1800] -> Loss: 1305.2691
Epoch [ 217/1800] -> Loss: 1304.1769
Epoch [ 218/1800] -> Loss: 1303.3926
Epoch [ 219/1800] -> Loss: 1302.6554
Epoch [ 220/1800] -> Loss: 1301.9748
Epoch [ 221/1800] -> Loss: 1300.7464
Epoch [ 222/1800] -> Loss: 1299.9831
Epoch [ 223/1800] -> Loss: 1299.1947
Epoch [ 224/1800] -> Loss: 1298.4293
Epoch [ 225/1800] -> Loss: 1297.8450
Epoch [ 226/1800] -> Loss: 1296.8947
Epoch [ 227/1800] -> Loss: 1295.7024
Epoch [ 228/1800] -> Loss: 1294.9725
Epoch [ 229/1800] -> Loss: 1293.8064
Epoch [ 230/1800] -> Loss: 1292.9567
Epoch [ 231/1800] -> Loss: 1291.2465
Epoch [ 232/1800] -> Loss: 1290.4592
Epoch [ 233/1800] -> Loss: 1289.9565
Epoch [ 234/1800] -> Loss: 1289.3334
Epoch [ 235/1800] -> Loss: 1289.0081
Epoch [ 236/1800] -> Loss: 1288.6266
Epoch [ 237/1800] -> Loss: 1288.0378
Epoch [ 238/1800] -> Loss: 1287.6031
Epoch [ 239/1800] -> Loss: 1287.8080
Epoch [ 240/1800] -> Loss: 1287.3651
Epoch [ 241/1800] -> Loss: 1286.8921
Epoch [ 242/1800] -> Loss: 1286.4777
Epoch [ 243/1800] -> Loss: 1286.0674
Epoch [ 244/1800] -> Loss: 1285.4385
Epoch [ 245/1800] -> Loss: 1285.0154
Epoch [ 246/1800] -> Loss: 1284.7446
Epoch [ 247/1800] -> Loss: 1284.3564
Epoch [ 248/1800] -> Loss: 1284.1674
Epoch [ 249/1800] -> Loss: 1283.7119
Epoch [ 250/1800] -> Loss: 1283.0726
Epoch [ 251/1800] -> Loss: 1282.8518
Epoch [ 252/1800] -> Loss: 1282.3944
Epoch [ 253/1800] -> Loss: 1281.7697
Epoch [ 254/1800] -> Loss: 1281.4372
Epoch [ 255/1800] -> Loss: 1281.0163
Epoch [ 256/1800] -> Loss: 1280.4716
Epoch [ 257/1800] -> Loss: 1280.1309
Epoch [ 258/1800] -> Loss: 1279.7928
Epoch [ 259/1800] -> Loss: 1279.4081
Epoch [ 260/1800] -> Loss: 1279.1862
Epoch [ 261/1800] -> Loss: 1278.7175
Epoch [ 262/1800] -> Loss: 1278.4446
Epoch [ 263/1800] -> Loss: 1277.9135
Epoch [ 264/1800] -> Loss: 1277.2676
Epoch [ 265/1800] -> Loss: 1276.6118
Epoch [ 266/1800] -> Loss: 1276.0035
Epoch [ 267/1800] -> Loss: 1275.5478
Epoch [ 268/1800] -> Loss: 1275.2428
Epoch [ 269/1800] -> Loss: 1274.9450
Epoch [ 270/1800] -> Loss: 1274.5597
Epoch [ 271/1800] -> Loss: 1273.7525
Epoch [ 272/1800] -> Loss: 1273.5234
Epoch [ 273/1800] -> Loss: 1272.0770
Epoch [ 274/1800] -> Loss: 1270.8378
Epoch [ 275/1800] -> Loss: 1270.3727
Epoch [ 276/1800] -> Loss: 1269.8897
Epoch [ 277/1800] -> Loss: 1269.5027
Epoch [ 278/1800] -> Loss: 1268.2149
Epoch [ 279/1800] -> Loss: 1269.1659
Epoch [ 280/1800] -> Loss: 1267.4966
Epoch [ 281/1800] -> Loss: 1266.9244
Epoch [ 282/1800] -> Loss: 1267.8974
Epoch [ 283/1800] -> Loss: 1266.5590
Epoch [ 284/1800] -> Loss: 1266.1707
Epoch [ 285/1800] -> Loss: 1265.7903
Epoch [ 286/1800] -> Loss: 1265.6009
Epoch [ 287/1800] -> Loss: 1265.6420
Epoch [ 288/1800] -> Loss: 1265.7664
Epoch [ 289/1800] -> Loss: 1265.4755
Epoch [ 290/1800] -> Loss: 1264.8918
Epoch [ 291/1800] -> Loss: 1264.7981
Epoch [ 292/1800] -> Loss: 1264.7046
Epoch [ 293/1800] -> Loss: 1264.4340
Epoch [ 294/1800] -> Loss: 1263.9987
Epoch [ 295/1800] -> Loss: 1263.6654
Epoch [ 296/1800] -> Loss: 1263.3963
Epoch [ 297/1800] -> Loss: 1263.9183
Epoch [ 298/1800] -> Loss: 1262.9567
Epoch [ 299/1800] -> Loss: 1262.8021
Epoch [ 300/1800] -> Loss: 1262.3882
Epoch [ 301/1800] -> Loss: 1262.3652
Epoch [ 302/1800] -> Loss: 1262.7187
Epoch [ 303/1800] -> Loss: 1261.9349
Epoch [ 304/1800] -> Loss: 1261.6164
Epoch [ 305/1800] -> Loss: 1260.9526
Epoch [ 306/1800] -> Loss: 1261.3077
Epoch [ 307/1800] -> Loss: 1259.9236
Epoch [ 308/1800] -> Loss: 1259.9624
Epoch [ 309/1800] -> Loss: 1260.2454
Epoch [ 310/1800] -> Loss: 1259.6539
Epoch [ 311/1800] -> Loss: 1259.4971
Epoch [ 312/1800] -> Loss: 1259.2856
Epoch [ 313/1800] -> Loss: 1258.8995
Epoch [ 314/1800] -> Loss: 1258.1497
Epoch [ 315/1800] -> Loss: 1257.9524
Epoch [ 316/1800] -> Loss: 1257.8326

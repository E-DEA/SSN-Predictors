Usage: python3 SSN_predictor.py <path_to_ssn_datafile> <path_to_aa_datafile>
----------------------------------------------------------------
Code running on device: cuda
----------------------------------------------------------------
Data loaded from file locations :
    SSN - /home/extern/Documents/Research/scripts/data/SILSO/TSN/SN_m_tot_V2.0.txt
    AA - /home/extern/Documents/Research/scripts/data/ISGI/aa_1869-01-01_2018-12-31_D.dat
----------------------------------------------------------------
Solar cycle data loaded/saved as: cycle_data.pickle
----------------------------------------------------------------
Selected model: FFNN(
  (model): Sequential(
    (0): Linear(in_features=6, out_features=6, bias=True)
    (1): LeakyReLU(negative_slope=0.01, inplace=True)
    (2): Linear(in_features=6, out_features=3, bias=True)
    (3): LeakyReLU(negative_slope=0.01, inplace=True)
    (4): Linear(in_features=3, out_features=1, bias=True)
  )
)    Training mode: True    Testing mode: False
----------------------------------------------------------------
No pre-trained models available, initializing model weights
----------------------------------------------------------------
Training model with: num_epochs=1200, start_lr=0.0001
Epoch [   1/1200] -> Loss: 128.5553
Epoch [   2/1200] -> Loss: 128.4650
Epoch [   3/1200] -> Loss: 129.6667
Epoch [   4/1200] -> Loss: 128.0462
Epoch [   5/1200] -> Loss: 126.8438
Epoch [   6/1200] -> Loss: 127.7596
Epoch [   7/1200] -> Loss: 128.0976
Epoch [   8/1200] -> Loss: 127.2908
Epoch [   9/1200] -> Loss: 127.0402
Epoch [  10/1200] -> Loss: 128.0244
Epoch [  11/1200] -> Loss: 126.6139
Epoch [  12/1200] -> Loss: 126.6537
Epoch [  13/1200] -> Loss: 126.7151
Epoch [  14/1200] -> Loss: 126.4565
Epoch [  15/1200] -> Loss: 126.4660
Epoch [  16/1200] -> Loss: 126.8503
Epoch [  17/1200] -> Loss: 125.9435
Epoch [  18/1200] -> Loss: 126.9921
Epoch [  19/1200] -> Loss: 127.2106
Epoch [  20/1200] -> Loss: 125.8678
Epoch [  21/1200] -> Loss: 126.9580
Epoch [  22/1200] -> Loss: 125.7277
Epoch [  23/1200] -> Loss: 125.0946
Epoch [  24/1200] -> Loss: 123.6561
Epoch [  25/1200] -> Loss: 125.0508
Epoch [  26/1200] -> Loss: 126.3996
Epoch [  27/1200] -> Loss: 124.7617
Epoch [  28/1200] -> Loss: 123.0847
Epoch [  29/1200] -> Loss: 123.7650
Epoch [  30/1200] -> Loss: 125.0155
Epoch [  31/1200] -> Loss: 123.4032
Epoch [  32/1200] -> Loss: 123.2485
Epoch [  33/1200] -> Loss: 123.3184
Epoch [  34/1200] -> Loss: 123.0033
Epoch [  35/1200] -> Loss: 122.1762
Epoch [  36/1200] -> Loss: 123.2347
Epoch [  37/1200] -> Loss: 121.8421
Epoch [  38/1200] -> Loss: 122.0916
Epoch [  39/1200] -> Loss: 122.0216
Epoch [  40/1200] -> Loss: 121.0761
Epoch [  41/1200] -> Loss: 122.6010
Epoch [  42/1200] -> Loss: 122.4652
Epoch [  43/1200] -> Loss: 120.9007
Epoch [  44/1200] -> Loss: 121.7728
Epoch [  45/1200] -> Loss: 119.0530
Epoch [  46/1200] -> Loss: 121.9643
Epoch [  47/1200] -> Loss: 121.5561
Epoch [  48/1200] -> Loss: 119.8737
Epoch [  49/1200] -> Loss: 118.9558
Epoch [  50/1200] -> Loss: 118.8446
Epoch [  51/1200] -> Loss: 119.2398
Epoch [  52/1200] -> Loss: 118.4351
Epoch [  53/1200] -> Loss: 117.3161
Epoch [  54/1200] -> Loss: 116.5943
Epoch [  55/1200] -> Loss: 115.5076
Epoch [  56/1200] -> Loss: 115.6751
Epoch [  57/1200] -> Loss: 116.2767
Epoch [  58/1200] -> Loss: 115.2762
Epoch [  59/1200] -> Loss: 115.7369
Epoch [  60/1200] -> Loss: 115.3918
Epoch [  61/1200] -> Loss: 114.0342
Epoch [  62/1200] -> Loss: 113.1713
Epoch [  63/1200] -> Loss: 115.1011
Epoch [  64/1200] -> Loss: 112.3622
Epoch [  65/1200] -> Loss: 112.1531
Epoch [  66/1200] -> Loss: 113.3656
Epoch [  67/1200] -> Loss: 112.9515
Epoch [  68/1200] -> Loss: 111.1936
Epoch [  69/1200] -> Loss: 111.5120
Epoch [  70/1200] -> Loss: 110.6448
Epoch [  71/1200] -> Loss: 109.9371
Epoch [  72/1200] -> Loss: 109.2523
Epoch [  73/1200] -> Loss: 109.0692
Epoch [  74/1200] -> Loss: 107.7275
Epoch [  75/1200] -> Loss: 108.6770
Epoch [  76/1200] -> Loss: 107.7303
Epoch [  77/1200] -> Loss: 107.3493
Epoch [  78/1200] -> Loss: 107.2857
Epoch [  79/1200] -> Loss: 107.0963
Epoch [  80/1200] -> Loss: 105.1765
Epoch [  81/1200] -> Loss: 105.9885
Epoch [  82/1200] -> Loss: 105.9783
Epoch [  83/1200] -> Loss: 106.1291
Epoch [  84/1200] -> Loss: 104.6151
Epoch [  85/1200] -> Loss: 104.2970
Epoch [  86/1200] -> Loss: 104.4717
Epoch [  87/1200] -> Loss: 103.5530
Epoch [  88/1200] -> Loss: 103.2078
Epoch [  89/1200] -> Loss: 102.1380
Epoch [  90/1200] -> Loss: 103.3504
Epoch [  91/1200] -> Loss: 101.1418
Epoch [  92/1200] -> Loss: 101.0949
Epoch [  93/1200] -> Loss: 100.0809
Epoch [  94/1200] -> Loss: 101.4298
Epoch [  95/1200] -> Loss: 99.6533
Epoch [  96/1200] -> Loss: 101.1130
Epoch [  97/1200] -> Loss: 98.9460
Epoch [  98/1200] -> Loss: 99.2583
Epoch [  99/1200] -> Loss: 99.1258
----------------------------------------------------------------
Model checkpoint saved as FFNN_100.pth
----------------------------------------------------------------
Epoch [ 100/1200] -> Loss: 98.2484
Epoch [ 101/1200] -> Loss: 97.6993
Epoch [ 102/1200] -> Loss: 97.3171
Epoch [ 103/1200] -> Loss: 96.8208
Epoch [ 104/1200] -> Loss: 96.2652
Epoch [ 105/1200] -> Loss: 94.2845
Epoch [ 106/1200] -> Loss: 96.4543
Epoch [ 107/1200] -> Loss: 96.2726
Epoch [ 108/1200] -> Loss: 93.5241
Epoch [ 109/1200] -> Loss: 94.7196
Epoch [ 110/1200] -> Loss: 94.7015
Epoch [ 111/1200] -> Loss: 95.5574
Epoch [ 112/1200] -> Loss: 94.3829
Epoch [ 113/1200] -> Loss: 93.5142
Epoch [ 114/1200] -> Loss: 92.8375
Epoch [ 115/1200] -> Loss: 92.4951
Epoch [ 116/1200] -> Loss: 92.4476
Epoch [ 117/1200] -> Loss: 91.3870
Epoch [ 118/1200] -> Loss: 91.8704
Epoch [ 119/1200] -> Loss: 91.6653
Epoch [ 120/1200] -> Loss: 91.2400
Epoch [ 121/1200] -> Loss: 92.5479
Epoch [ 122/1200] -> Loss: 89.7886
Epoch [ 123/1200] -> Loss: 89.8456
Epoch [ 124/1200] -> Loss: 89.9394
Epoch [ 125/1200] -> Loss: 89.9521
Epoch [ 126/1200] -> Loss: 90.3344
Epoch [ 127/1200] -> Loss: 88.0318
Epoch [ 128/1200] -> Loss: 88.2346
Epoch [ 129/1200] -> Loss: 88.1584
Epoch [ 130/1200] -> Loss: 87.7829
Epoch [ 131/1200] -> Loss: 89.0459
Epoch [ 132/1200] -> Loss: 87.0296
Epoch [ 133/1200] -> Loss: 87.3320
Epoch [ 134/1200] -> Loss: 86.1993
Epoch [ 135/1200] -> Loss: 86.4015
Epoch [ 136/1200] -> Loss: 85.1089
Epoch [ 137/1200] -> Loss: 86.6285
Epoch [ 138/1200] -> Loss: 85.5461
Epoch [ 139/1200] -> Loss: 83.6897
Epoch [ 140/1200] -> Loss: 84.6637
Epoch [ 141/1200] -> Loss: 84.1304
Epoch [ 142/1200] -> Loss: 84.0133
Epoch [ 143/1200] -> Loss: 82.5773
Epoch [ 144/1200] -> Loss: 82.8863
Epoch [ 145/1200] -> Loss: 81.9226
Epoch [ 146/1200] -> Loss: 81.9657
Epoch [ 147/1200] -> Loss: 82.4173
Epoch [ 148/1200] -> Loss: 81.1962
Epoch [ 149/1200] -> Loss: 80.3544
Epoch [ 150/1200] -> Loss: 80.3241
Epoch [ 151/1200] -> Loss: 79.8378
Epoch [ 152/1200] -> Loss: 80.4565
Epoch [ 153/1200] -> Loss: 79.8797
Epoch [ 154/1200] -> Loss: 79.4707
Epoch [ 155/1200] -> Loss: 79.4407
Epoch [ 156/1200] -> Loss: 77.9059
Epoch [ 157/1200] -> Loss: 78.4188
Epoch [ 158/1200] -> Loss: 79.3020
Epoch [ 159/1200] -> Loss: 77.3072
Epoch [ 160/1200] -> Loss: 75.9126
Epoch [ 161/1200] -> Loss: 75.9039
Epoch [ 162/1200] -> Loss: 77.1703
Epoch [ 163/1200] -> Loss: 76.4094
Epoch [ 164/1200] -> Loss: 75.4912
Epoch [ 165/1200] -> Loss: 75.7146
Epoch [ 166/1200] -> Loss: 75.7723
Epoch [ 167/1200] -> Loss: 74.5711
Epoch [ 168/1200] -> Loss: 74.4396
Epoch [ 169/1200] -> Loss: 74.6127
Epoch [ 170/1200] -> Loss: 72.1765
Epoch [ 171/1200] -> Loss: 72.9528
Epoch [ 172/1200] -> Loss: 72.1655
Epoch [ 173/1200] -> Loss: 71.7636
Epoch [ 174/1200] -> Loss: 71.7978
Epoch [ 175/1200] -> Loss: 71.3549
Epoch [ 176/1200] -> Loss: 71.4298
Epoch [ 177/1200] -> Loss: 70.9223
Epoch [ 178/1200] -> Loss: 71.0214
Epoch [ 179/1200] -> Loss: 70.5361
Epoch [ 180/1200] -> Loss: 71.0385
Epoch [ 181/1200] -> Loss: 69.6362
Epoch [ 182/1200] -> Loss: 69.0501
Epoch [ 183/1200] -> Loss: 68.9937
Epoch [ 184/1200] -> Loss: 68.3043
Epoch [ 185/1200] -> Loss: 68.5237
Epoch [ 186/1200] -> Loss: 68.3506
Epoch [ 187/1200] -> Loss: 67.6987
Epoch [ 188/1200] -> Loss: 67.3089
Epoch [ 189/1200] -> Loss: 67.0395
Epoch [ 190/1200] -> Loss: 66.5340
Epoch [ 191/1200] -> Loss: 67.6676
Epoch [ 192/1200] -> Loss: 65.9016
Epoch [ 193/1200] -> Loss: 65.8980
Epoch [ 194/1200] -> Loss: 65.0078
Epoch [ 195/1200] -> Loss: 66.4737
Epoch [ 196/1200] -> Loss: 65.7422
Epoch [ 197/1200] -> Loss: 64.6719
Epoch [ 198/1200] -> Loss: 64.1245
Epoch [ 199/1200] -> Loss: 63.8662
----------------------------------------------------------------
Model checkpoint saved as FFNN_200.pth
----------------------------------------------------------------
Epoch [ 200/1200] -> Loss: 65.2536
Epoch [ 201/1200] -> Loss: 62.2412
Epoch [ 202/1200] -> Loss: 64.3587
Epoch [ 203/1200] -> Loss: 61.7532
Epoch [ 204/1200] -> Loss: 63.1724
Epoch [ 205/1200] -> Loss: 62.4586
Epoch [ 206/1200] -> Loss: 61.4581
Epoch [ 207/1200] -> Loss: 62.2647
Epoch [ 208/1200] -> Loss: 61.1717
Epoch [ 209/1200] -> Loss: 61.0236
Epoch [ 210/1200] -> Loss: 60.2263
Epoch [ 211/1200] -> Loss: 61.2718
Epoch [ 212/1200] -> Loss: 60.3184
Epoch [ 213/1200] -> Loss: 60.1696
Epoch [ 214/1200] -> Loss: 60.7183
Epoch [ 215/1200] -> Loss: 60.5508
Epoch [ 216/1200] -> Loss: 59.5966
Epoch [ 217/1200] -> Loss: 60.5798
Epoch [ 218/1200] -> Loss: 59.2690
Epoch [ 219/1200] -> Loss: 59.2428
Epoch [ 220/1200] -> Loss: 59.6657
Epoch [ 221/1200] -> Loss: 59.2257
Epoch [ 222/1200] -> Loss: 59.3789
Epoch [ 223/1200] -> Loss: 57.3634
Epoch [ 224/1200] -> Loss: 59.8518
Epoch [ 225/1200] -> Loss: 58.4956
Epoch [ 226/1200] -> Loss: 56.9796
Epoch [ 227/1200] -> Loss: 57.4898
Epoch [ 228/1200] -> Loss: 58.2119
Epoch [ 229/1200] -> Loss: 58.9387
Epoch [ 230/1200] -> Loss: 57.3041
Epoch [ 231/1200] -> Loss: 57.9304
Epoch [ 232/1200] -> Loss: 55.9405
Epoch [ 233/1200] -> Loss: 58.0978
Epoch [ 234/1200] -> Loss: 56.9445
Epoch [ 235/1200] -> Loss: 56.5107
Epoch [ 236/1200] -> Loss: 57.0853
Epoch [ 237/1200] -> Loss: 57.0781
Epoch [ 238/1200] -> Loss: 56.4128
Epoch [ 239/1200] -> Loss: 57.0086
Epoch [ 240/1200] -> Loss: 55.6675
Epoch [ 241/1200] -> Loss: 57.3300
Epoch [ 242/1200] -> Loss: 56.2316
Epoch [ 243/1200] -> Loss: 56.8657
Epoch [ 244/1200] -> Loss: 56.6447
Epoch [ 245/1200] -> Loss: 55.7615
Epoch [ 246/1200] -> Loss: 56.4306
Epoch [ 247/1200] -> Loss: 55.8546
Epoch [ 248/1200] -> Loss: 56.2000
Epoch [ 249/1200] -> Loss: 55.5185
Epoch [ 250/1200] -> Loss: 56.1455
Epoch [ 251/1200] -> Loss: 56.4570
Epoch [ 252/1200] -> Loss: 55.0723
Epoch [ 253/1200] -> Loss: 55.1728
Epoch [ 254/1200] -> Loss: 54.9749
Epoch [ 255/1200] -> Loss: 55.2660
Epoch [ 256/1200] -> Loss: 55.8418
Epoch [ 257/1200] -> Loss: 55.9882
Epoch [ 258/1200] -> Loss: 56.4249
Epoch [ 259/1200] -> Loss: 57.1440
Epoch [ 260/1200] -> Loss: 55.4054
Epoch [ 261/1200] -> Loss: 55.3868
Epoch [ 262/1200] -> Loss: 54.1397
Epoch [ 263/1200] -> Loss: 55.5548
Epoch [ 264/1200] -> Loss: 54.6996
Epoch [ 265/1200] -> Loss: 55.1079
Epoch [ 266/1200] -> Loss: 55.6803
Epoch [ 267/1200] -> Loss: 55.5047
Epoch [ 268/1200] -> Loss: 56.6406
Epoch [ 269/1200] -> Loss: 54.8826
Epoch [ 270/1200] -> Loss: 56.1137
Epoch [ 271/1200] -> Loss: 54.2163
Epoch [ 272/1200] -> Loss: 54.5610
Epoch   273: reducing learning rate of group 0 to 5.0000e-05.
Epoch [ 273/1200] -> Loss: 54.9142
Epoch [ 274/1200] -> Loss: 54.9235
Epoch [ 275/1200] -> Loss: 54.4098
Epoch [ 276/1200] -> Loss: 55.3022
Epoch [ 277/1200] -> Loss: 55.6525
Epoch [ 278/1200] -> Loss: 54.5923
Epoch [ 279/1200] -> Loss: 55.3658
Epoch [ 280/1200] -> Loss: 55.3102
Epoch [ 281/1200] -> Loss: 54.6846
Epoch [ 282/1200] -> Loss: 54.7047
Epoch [ 283/1200] -> Loss: 54.9709
Epoch   284: reducing learning rate of group 0 to 2.5000e-05.
Epoch [ 284/1200] -> Loss: 55.2053
Epoch [ 285/1200] -> Loss: 55.0403
Epoch [ 286/1200] -> Loss: 55.9054
Epoch [ 287/1200] -> Loss: 55.4729
Epoch [ 288/1200] -> Loss: 55.2140
Epoch [ 289/1200] -> Loss: 54.5247
Epoch [ 290/1200] -> Loss: 54.9342
Epoch [ 291/1200] -> Loss: 54.4564
Epoch [ 292/1200] -> Loss: 54.3801
Epoch [ 293/1200] -> Loss: 55.3383
Epoch [ 294/1200] -> Loss: 54.4741
Epoch   295: reducing learning rate of group 0 to 1.2500e-05.
Epoch [ 295/1200] -> Loss: 54.9080
Epoch [ 296/1200] -> Loss: 54.9882
Epoch [ 297/1200] -> Loss: 55.7901
Epoch [ 298/1200] -> Loss: 54.7611
Epoch [ 299/1200] -> Loss: 56.2558
----------------------------------------------------------------
Model checkpoint saved as FFNN_300.pth
----------------------------------------------------------------
Epoch [ 300/1200] -> Loss: 55.6429
Epoch [ 301/1200] -> Loss: 54.6101
Epoch [ 302/1200] -> Loss: 55.1310
Epoch [ 303/1200] -> Loss: 55.8202
Epoch [ 304/1200] -> Loss: 55.3821
Epoch [ 305/1200] -> Loss: 55.3616
Epoch   306: reducing learning rate of group 0 to 6.2500e-06.
Epoch [ 306/1200] -> Loss: 55.2803
Epoch [ 307/1200] -> Loss: 54.9183
Epoch [ 308/1200] -> Loss: 55.1648
Epoch [ 309/1200] -> Loss: 55.0208
Epoch [ 310/1200] -> Loss: 55.4364
Epoch [ 311/1200] -> Loss: 55.5571
Epoch [ 312/1200] -> Loss: 54.8596
Epoch [ 313/1200] -> Loss: 54.7831
Epoch [ 314/1200] -> Loss: 54.5769
Epoch [ 315/1200] -> Loss: 55.2613
Epoch [ 316/1200] -> Loss: 54.2511
Epoch   317: reducing learning rate of group 0 to 3.1250e-06.
Epoch [ 317/1200] -> Loss: 55.3162
Epoch [ 318/1200] -> Loss: 54.9545
Epoch [ 319/1200] -> Loss: 55.0161
Epoch [ 320/1200] -> Loss: 54.8551
Epoch [ 321/1200] -> Loss: 55.1478
Epoch [ 322/1200] -> Loss: 55.6063
Epoch [ 323/1200] -> Loss: 55.5291
Epoch [ 324/1200] -> Loss: 54.4781
Epoch [ 325/1200] -> Loss: 55.5183
Epoch [ 326/1200] -> Loss: 54.7585
Epoch [ 327/1200] -> Loss: 55.8705
Epoch   328: reducing learning rate of group 0 to 1.5625e-06.
Epoch [ 328/1200] -> Loss: 55.0711
Epoch [ 329/1200] -> Loss: 54.8036
Epoch [ 330/1200] -> Loss: 55.1386
Epoch [ 331/1200] -> Loss: 55.6150
Epoch [ 332/1200] -> Loss: 55.1573
Epoch [ 333/1200] -> Loss: 54.4625
Epoch [ 334/1200] -> Loss: 55.2353
Epoch [ 335/1200] -> Loss: 55.5626
Epoch [ 336/1200] -> Loss: 54.5124
Epoch [ 337/1200] -> Loss: 55.3806
Epoch [ 338/1200] -> Loss: 55.1183
Epoch [ 339/1200] -> Loss: 54.0362
Epoch [ 340/1200] -> Loss: 55.0605
Epoch [ 341/1200] -> Loss: 54.7107
Epoch [ 342/1200] -> Loss: 55.4277
Epoch [ 343/1200] -> Loss: 55.6299
Epoch [ 344/1200] -> Loss: 54.7592
Epoch [ 345/1200] -> Loss: 55.3827
Epoch [ 346/1200] -> Loss: 55.4118
Epoch [ 347/1200] -> Loss: 56.0363
Epoch [ 348/1200] -> Loss: 54.7887
Epoch [ 349/1200] -> Loss: 54.3783
Epoch   350: reducing learning rate of group 0 to 7.8125e-07.
Epoch [ 350/1200] -> Loss: 55.7549
Epoch [ 351/1200] -> Loss: 54.8516
Epoch [ 352/1200] -> Loss: 55.0458
Epoch [ 353/1200] -> Loss: 55.3275
Epoch [ 354/1200] -> Loss: 54.6514
Epoch [ 355/1200] -> Loss: 55.0778
Epoch [ 356/1200] -> Loss: 54.8216
Epoch [ 357/1200] -> Loss: 54.7887
Epoch [ 358/1200] -> Loss: 56.0489
Epoch [ 359/1200] -> Loss: 55.1037
Epoch [ 360/1200] -> Loss: 54.8693
Epoch   361: reducing learning rate of group 0 to 3.9063e-07.
Epoch [ 361/1200] -> Loss: 55.7637
Epoch [ 362/1200] -> Loss: 54.1131
Epoch [ 363/1200] -> Loss: 53.9385
Epoch [ 364/1200] -> Loss: 55.7472
Epoch [ 365/1200] -> Loss: 54.7809
Epoch [ 366/1200] -> Loss: 55.2157
Epoch [ 367/1200] -> Loss: 55.1410
Epoch [ 368/1200] -> Loss: 55.6435
Epoch [ 369/1200] -> Loss: 54.7833
Epoch [ 370/1200] -> Loss: 54.9075
Epoch [ 371/1200] -> Loss: 54.7749
Epoch [ 372/1200] -> Loss: 54.8957
Epoch [ 373/1200] -> Loss: 55.3530
Epoch   374: reducing learning rate of group 0 to 1.9531e-07.
Epoch [ 374/1200] -> Loss: 54.6217
Epoch [ 375/1200] -> Loss: 55.7314
Epoch [ 376/1200] -> Loss: 56.2755
Epoch [ 377/1200] -> Loss: 54.7715
Epoch [ 378/1200] -> Loss: 55.3880
Epoch [ 379/1200] -> Loss: 56.1380
Epoch [ 380/1200] -> Loss: 54.3749
Epoch [ 381/1200] -> Loss: 54.5280
Epoch [ 382/1200] -> Loss: 54.8840
Epoch [ 383/1200] -> Loss: 55.5881
Epoch [ 384/1200] -> Loss: 55.0188
Epoch   385: reducing learning rate of group 0 to 9.7656e-08.
Epoch [ 385/1200] -> Loss: 55.3203
Epoch [ 386/1200] -> Loss: 55.2690
Epoch [ 387/1200] -> Loss: 55.1093
Epoch [ 388/1200] -> Loss: 55.1272
Epoch [ 389/1200] -> Loss: 55.8310
Epoch [ 390/1200] -> Loss: 54.4517
Epoch [ 391/1200] -> Loss: 54.6147
Epoch [ 392/1200] -> Loss: 55.1367
Epoch [ 393/1200] -> Loss: 54.1239
Epoch [ 394/1200] -> Loss: 54.5336
Epoch [ 395/1200] -> Loss: 54.8468
Epoch   396: reducing learning rate of group 0 to 4.8828e-08.
Epoch [ 396/1200] -> Loss: 56.0773
Epoch [ 397/1200] -> Loss: 55.6885
Epoch [ 398/1200] -> Loss: 54.9798
Epoch [ 399/1200] -> Loss: 54.5943
----------------------------------------------------------------
Model checkpoint saved as FFNN_400.pth
----------------------------------------------------------------
Epoch [ 400/1200] -> Loss: 55.5631
Epoch [ 401/1200] -> Loss: 55.1108
Epoch [ 402/1200] -> Loss: 55.2771
Epoch [ 403/1200] -> Loss: 55.0599
Epoch [ 404/1200] -> Loss: 54.6251
Epoch [ 405/1200] -> Loss: 55.1331
Epoch [ 406/1200] -> Loss: 55.4377
Epoch   407: reducing learning rate of group 0 to 2.4414e-08.
Epoch [ 407/1200] -> Loss: 54.8688
Epoch [ 408/1200] -> Loss: 55.1913
Epoch [ 409/1200] -> Loss: 55.5051
Epoch [ 410/1200] -> Loss: 56.1348
Epoch [ 411/1200] -> Loss: 55.1641
Epoch [ 412/1200] -> Loss: 54.1113
Epoch [ 413/1200] -> Loss: 54.5844
Epoch [ 414/1200] -> Loss: 55.2487
Epoch [ 415/1200] -> Loss: 54.4287
Epoch [ 416/1200] -> Loss: 55.4426
Epoch [ 417/1200] -> Loss: 54.9587
Epoch   418: reducing learning rate of group 0 to 1.2207e-08.
Epoch [ 418/1200] -> Loss: 54.9135
Epoch [ 419/1200] -> Loss: 56.6111
Epoch [ 420/1200] -> Loss: 55.1080
Epoch [ 421/1200] -> Loss: 55.5823
Epoch [ 422/1200] -> Loss: 55.2076
Epoch [ 423/1200] -> Loss: 55.2273
Epoch [ 424/1200] -> Loss: 55.0526
Epoch [ 425/1200] -> Loss: 55.4950
Epoch [ 426/1200] -> Loss: 54.9958
Epoch [ 427/1200] -> Loss: 55.7683
Epoch [ 428/1200] -> Loss: 55.0824
Epoch [ 429/1200] -> Loss: 55.8262
Epoch [ 430/1200] -> Loss: 55.4358
Epoch [ 431/1200] -> Loss: 54.6116
Epoch [ 432/1200] -> Loss: 54.0798
Epoch [ 433/1200] -> Loss: 55.0074
Epoch [ 434/1200] -> Loss: 55.4021
Epoch [ 435/1200] -> Loss: 55.7440
Epoch [ 436/1200] -> Loss: 55.0200
Epoch [ 437/1200] -> Loss: 54.9078
Epoch [ 438/1200] -> Loss: 56.1973
Epoch [ 439/1200] -> Loss: 54.5231
Epoch [ 440/1200] -> Loss: 54.4485
Epoch [ 441/1200] -> Loss: 55.8993
Epoch [ 442/1200] -> Loss: 54.8116
Epoch [ 443/1200] -> Loss: 55.6009
Epoch [ 444/1200] -> Loss: 55.3593
Epoch [ 445/1200] -> Loss: 53.9990
Epoch [ 446/1200] -> Loss: 55.5536
Epoch [ 447/1200] -> Loss: 54.7838
Epoch [ 448/1200] -> Loss: 55.3133
Epoch [ 449/1200] -> Loss: 54.7801
Epoch [ 450/1200] -> Loss: 55.6118
Epoch [ 451/1200] -> Loss: 54.8648
Epoch [ 452/1200] -> Loss: 55.0136
Epoch [ 453/1200] -> Loss: 55.2038
Epoch [ 454/1200] -> Loss: 54.3875
Epoch [ 455/1200] -> Loss: 55.0475
Epoch [ 456/1200] -> Loss: 55.2921
Epoch [ 457/1200] -> Loss: 55.3832
Epoch [ 458/1200] -> Loss: 54.8834
Epoch [ 459/1200] -> Loss: 55.4867
Epoch [ 460/1200] -> Loss: 54.7452
Epoch [ 461/1200] -> Loss: 55.2041
Epoch [ 462/1200] -> Loss: 55.4117
Epoch [ 463/1200] -> Loss: 55.0857
Epoch [ 464/1200] -> Loss: 54.2336
Epoch [ 465/1200] -> Loss: 55.7415
Epoch [ 466/1200] -> Loss: 55.5951
Epoch [ 467/1200] -> Loss: 55.3672
Epoch [ 468/1200] -> Loss: 54.9258
Epoch [ 469/1200] -> Loss: 54.4137
Epoch [ 470/1200] -> Loss: 54.9588
Epoch [ 471/1200] -> Loss: 55.0043
Epoch [ 472/1200] -> Loss: 54.9054
Epoch [ 473/1200] -> Loss: 55.1410
Epoch [ 474/1200] -> Loss: 55.8466
Epoch [ 475/1200] -> Loss: 54.8935
Epoch [ 476/1200] -> Loss: 54.7102
Epoch [ 477/1200] -> Loss: 54.8763
Epoch [ 478/1200] -> Loss: 54.9265
Epoch [ 479/1200] -> Loss: 54.8812
Epoch [ 480/1200] -> Loss: 55.1849
Epoch [ 481/1200] -> Loss: 55.0864
Epoch [ 482/1200] -> Loss: 55.1116
Epoch [ 483/1200] -> Loss: 55.6236
Epoch [ 484/1200] -> Loss: 54.7699
Epoch [ 485/1200] -> Loss: 55.4117
Epoch [ 486/1200] -> Loss: 55.2959
Epoch [ 487/1200] -> Loss: 54.7405
Epoch [ 488/1200] -> Loss: 54.7720
Epoch [ 489/1200] -> Loss: 54.5542
Epoch [ 490/1200] -> Loss: 54.6091
Epoch [ 491/1200] -> Loss: 55.2550
Epoch [ 492/1200] -> Loss: 55.1410
Epoch [ 493/1200] -> Loss: 55.5209
Epoch [ 494/1200] -> Loss: 55.1019
Epoch [ 495/1200] -> Loss: 54.5334
Epoch [ 496/1200] -> Loss: 54.2679
Epoch [ 497/1200] -> Loss: 54.9893
Epoch [ 498/1200] -> Loss: 55.1596
Epoch [ 499/1200] -> Loss: 54.0911
----------------------------------------------------------------
Model checkpoint saved as FFNN_500.pth
----------------------------------------------------------------
Epoch [ 500/1200] -> Loss: 55.0970
Epoch [ 501/1200] -> Loss: 55.0721
Epoch [ 502/1200] -> Loss: 56.1057
Epoch [ 503/1200] -> Loss: 53.8116
Epoch [ 504/1200] -> Loss: 54.3964
Epoch [ 505/1200] -> Loss: 54.8797
Epoch [ 506/1200] -> Loss: 54.5036
Epoch [ 507/1200] -> Loss: 54.0986
Epoch [ 508/1200] -> Loss: 54.2436
Epoch [ 509/1200] -> Loss: 55.6196
Epoch [ 510/1200] -> Loss: 54.3195
Epoch [ 511/1200] -> Loss: 55.1961
Epoch [ 512/1200] -> Loss: 55.7685
Epoch [ 513/1200] -> Loss: 55.3509
Epoch [ 514/1200] -> Loss: 55.5079
Epoch [ 515/1200] -> Loss: 54.9450
Epoch [ 516/1200] -> Loss: 55.4503
Epoch [ 517/1200] -> Loss: 56.0981
Epoch [ 518/1200] -> Loss: 55.8521
Epoch [ 519/1200] -> Loss: 55.1920
Epoch [ 520/1200] -> Loss: 54.8925
Epoch [ 521/1200] -> Loss: 55.4132
Epoch [ 522/1200] -> Loss: 54.8085
Epoch [ 523/1200] -> Loss: 55.7307
Epoch [ 524/1200] -> Loss: 55.1895
Epoch [ 525/1200] -> Loss: 55.0463
Epoch [ 526/1200] -> Loss: 54.2963
Epoch [ 527/1200] -> Loss: 55.0385
Epoch [ 528/1200] -> Loss: 55.0076
Epoch [ 529/1200] -> Loss: 55.3848
Epoch [ 530/1200] -> Loss: 54.9573
Epoch [ 531/1200] -> Loss: 55.5645
Epoch [ 532/1200] -> Loss: 54.3214
Epoch [ 533/1200] -> Loss: 54.0982
Epoch [ 534/1200] -> Loss: 55.4451
Epoch [ 535/1200] -> Loss: 54.8846
Epoch [ 536/1200] -> Loss: 54.5914
Epoch [ 537/1200] -> Loss: 54.8708
Epoch [ 538/1200] -> Loss: 54.5994
Epoch [ 539/1200] -> Loss: 55.0518
Epoch [ 540/1200] -> Loss: 55.0731
Epoch [ 541/1200] -> Loss: 54.9790
Epoch [ 542/1200] -> Loss: 54.2794
Epoch [ 543/1200] -> Loss: 54.2985
Epoch [ 544/1200] -> Loss: 54.8586
Epoch [ 545/1200] -> Loss: 55.5152
Epoch [ 546/1200] -> Loss: 55.4075
Epoch [ 547/1200] -> Loss: 54.8096
Epoch [ 548/1200] -> Loss: 55.1317
Epoch [ 549/1200] -> Loss: 54.8056
Epoch [ 550/1200] -> Loss: 54.8816
Epoch [ 551/1200] -> Loss: 55.3759
Epoch [ 552/1200] -> Loss: 54.9952
Epoch [ 553/1200] -> Loss: 55.7110
Epoch [ 554/1200] -> Loss: 54.8663
Epoch [ 555/1200] -> Loss: 55.1850
Epoch [ 556/1200] -> Loss: 54.7331
Epoch [ 557/1200] -> Loss: 55.4648
Epoch [ 558/1200] -> Loss: 55.3745
Epoch [ 559/1200] -> Loss: 55.6903
Epoch [ 560/1200] -> Loss: 55.0976
Epoch [ 561/1200] -> Loss: 54.6621
Epoch [ 562/1200] -> Loss: 55.9497
Epoch [ 563/1200] -> Loss: 55.3390
Epoch [ 564/1200] -> Loss: 56.3347
Epoch [ 565/1200] -> Loss: 55.4647
Epoch [ 566/1200] -> Loss: 55.1274
Epoch [ 567/1200] -> Loss: 54.8750
Epoch [ 568/1200] -> Loss: 55.1457
Epoch [ 569/1200] -> Loss: 55.6389
Epoch [ 570/1200] -> Loss: 55.5458
Epoch [ 571/1200] -> Loss: 54.8563
Epoch [ 572/1200] -> Loss: 55.2765
Epoch [ 573/1200] -> Loss: 55.3612
Epoch [ 574/1200] -> Loss: 55.6818
Epoch [ 575/1200] -> Loss: 54.7635
Epoch [ 576/1200] -> Loss: 55.9007
Epoch [ 577/1200] -> Loss: 54.9630
Epoch [ 578/1200] -> Loss: 54.8105
Epoch [ 579/1200] -> Loss: 54.6405
Epoch [ 580/1200] -> Loss: 54.7860
Epoch [ 581/1200] -> Loss: 54.9756
Epoch [ 582/1200] -> Loss: 54.7524
Epoch [ 583/1200] -> Loss: 54.7391
Epoch [ 584/1200] -> Loss: 54.9406
Epoch [ 585/1200] -> Loss: 54.3292
Epoch [ 586/1200] -> Loss: 54.6271
Epoch [ 587/1200] -> Loss: 54.8527
Epoch [ 588/1200] -> Loss: 55.0452
Epoch [ 589/1200] -> Loss: 54.5362
Epoch [ 590/1200] -> Loss: 54.6742
Epoch [ 591/1200] -> Loss: 56.1650
Epoch [ 592/1200] -> Loss: 55.1383
Epoch [ 593/1200] -> Loss: 54.9884
Epoch [ 594/1200] -> Loss: 54.3872
Epoch [ 595/1200] -> Loss: 54.7621
Epoch [ 596/1200] -> Loss: 56.0093
Epoch [ 597/1200] -> Loss: 54.8446
Epoch [ 598/1200] -> Loss: 54.9353
Epoch [ 599/1200] -> Loss: 55.1336
----------------------------------------------------------------
Model checkpoint saved as FFNN_600.pth
----------------------------------------------------------------
Epoch [ 600/1200] -> Loss: 54.3039
Epoch [ 601/1200] -> Loss: 55.0399
Epoch [ 602/1200] -> Loss: 55.0225
Epoch [ 603/1200] -> Loss: 55.3181
Epoch [ 604/1200] -> Loss: 55.6581
Epoch [ 605/1200] -> Loss: 54.9772
Epoch [ 606/1200] -> Loss: 54.8113
Epoch [ 607/1200] -> Loss: 54.1984
Epoch [ 608/1200] -> Loss: 54.5484
Epoch [ 609/1200] -> Loss: 55.4038
Epoch [ 610/1200] -> Loss: 54.6664
Epoch [ 611/1200] -> Loss: 54.9768
Epoch [ 612/1200] -> Loss: 54.9065
Epoch [ 613/1200] -> Loss: 55.8257
Epoch [ 614/1200] -> Loss: 54.5103
Epoch [ 615/1200] -> Loss: 54.7691
Epoch [ 616/1200] -> Loss: 55.1664
Epoch [ 617/1200] -> Loss: 55.2440
Epoch [ 618/1200] -> Loss: 54.7408
Epoch [ 619/1200] -> Loss: 56.0839
Epoch [ 620/1200] -> Loss: 54.6595
Epoch [ 621/1200] -> Loss: 54.8094
Epoch [ 622/1200] -> Loss: 55.4942
Epoch [ 623/1200] -> Loss: 54.9235
Epoch [ 624/1200] -> Loss: 55.0643
Epoch [ 625/1200] -> Loss: 54.7164
Epoch [ 626/1200] -> Loss: 54.4503
Epoch [ 627/1200] -> Loss: 55.5521
Epoch [ 628/1200] -> Loss: 54.5011
Epoch [ 629/1200] -> Loss: 55.5952
Epoch [ 630/1200] -> Loss: 54.2459
Epoch [ 631/1200] -> Loss: 54.9676
Epoch [ 632/1200] -> Loss: 55.2698
Epoch [ 633/1200] -> Loss: 56.1432
Epoch [ 634/1200] -> Loss: 55.6738
Epoch [ 635/1200] -> Loss: 54.9452
Epoch [ 636/1200] -> Loss: 55.1523
Epoch [ 637/1200] -> Loss: 54.7145
Epoch [ 638/1200] -> Loss: 55.4731
Epoch [ 639/1200] -> Loss: 55.5023
Epoch [ 640/1200] -> Loss: 54.6489
Epoch [ 641/1200] -> Loss: 55.9241
Epoch [ 642/1200] -> Loss: 54.0854
Epoch [ 643/1200] -> Loss: 55.7120
Epoch [ 644/1200] -> Loss: 54.3091
Epoch [ 645/1200] -> Loss: 55.7425
Epoch [ 646/1200] -> Loss: 55.6070
Epoch [ 647/1200] -> Loss: 55.2079
Epoch [ 648/1200] -> Loss: 55.2627
Epoch [ 649/1200] -> Loss: 55.0657
Epoch [ 650/1200] -> Loss: 54.4968
Epoch [ 651/1200] -> Loss: 54.3702
Epoch [ 652/1200] -> Loss: 55.2201
Epoch [ 653/1200] -> Loss: 55.1574
Epoch [ 654/1200] -> Loss: 55.3587
Epoch [ 655/1200] -> Loss: 55.4456
Epoch [ 656/1200] -> Loss: 55.0904
Epoch [ 657/1200] -> Loss: 54.4006
Epoch [ 658/1200] -> Loss: 54.9349
Epoch [ 659/1200] -> Loss: 54.9749
Epoch [ 660/1200] -> Loss: 54.6400
Epoch [ 661/1200] -> Loss: 55.4126
Epoch [ 662/1200] -> Loss: 54.6430
Epoch [ 663/1200] -> Loss: 54.3232
Epoch [ 664/1200] -> Loss: 55.8637
Epoch [ 665/1200] -> Loss: 54.4126
Epoch [ 666/1200] -> Loss: 55.0864
Epoch [ 667/1200] -> Loss: 54.7346
Epoch [ 668/1200] -> Loss: 55.2950
Epoch [ 669/1200] -> Loss: 55.0897
Epoch [ 670/1200] -> Loss: 55.2729
Epoch [ 671/1200] -> Loss: 54.4028
Epoch [ 672/1200] -> Loss: 54.9382
Epoch [ 673/1200] -> Loss: 54.9613
Epoch [ 674/1200] -> Loss: 54.4328
Epoch [ 675/1200] -> Loss: 54.7728
Epoch [ 676/1200] -> Loss: 54.8177
Epoch [ 677/1200] -> Loss: 54.2883
Epoch [ 678/1200] -> Loss: 55.5709
Epoch [ 679/1200] -> Loss: 55.1200
Epoch [ 680/1200] -> Loss: 54.7121
Epoch [ 681/1200] -> Loss: 56.1544
Epoch [ 682/1200] -> Loss: 55.2502
Epoch [ 683/1200] -> Loss: 54.8288
Epoch [ 684/1200] -> Loss: 54.7023
Epoch [ 685/1200] -> Loss: 55.2039
Epoch [ 686/1200] -> Loss: 55.9138
Epoch [ 687/1200] -> Loss: 54.6296
Epoch [ 688/1200] -> Loss: 55.1309
Epoch [ 689/1200] -> Loss: 54.2151
Epoch [ 690/1200] -> Loss: 54.1651
Epoch [ 691/1200] -> Loss: 54.8742
Epoch [ 692/1200] -> Loss: 54.4598
Epoch [ 693/1200] -> Loss: 55.0812
Epoch [ 694/1200] -> Loss: 54.5188
Epoch [ 695/1200] -> Loss: 55.3147
Epoch [ 696/1200] -> Loss: 55.1265
Epoch [ 697/1200] -> Loss: 54.9349
Epoch [ 698/1200] -> Loss: 55.2920
Epoch [ 699/1200] -> Loss: 54.7128
----------------------------------------------------------------
Model checkpoint saved as FFNN_700.pth
----------------------------------------------------------------
Epoch [ 700/1200] -> Loss: 54.9837
Epoch [ 701/1200] -> Loss: 55.0886
Epoch [ 702/1200] -> Loss: 55.1402
Epoch [ 703/1200] -> Loss: 54.7998
Epoch [ 704/1200] -> Loss: 54.8699
Epoch [ 705/1200] -> Loss: 55.5474
Epoch [ 706/1200] -> Loss: 54.8674
Epoch [ 707/1200] -> Loss: 55.3512
Epoch [ 708/1200] -> Loss: 55.1716
Epoch [ 709/1200] -> Loss: 55.0221
Epoch [ 710/1200] -> Loss: 55.1051
Epoch [ 711/1200] -> Loss: 55.5961
Epoch [ 712/1200] -> Loss: 54.9922
Epoch [ 713/1200] -> Loss: 54.8290
Epoch [ 714/1200] -> Loss: 55.2371
Epoch [ 715/1200] -> Loss: 54.6515
Epoch [ 716/1200] -> Loss: 54.7543
Epoch [ 717/1200] -> Loss: 54.9018
Epoch [ 718/1200] -> Loss: 56.1596
Epoch [ 719/1200] -> Loss: 55.4033
Epoch [ 720/1200] -> Loss: 56.2162
Epoch [ 721/1200] -> Loss: 55.4636
Epoch [ 722/1200] -> Loss: 54.9796
Epoch [ 723/1200] -> Loss: 54.8180
Epoch [ 724/1200] -> Loss: 54.8541
Epoch [ 725/1200] -> Loss: 55.5656
Epoch [ 726/1200] -> Loss: 54.6156
Epoch [ 727/1200] -> Loss: 55.5977
Epoch [ 728/1200] -> Loss: 54.2829
Epoch [ 729/1200] -> Loss: 55.3053
Epoch [ 730/1200] -> Loss: 55.6246
Epoch [ 731/1200] -> Loss: 54.1589
Epoch [ 732/1200] -> Loss: 54.3370
Epoch [ 733/1200] -> Loss: 55.4170
Epoch [ 734/1200] -> Loss: 55.8436
Epoch [ 735/1200] -> Loss: 54.6979
Epoch [ 736/1200] -> Loss: 55.0744
Epoch [ 737/1200] -> Loss: 55.6263
Epoch [ 738/1200] -> Loss: 55.2151
Epoch [ 739/1200] -> Loss: 55.1760
Epoch [ 740/1200] -> Loss: 54.8293
Epoch [ 741/1200] -> Loss: 54.4438
Epoch [ 742/1200] -> Loss: 54.8677
Epoch [ 743/1200] -> Loss: 54.1267
Epoch [ 744/1200] -> Loss: 55.6552
Epoch [ 745/1200] -> Loss: 54.3304
Epoch [ 746/1200] -> Loss: 55.0357
Epoch [ 747/1200] -> Loss: 54.3136
Epoch [ 748/1200] -> Loss: 54.9126
Epoch [ 749/1200] -> Loss: 54.6749
Epoch [ 750/1200] -> Loss: 55.0390
Epoch [ 751/1200] -> Loss: 54.5843
Epoch [ 752/1200] -> Loss: 55.7593
Epoch [ 753/1200] -> Loss: 54.9480
Epoch [ 754/1200] -> Loss: 55.5636
Epoch [ 755/1200] -> Loss: 54.2979
Epoch [ 756/1200] -> Loss: 54.8275
Epoch [ 757/1200] -> Loss: 55.1992
Epoch [ 758/1200] -> Loss: 54.7827
Epoch [ 759/1200] -> Loss: 54.9440
Epoch [ 760/1200] -> Loss: 55.8824
Epoch [ 761/1200] -> Loss: 55.4439
Epoch [ 762/1200] -> Loss: 54.9573
Epoch [ 763/1200] -> Loss: 54.9307
Epoch [ 764/1200] -> Loss: 54.8138
Epoch [ 765/1200] -> Loss: 55.4398
Epoch [ 766/1200] -> Loss: 55.0370
Epoch [ 767/1200] -> Loss: 55.3190
Epoch [ 768/1200] -> Loss: 55.2305
Epoch [ 769/1200] -> Loss: 55.4537
Epoch [ 770/1200] -> Loss: 54.3947
Epoch [ 771/1200] -> Loss: 55.0332
Epoch [ 772/1200] -> Loss: 55.2792
Epoch [ 773/1200] -> Loss: 55.9901
Epoch [ 774/1200] -> Loss: 54.6920
Epoch [ 775/1200] -> Loss: 54.9033
Epoch [ 776/1200] -> Loss: 54.8966
Epoch [ 777/1200] -> Loss: 54.5661
Epoch [ 778/1200] -> Loss: 55.2385
Epoch [ 779/1200] -> Loss: 54.2185
Epoch [ 780/1200] -> Loss: 54.5510
Epoch [ 781/1200] -> Loss: 55.0715
Epoch [ 782/1200] -> Loss: 55.4966
Epoch [ 783/1200] -> Loss: 55.6587
Epoch [ 784/1200] -> Loss: 55.4737
Epoch [ 785/1200] -> Loss: 55.2130
Epoch [ 786/1200] -> Loss: 54.3633
Epoch [ 787/1200] -> Loss: 55.1338
Epoch [ 788/1200] -> Loss: 54.8519
Epoch [ 789/1200] -> Loss: 54.5556
Epoch [ 790/1200] -> Loss: 55.0186
Epoch [ 791/1200] -> Loss: 56.0389
Epoch [ 792/1200] -> Loss: 55.1488
Epoch [ 793/1200] -> Loss: 55.1790
Epoch [ 794/1200] -> Loss: 55.7678
Epoch [ 795/1200] -> Loss: 54.3850
Epoch [ 796/1200] -> Loss: 55.2747
Epoch [ 797/1200] -> Loss: 54.9983
Epoch [ 798/1200] -> Loss: 54.5683
Epoch [ 799/1200] -> Loss: 55.2961
----------------------------------------------------------------
Model checkpoint saved as FFNN_800.pth
----------------------------------------------------------------
Epoch [ 800/1200] -> Loss: 55.3069
Epoch [ 801/1200] -> Loss: 54.5348
Epoch [ 802/1200] -> Loss: 54.5410
Epoch [ 803/1200] -> Loss: 56.1586
Epoch [ 804/1200] -> Loss: 55.0384
Epoch [ 805/1200] -> Loss: 55.2135
Epoch [ 806/1200] -> Loss: 55.4492
Epoch [ 807/1200] -> Loss: 55.0510
Epoch [ 808/1200] -> Loss: 55.3150
Epoch [ 809/1200] -> Loss: 54.4355
Epoch [ 810/1200] -> Loss: 54.3836
Epoch [ 811/1200] -> Loss: 55.5758
Epoch [ 812/1200] -> Loss: 54.5595
Epoch [ 813/1200] -> Loss: 54.5442
Epoch [ 814/1200] -> Loss: 55.8207
Epoch [ 815/1200] -> Loss: 55.0007
Epoch [ 816/1200] -> Loss: 54.5198
Epoch [ 817/1200] -> Loss: 55.1611
Epoch [ 818/1200] -> Loss: 55.4299
Epoch [ 819/1200] -> Loss: 54.6138
Epoch [ 820/1200] -> Loss: 56.1176
Epoch [ 821/1200] -> Loss: 55.2008
Epoch [ 822/1200] -> Loss: 55.5567
Epoch [ 823/1200] -> Loss: 54.7927
Epoch [ 824/1200] -> Loss: 55.9164
Epoch [ 825/1200] -> Loss: 55.7646
Epoch [ 826/1200] -> Loss: 54.5066
Epoch [ 827/1200] -> Loss: 55.0530
Epoch [ 828/1200] -> Loss: 54.9342
Epoch [ 829/1200] -> Loss: 55.0701
Epoch [ 830/1200] -> Loss: 54.6412
Epoch [ 831/1200] -> Loss: 55.9820
Epoch [ 832/1200] -> Loss: 55.2550
Epoch [ 833/1200] -> Loss: 55.0247
Epoch [ 834/1200] -> Loss: 54.5300
Epoch [ 835/1200] -> Loss: 54.7059
Epoch [ 836/1200] -> Loss: 54.6550
Epoch [ 837/1200] -> Loss: 54.8810
Epoch [ 838/1200] -> Loss: 55.3078
Epoch [ 839/1200] -> Loss: 54.7958
Epoch [ 840/1200] -> Loss: 54.4122
Epoch [ 841/1200] -> Loss: 55.2727
Epoch [ 842/1200] -> Loss: 55.5279
Epoch [ 843/1200] -> Loss: 55.0591
Epoch [ 844/1200] -> Loss: 54.0643
Epoch [ 845/1200] -> Loss: 54.5858
Epoch [ 846/1200] -> Loss: 54.3789
Epoch [ 847/1200] -> Loss: 55.1769
Epoch [ 848/1200] -> Loss: 55.5443
Epoch [ 849/1200] -> Loss: 54.6019
Epoch [ 850/1200] -> Loss: 54.8975
Epoch [ 851/1200] -> Loss: 54.4822
Epoch [ 852/1200] -> Loss: 54.9525
Epoch [ 853/1200] -> Loss: 54.9105
Epoch [ 854/1200] -> Loss: 55.1627
Epoch [ 855/1200] -> Loss: 54.3008
Epoch [ 856/1200] -> Loss: 54.8885
Epoch [ 857/1200] -> Loss: 54.3797
Epoch [ 858/1200] -> Loss: 54.4164
Epoch [ 859/1200] -> Loss: 54.7015
Epoch [ 860/1200] -> Loss: 55.6198
Epoch [ 861/1200] -> Loss: 54.8176
Epoch [ 862/1200] -> Loss: 55.8964
Epoch [ 863/1200] -> Loss: 55.6267
Epoch [ 864/1200] -> Loss: 55.0221
Epoch [ 865/1200] -> Loss: 54.9304
Epoch [ 866/1200] -> Loss: 55.7709
Epoch [ 867/1200] -> Loss: 55.4041
Epoch [ 868/1200] -> Loss: 54.9950
Epoch [ 869/1200] -> Loss: 55.2919
Epoch [ 870/1200] -> Loss: 55.0596
Epoch [ 871/1200] -> Loss: 54.2998
Epoch [ 872/1200] -> Loss: 55.2998
Epoch [ 873/1200] -> Loss: 55.1274
Epoch [ 874/1200] -> Loss: 55.0095
Epoch [ 875/1200] -> Loss: 55.1904
Epoch [ 876/1200] -> Loss: 55.7914
Epoch [ 877/1200] -> Loss: 54.7295
Epoch [ 878/1200] -> Loss: 55.9757
Epoch [ 879/1200] -> Loss: 55.6947
Epoch [ 880/1200] -> Loss: 55.5419
Epoch [ 881/1200] -> Loss: 55.3255
Epoch [ 882/1200] -> Loss: 55.5626
Epoch [ 883/1200] -> Loss: 56.1586
Epoch [ 884/1200] -> Loss: 54.6534
Epoch [ 885/1200] -> Loss: 55.6904
Epoch [ 886/1200] -> Loss: 55.0551
Epoch [ 887/1200] -> Loss: 55.7709
Epoch [ 888/1200] -> Loss: 54.8720
Epoch [ 889/1200] -> Loss: 54.0194
Epoch [ 890/1200] -> Loss: 54.8412
Epoch [ 891/1200] -> Loss: 55.5016
Epoch [ 892/1200] -> Loss: 55.3227
Epoch [ 893/1200] -> Loss: 54.9367
Epoch [ 894/1200] -> Loss: 55.3817
Epoch [ 895/1200] -> Loss: 54.8228
Epoch [ 896/1200] -> Loss: 54.7058
Epoch [ 897/1200] -> Loss: 54.1892
Epoch [ 898/1200] -> Loss: 55.0768
Epoch [ 899/1200] -> Loss: 55.1133
----------------------------------------------------------------
Model checkpoint saved as FFNN_900.pth
----------------------------------------------------------------
Epoch [ 900/1200] -> Loss: 54.5750
Epoch [ 901/1200] -> Loss: 54.5024
Epoch [ 902/1200] -> Loss: 55.1361
Epoch [ 903/1200] -> Loss: 55.7118
Epoch [ 904/1200] -> Loss: 54.7033
Epoch [ 905/1200] -> Loss: 55.4265
Epoch [ 906/1200] -> Loss: 54.7832
Epoch [ 907/1200] -> Loss: 54.5867
Epoch [ 908/1200] -> Loss: 55.3112
Epoch [ 909/1200] -> Loss: 56.0914
Epoch [ 910/1200] -> Loss: 54.1930
Epoch [ 911/1200] -> Loss: 54.9163
Epoch [ 912/1200] -> Loss: 54.9445
Epoch [ 913/1200] -> Loss: 55.8506
Epoch [ 914/1200] -> Loss: 55.7486
Epoch [ 915/1200] -> Loss: 55.5106
Epoch [ 916/1200] -> Loss: 54.6333
Epoch [ 917/1200] -> Loss: 54.5018
Epoch [ 918/1200] -> Loss: 55.1341
Epoch [ 919/1200] -> Loss: 55.6156
Epoch [ 920/1200] -> Loss: 55.4258
Epoch [ 921/1200] -> Loss: 55.0744
Epoch [ 922/1200] -> Loss: 53.3689
Epoch [ 923/1200] -> Loss: 55.0883
Epoch [ 924/1200] -> Loss: 54.8788
Epoch [ 925/1200] -> Loss: 55.0437
Epoch [ 926/1200] -> Loss: 54.5842
Epoch [ 927/1200] -> Loss: 55.3149
Epoch [ 928/1200] -> Loss: 54.6331
Epoch [ 929/1200] -> Loss: 55.1983
Epoch [ 930/1200] -> Loss: 55.2621
Epoch [ 931/1200] -> Loss: 54.7855
Epoch [ 932/1200] -> Loss: 55.1818
Epoch [ 933/1200] -> Loss: 55.2392
Epoch [ 934/1200] -> Loss: 55.6833
Epoch [ 935/1200] -> Loss: 55.4376
Epoch [ 936/1200] -> Loss: 55.3575
Epoch [ 937/1200] -> Loss: 54.8379
Epoch [ 938/1200] -> Loss: 54.3885
Epoch [ 939/1200] -> Loss: 55.6875
Epoch [ 940/1200] -> Loss: 55.1301
Epoch [ 941/1200] -> Loss: 55.2714
Epoch [ 942/1200] -> Loss: 54.5653
Epoch [ 943/1200] -> Loss: 56.6535
Epoch [ 944/1200] -> Loss: 55.0775
Epoch [ 945/1200] -> Loss: 55.5798
Epoch [ 946/1200] -> Loss: 54.3321
Epoch [ 947/1200] -> Loss: 54.5049
Epoch [ 948/1200] -> Loss: 54.9736
Epoch [ 949/1200] -> Loss: 54.5294
Epoch [ 950/1200] -> Loss: 54.7268
Epoch [ 951/1200] -> Loss: 54.5076
Epoch [ 952/1200] -> Loss: 55.4728
Epoch [ 953/1200] -> Loss: 55.3523
Epoch [ 954/1200] -> Loss: 55.9932
Epoch [ 955/1200] -> Loss: 55.2342
Epoch [ 956/1200] -> Loss: 53.4389
Epoch [ 957/1200] -> Loss: 55.6626
Epoch [ 958/1200] -> Loss: 54.4184
Epoch [ 959/1200] -> Loss: 55.3547
Epoch [ 960/1200] -> Loss: 54.8795
Epoch [ 961/1200] -> Loss: 54.5376
Epoch [ 962/1200] -> Loss: 54.7429
Epoch [ 963/1200] -> Loss: 54.9881
Epoch [ 964/1200] -> Loss: 54.7996
Epoch [ 965/1200] -> Loss: 55.3709
Epoch [ 966/1200] -> Loss: 54.5702
Epoch [ 967/1200] -> Loss: 56.2348
Epoch [ 968/1200] -> Loss: 54.1774
Epoch [ 969/1200] -> Loss: 54.4007
Epoch [ 970/1200] -> Loss: 54.1888
Epoch [ 971/1200] -> Loss: 54.8657
Epoch [ 972/1200] -> Loss: 54.8153
Epoch [ 973/1200] -> Loss: 54.0510
Epoch [ 974/1200] -> Loss: 55.0800
Epoch [ 975/1200] -> Loss: 54.5637
Epoch [ 976/1200] -> Loss: 54.9976
Epoch [ 977/1200] -> Loss: 54.7154
Epoch [ 978/1200] -> Loss: 55.1499
Epoch [ 979/1200] -> Loss: 54.4461
Epoch [ 980/1200] -> Loss: 55.6043
Epoch [ 981/1200] -> Loss: 54.6415
Epoch [ 982/1200] -> Loss: 55.3139
Epoch [ 983/1200] -> Loss: 54.2476
Epoch [ 984/1200] -> Loss: 54.8003
Epoch [ 985/1200] -> Loss: 55.4417
Epoch [ 986/1200] -> Loss: 55.1499
Epoch [ 987/1200] -> Loss: 55.0772
Epoch [ 988/1200] -> Loss: 55.3538
Epoch [ 989/1200] -> Loss: 55.1697
Epoch [ 990/1200] -> Loss: 54.8485
Epoch [ 991/1200] -> Loss: 54.7459
Epoch [ 992/1200] -> Loss: 55.3027
Epoch [ 993/1200] -> Loss: 55.3275
Epoch [ 994/1200] -> Loss: 55.9064
Epoch [ 995/1200] -> Loss: 55.2406
Epoch [ 996/1200] -> Loss: 54.7585
Epoch [ 997/1200] -> Loss: 54.9000
Epoch [ 998/1200] -> Loss: 55.0005
Epoch [ 999/1200] -> Loss: 55.6045
----------------------------------------------------------------
Model checkpoint saved as FFNN_1000.pth
----------------------------------------------------------------
Epoch [1000/1200] -> Loss: 54.7084
Epoch [1001/1200] -> Loss: 55.5602
Epoch [1002/1200] -> Loss: 55.3348
Epoch [1003/1200] -> Loss: 55.3068
Epoch [1004/1200] -> Loss: 55.2736
Epoch [1005/1200] -> Loss: 55.1587
Epoch [1006/1200] -> Loss: 55.1210
Epoch [1007/1200] -> Loss: 55.3877
Epoch [1008/1200] -> Loss: 55.3370
Epoch [1009/1200] -> Loss: 55.2021
Epoch [1010/1200] -> Loss: 54.9055
Epoch [1011/1200] -> Loss: 55.8969
Epoch [1012/1200] -> Loss: 55.8083
Epoch [1013/1200] -> Loss: 55.3580
Epoch [1014/1200] -> Loss: 54.4474
Epoch [1015/1200] -> Loss: 55.8368
Epoch [1016/1200] -> Loss: 54.6302
Epoch [1017/1200] -> Loss: 54.5762
Epoch [1018/1200] -> Loss: 55.0774
Epoch [1019/1200] -> Loss: 54.8595
Epoch [1020/1200] -> Loss: 54.7448
Epoch [1021/1200] -> Loss: 55.3234
Epoch [1022/1200] -> Loss: 55.1921
Epoch [1023/1200] -> Loss: 54.6631
Epoch [1024/1200] -> Loss: 55.9133
Epoch [1025/1200] -> Loss: 54.6971
Epoch [1026/1200] -> Loss: 55.3455
Epoch [1027/1200] -> Loss: 54.8833
Epoch [1028/1200] -> Loss: 54.9662
Epoch [1029/1200] -> Loss: 55.7094
Epoch [1030/1200] -> Loss: 55.3359
Epoch [1031/1200] -> Loss: 54.5140
Epoch [1032/1200] -> Loss: 55.5564
Epoch [1033/1200] -> Loss: 54.2772
Epoch [1034/1200] -> Loss: 55.0633
Epoch [1035/1200] -> Loss: 55.5431
Epoch [1036/1200] -> Loss: 55.3949
Epoch [1037/1200] -> Loss: 54.7215
Epoch [1038/1200] -> Loss: 55.4877
Epoch [1039/1200] -> Loss: 54.7949
Epoch [1040/1200] -> Loss: 55.5684
Epoch [1041/1200] -> Loss: 56.1915
Epoch [1042/1200] -> Loss: 56.3416
Epoch [1043/1200] -> Loss: 55.2086
Epoch [1044/1200] -> Loss: 56.1221
Epoch [1045/1200] -> Loss: 55.8533
Epoch [1046/1200] -> Loss: 54.5950
Epoch [1047/1200] -> Loss: 54.4443
Epoch [1048/1200] -> Loss: 55.2916
Epoch [1049/1200] -> Loss: 55.2732
Epoch [1050/1200] -> Loss: 55.9895
Epoch [1051/1200] -> Loss: 54.7935
Epoch [1052/1200] -> Loss: 55.1176
Epoch [1053/1200] -> Loss: 53.4611
Epoch [1054/1200] -> Loss: 54.5445
Epoch [1055/1200] -> Loss: 54.9254
Epoch [1056/1200] -> Loss: 54.1916
Epoch [1057/1200] -> Loss: 55.5120
Epoch [1058/1200] -> Loss: 55.6558
Epoch [1059/1200] -> Loss: 55.2298
Epoch [1060/1200] -> Loss: 54.7206
Epoch [1061/1200] -> Loss: 54.8100
Epoch [1062/1200] -> Loss: 55.2156
Epoch [1063/1200] -> Loss: 55.0542
Epoch [1064/1200] -> Loss: 54.3772
Epoch [1065/1200] -> Loss: 54.4992
Epoch [1066/1200] -> Loss: 54.4214
Epoch [1067/1200] -> Loss: 55.5080
Epoch [1068/1200] -> Loss: 56.0820
Epoch [1069/1200] -> Loss: 55.5173
Epoch [1070/1200] -> Loss: 55.9564
Epoch [1071/1200] -> Loss: 54.7012
Epoch [1072/1200] -> Loss: 55.3325
Epoch [1073/1200] -> Loss: 55.3145
Epoch [1074/1200] -> Loss: 55.0412
Epoch [1075/1200] -> Loss: 55.2869
Epoch [1076/1200] -> Loss: 55.3885
Epoch [1077/1200] -> Loss: 54.7316
Epoch [1078/1200] -> Loss: 55.2024
Epoch [1079/1200] -> Loss: 54.1480
Epoch [1080/1200] -> Loss: 55.1282
Epoch [1081/1200] -> Loss: 55.3272
Epoch [1082/1200] -> Loss: 55.2817
Epoch [1083/1200] -> Loss: 55.1229
Epoch [1084/1200] -> Loss: 55.1953
Epoch [1085/1200] -> Loss: 55.5591
Epoch [1086/1200] -> Loss: 55.6651
Epoch [1087/1200] -> Loss: 54.8566
Epoch [1088/1200] -> Loss: 55.1774
Epoch [1089/1200] -> Loss: 54.7574
Epoch [1090/1200] -> Loss: 54.9766
Epoch [1091/1200] -> Loss: 54.9894
Epoch [1092/1200] -> Loss: 55.4848
Epoch [1093/1200] -> Loss: 54.8123
Epoch [1094/1200] -> Loss: 54.5545
Epoch [1095/1200] -> Loss: 55.2917
Epoch [1096/1200] -> Loss: 54.5662
Epoch [1097/1200] -> Loss: 54.5056
Epoch [1098/1200] -> Loss: 55.7085
Epoch [1099/1200] -> Loss: 55.7463
----------------------------------------------------------------
Model checkpoint saved as FFNN_1100.pth
----------------------------------------------------------------
Epoch [1100/1200] -> Loss: 55.2434
Epoch [1101/1200] -> Loss: 54.9172
Epoch [1102/1200] -> Loss: 55.1187
Epoch [1103/1200] -> Loss: 56.2910
Epoch [1104/1200] -> Loss: 54.3634
Epoch [1105/1200] -> Loss: 54.6215
Epoch [1106/1200] -> Loss: 55.7645
Epoch [1107/1200] -> Loss: 55.2580
Epoch [1108/1200] -> Loss: 55.3362
Epoch [1109/1200] -> Loss: 55.2010
Epoch [1110/1200] -> Loss: 55.6108
Epoch [1111/1200] -> Loss: 55.1527
Epoch [1112/1200] -> Loss: 56.0118
Epoch [1113/1200] -> Loss: 54.8513
Epoch [1114/1200] -> Loss: 54.9379
Epoch [1115/1200] -> Loss: 55.4721
Epoch [1116/1200] -> Loss: 54.9389
Epoch [1117/1200] -> Loss: 55.3783
Epoch [1118/1200] -> Loss: 55.5015
Epoch [1119/1200] -> Loss: 55.1744
Epoch [1120/1200] -> Loss: 55.1292
Epoch [1121/1200] -> Loss: 54.5745
Epoch [1122/1200] -> Loss: 56.3645
Epoch [1123/1200] -> Loss: 54.8409
Epoch [1124/1200] -> Loss: 54.8219
Epoch [1125/1200] -> Loss: 55.1025
Epoch [1126/1200] -> Loss: 54.4661
Epoch [1127/1200] -> Loss: 55.2016
Epoch [1128/1200] -> Loss: 54.3078
Epoch [1129/1200] -> Loss: 55.1085
Epoch [1130/1200] -> Loss: 55.3176
Epoch [1131/1200] -> Loss: 56.0752
Epoch [1132/1200] -> Loss: 54.7460
Epoch [1133/1200] -> Loss: 54.4049
Epoch [1134/1200] -> Loss: 55.2828
Epoch [1135/1200] -> Loss: 54.9674
Epoch [1136/1200] -> Loss: 55.6191
Epoch [1137/1200] -> Loss: 55.5080
Epoch [1138/1200] -> Loss: 55.5843
Epoch [1139/1200] -> Loss: 54.8784
Epoch [1140/1200] -> Loss: 55.6836
Epoch [1141/1200] -> Loss: 55.4044
Epoch [1142/1200] -> Loss: 55.6114
Epoch [1143/1200] -> Loss: 55.1982
Epoch [1144/1200] -> Loss: 55.3332
Epoch [1145/1200] -> Loss: 54.9423
Epoch [1146/1200] -> Loss: 55.8663
Epoch [1147/1200] -> Loss: 55.0100
Epoch [1148/1200] -> Loss: 55.2934
Epoch [1149/1200] -> Loss: 55.6356
Epoch [1150/1200] -> Loss: 55.5117
Epoch [1151/1200] -> Loss: 55.1532
Epoch [1152/1200] -> Loss: 56.1317
Epoch [1153/1200] -> Loss: 54.4146
Epoch [1154/1200] -> Loss: 55.1200
Epoch [1155/1200] -> Loss: 55.2888
Epoch [1156/1200] -> Loss: 54.6419
Epoch [1157/1200] -> Loss: 55.6949
Epoch [1158/1200] -> Loss: 55.0058
Epoch [1159/1200] -> Loss: 55.2996
Epoch [1160/1200] -> Loss: 54.4136
Epoch [1161/1200] -> Loss: 55.1804
Epoch [1162/1200] -> Loss: 55.1163
Epoch [1163/1200] -> Loss: 55.4745
Epoch [1164/1200] -> Loss: 55.3203
Epoch [1165/1200] -> Loss: 54.2745
Epoch [1166/1200] -> Loss: 54.5023
Epoch [1167/1200] -> Loss: 54.6833
Epoch [1168/1200] -> Loss: 54.9946
Epoch [1169/1200] -> Loss: 54.7720
Epoch [1170/1200] -> Loss: 54.4694
Epoch [1171/1200] -> Loss: 56.1244
Epoch [1172/1200] -> Loss: 55.2946
Epoch [1173/1200] -> Loss: 54.8674
Epoch [1174/1200] -> Loss: 55.0348
Epoch [1175/1200] -> Loss: 56.0474
Epoch [1176/1200] -> Loss: 54.3433
Epoch [1177/1200] -> Loss: 55.5632
Epoch [1178/1200] -> Loss: 54.7840
Epoch [1179/1200] -> Loss: 55.2187
Epoch [1180/1200] -> Loss: 54.9626
Epoch [1181/1200] -> Loss: 54.1392
Epoch [1182/1200] -> Loss: 54.8949
Epoch [1183/1200] -> Loss: 54.5244
Epoch [1184/1200] -> Loss: 55.4423
Epoch [1185/1200] -> Loss: 54.5764
Epoch [1186/1200] -> Loss: 55.6172
Epoch [1187/1200] -> Loss: 55.1649
Epoch [1188/1200] -> Loss: 55.0821
Epoch [1189/1200] -> Loss: 54.6751
Epoch [1190/1200] -> Loss: 54.6068
Epoch [1191/1200] -> Loss: 55.9433
Epoch [1192/1200] -> Loss: 55.0210
Epoch [1193/1200] -> Loss: 55.5155
Epoch [1194/1200] -> Loss: 55.0326
Epoch [1195/1200] -> Loss: 54.6950
Epoch [1196/1200] -> Loss: 55.1367
Epoch [1197/1200] -> Loss: 55.2414
Epoch [1198/1200] -> Loss: 55.6652
Epoch [1199/1200] -> Loss: 54.6682
----------------------------------------------------------------
Model checkpoint saved as FFNN_1200.pth
----------------------------------------------------------------
Epoch [1200/1200] -> Loss: 54.9126
----------------------------------------------------------------
Training finished successfully.
        Saved model checkpoints can be found in: /home/extern/Documents/Research/scripts/models/
        Saved data/loss graphs can be found in: /home/extern/Documents/Research/scripts/graphs/
----------------------------------------------------------------
Plotting data...

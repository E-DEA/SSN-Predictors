----------------------------------------------------------------------------------------------------
Usage: python3 SSN_predictor.py <path_to_ssn_datafile> <path_to_aa_datafile>
----------------------------------------------------------------------------------------------------
Code running on device: cuda
----------------------------------------------------------------------------------------------------
Data loaded from file locations :
    SSN - /home/extern/Dropbox/Research/scripts/data/SILSO/TSN/SN_m_tot_V2.0.txt
    AA - /home/extern/Dropbox/Research/scripts/data/ISGI/aa_1869-01-01_2018-12-31_D.dat
----------------------------------------------------------------------------------------------------
Solar cycle data loaded/saved as: cycle_data.pickle
----------------------------------------------------------------------------------------------------
SC Number     Start Date       End Date      Solar Max   Length(in months)
         0      [1749, 1]      [1755, 1]         154.27                  73
         1      [1755, 2]      [1766, 5]         144.12                 136
         2      [1766, 6]      [1775, 5]         192.98                 108
         3      [1775, 6]      [1784, 8]         264.25                 111
         4      [1784, 9]      [1798, 3]         235.28                 163
         5      [1798, 4]     [1810, 11]          67.93                 152
         6     [1810, 12]      [1823, 4]          81.99                 149
         7      [1823, 5]     [1833, 10]          81.16                 126
         8     [1833, 11]      [1843, 6]         119.24                 116
         9      [1843, 7]     [1855, 11]         244.87                 149
        10     [1855, 12]      [1867, 2]         219.94                 135
        11      [1867, 3]     [1878, 11]         186.15                 141
        12     [1878, 12]      [1890, 2]         234.02                 135
        13      [1890, 3]      [1902, 0]         124.41                 142
        14      [1902, 1]      [1913, 6]         146.55                 138
        15      [1913, 7]      [1923, 7]         107.08                 121
        16      [1923, 8]      [1933, 8]         175.67                 121
        17      [1933, 9]      [1944, 1]         130.23                 125
        18      [1944, 2]      [1954, 3]         198.64                 122
        19      [1954, 4]      [1964, 9]         218.73                 126
        20     [1964, 10]      [1976, 2]          285.0                 137
        21      [1976, 3]      [1986, 8]         156.63                 126
        22      [1986, 9]      [1996, 4]         232.92                 116
        23      [1996, 5]     [2008, 11]         212.48                 151
        24     [2008, 12]     [2019, 11]         180.28                 132
----------------------------------------------------------------------------------------------------
Selected data:
    Training: SC 13 to 22
    Validation: SC 23
    Prediction: SC 24
----------------------------------------------------------------------------------------------------
Selected model: FFNN(
  (model): Sequential(
    (0): Linear(in_features=6, out_features=6, bias=True)
    (1): LeakyReLU(negative_slope=0.01, inplace=True)
    (2): Linear(in_features=6, out_features=3, bias=True)
    (3): LeakyReLU(negative_slope=0.01, inplace=True)
    (4): Linear(in_features=3, out_features=1, bias=True)
  )
)    Training mode: True    Prediction mode: True
----------------------------------------------------------------------------------------------------
Selected optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005
    weight_decay: 0
)
----------------------------------------------------------------------------------------------------
Selected scheduler: ReduceLROnPlateau(
    {'factor': 0.9, 'min_lrs': [0], 'patience': 10, 'verbose': True, 'cooldown': 0, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 0.0001, 'threshold_mode': 'rel', 'best': inf, 'num_bad_epochs': 0, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 0})
----------------------------------------------------------------------------------------------------
No pre-trained models available, initializing model weights
----------------------------------------------------------------------------------------------------
Training model with solar cycle 12 to 22 data with: num_epochs=1000
Epoch [   5/1000] -> Loss: 57.7254
Epoch [  10/1000] -> Loss: 49.7633
Epoch [  15/1000] -> Loss: 33.8869
Epoch [  20/1000] -> Loss: 30.6545
Epoch [  25/1000] -> Loss: 30.1057
Epoch [  30/1000] -> Loss: 29.8722
Epoch [  35/1000] -> Loss: 29.7374
Epoch [  40/1000] -> Loss: 29.6386
Epoch [  45/1000] -> Loss: 29.5805
Epoch [  50/1000] -> Loss: 29.4869
Epoch [  55/1000] -> Loss: 29.4723
Epoch [  60/1000] -> Loss: 29.4177
Epoch [  65/1000] -> Loss: 29.3606
Epoch [  70/1000] -> Loss: 29.3255
Epoch [  75/1000] -> Loss: 29.2938
Epoch [  80/1000] -> Loss: 29.2572
Epoch [  85/1000] -> Loss: 29.2436
Epoch [  90/1000] -> Loss: 29.2419
Epoch [  95/1000] -> Loss: 29.2091
----------------------------------------------------------------------------------------------------
Model checkpoint saved as _FFNN_100.pth
----------------------------------------------------------------------------------------------------
Epoch [ 100/1000] -> Loss: 29.2069
Epoch [ 105/1000] -> Loss: 29.1940
Epoch [ 110/1000] -> Loss: 29.1769
Epoch [ 115/1000] -> Loss: 29.1712
Epoch [ 120/1000] -> Loss: 29.1368
Epoch [ 125/1000] -> Loss: 29.1206
Epoch [ 130/1000] -> Loss: 29.1306
Epoch [ 135/1000] -> Loss: 29.1312
Epoch   136: reducing learning rate of group 0 to 4.5000e-04.
Epoch [ 140/1000] -> Loss: 29.1119
Epoch [ 145/1000] -> Loss: 29.1066
Epoch [ 150/1000] -> Loss: 29.1011
Epoch [ 155/1000] -> Loss: 29.0984
Epoch [ 160/1000] -> Loss: 29.0902
Epoch [ 165/1000] -> Loss: 29.0932
Epoch [ 170/1000] -> Loss: 29.0820
Epoch [ 175/1000] -> Loss: 29.0852
Epoch [ 180/1000] -> Loss: 29.0782
Epoch [ 185/1000] -> Loss: 29.0809
Epoch [ 190/1000] -> Loss: 29.0617
Epoch [ 195/1000] -> Loss: 29.0670
Epoch   200: reducing learning rate of group 0 to 4.0500e-04.
----------------------------------------------------------------------------------------------------
Model checkpoint saved as _FFNN_200.pth
----------------------------------------------------------------------------------------------------
Epoch [ 200/1000] -> Loss: 29.0658
Epoch [ 205/1000] -> Loss: 29.0585
Epoch [ 210/1000] -> Loss: 29.0401
Epoch [ 215/1000] -> Loss: 29.0497
Epoch [ 220/1000] -> Loss: 29.0428
Epoch [ 225/1000] -> Loss: 29.0434
Epoch [ 230/1000] -> Loss: 29.0341
Epoch   234: reducing learning rate of group 0 to 3.6450e-04.
Epoch [ 235/1000] -> Loss: 29.0283
Epoch [ 240/1000] -> Loss: 29.0379
Epoch   245: reducing learning rate of group 0 to 3.2805e-04.
Epoch [ 245/1000] -> Loss: 29.0310
Epoch [ 250/1000] -> Loss: 29.0162
Epoch [ 255/1000] -> Loss: 29.0131
Epoch [ 260/1000] -> Loss: 29.0208
Epoch [ 265/1000] -> Loss: 29.0152
Epoch   266: reducing learning rate of group 0 to 2.9525e-04.
Epoch [ 270/1000] -> Loss: 29.0137
Epoch [ 275/1000] -> Loss: 29.0087
Epoch [ 280/1000] -> Loss: 29.0113
Epoch [ 285/1000] -> Loss: 29.0104
Epoch [ 290/1000] -> Loss: 29.0115
Epoch   293: reducing learning rate of group 0 to 2.6572e-04.
Epoch [ 295/1000] -> Loss: 29.0059
----------------------------------------------------------------------------------------------------
Model checkpoint saved as _FFNN_300.pth
----------------------------------------------------------------------------------------------------
Epoch [ 300/1000] -> Loss: 29.0055
Epoch   304: reducing learning rate of group 0 to 2.3915e-04.
Epoch [ 305/1000] -> Loss: 28.9998
Epoch [ 310/1000] -> Loss: 29.0027
Epoch   315: reducing learning rate of group 0 to 2.1523e-04.
Epoch [ 315/1000] -> Loss: 29.0022
Epoch [ 320/1000] -> Loss: 28.9988
Epoch [ 325/1000] -> Loss: 28.9977
Epoch   326: reducing learning rate of group 0 to 1.9371e-04.
Epoch [ 330/1000] -> Loss: 28.9962
Epoch [ 335/1000] -> Loss: 28.9981
Epoch   337: reducing learning rate of group 0 to 1.7434e-04.
Epoch [ 340/1000] -> Loss: 28.9956
Epoch [ 345/1000] -> Loss: 28.9813
Epoch [ 350/1000] -> Loss: 28.9927
Epoch [ 355/1000] -> Loss: 28.9934
Epoch   356: reducing learning rate of group 0 to 1.5691e-04.
Epoch [ 360/1000] -> Loss: 28.9904
Epoch [ 365/1000] -> Loss: 28.9922
Epoch   367: reducing learning rate of group 0 to 1.4121e-04.
Epoch [ 370/1000] -> Loss: 28.9875
Epoch [ 375/1000] -> Loss: 28.9873
Epoch   378: reducing learning rate of group 0 to 1.2709e-04.
Epoch [ 380/1000] -> Loss: 28.9890
Epoch [ 385/1000] -> Loss: 28.9883
Epoch   389: reducing learning rate of group 0 to 1.1438e-04.
Epoch [ 390/1000] -> Loss: 28.9880
Epoch [ 395/1000] -> Loss: 28.9859
Epoch   400: reducing learning rate of group 0 to 1.0295e-04.
----------------------------------------------------------------------------------------------------
Model checkpoint saved as _FFNN_400.pth
----------------------------------------------------------------------------------------------------
Epoch [ 400/1000] -> Loss: 28.9863
Epoch [ 405/1000] -> Loss: 28.9842
Epoch [ 410/1000] -> Loss: 28.9837
Epoch   411: reducing learning rate of group 0 to 9.2651e-05.
Epoch [ 415/1000] -> Loss: 28.9823
Epoch [ 420/1000] -> Loss: 28.9838
Epoch   422: reducing learning rate of group 0 to 8.3386e-05.
Epoch [ 425/1000] -> Loss: 28.9818
Epoch [ 430/1000] -> Loss: 28.9828
Epoch   433: reducing learning rate of group 0 to 7.5047e-05.
Epoch [ 435/1000] -> Loss: 28.9807
Epoch [ 440/1000] -> Loss: 28.9810
Epoch   444: reducing learning rate of group 0 to 6.7543e-05.
Epoch [ 445/1000] -> Loss: 28.9798
Epoch [ 450/1000] -> Loss: 28.9795
Epoch   455: reducing learning rate of group 0 to 6.0788e-05.
Epoch [ 455/1000] -> Loss: 28.9802
Epoch [ 460/1000] -> Loss: 28.9785
Epoch [ 465/1000] -> Loss: 28.9790
Epoch   466: reducing learning rate of group 0 to 5.4709e-05.
Epoch [ 470/1000] -> Loss: 28.9793
Epoch [ 475/1000] -> Loss: 28.9790
Epoch   480: reducing learning rate of group 0 to 4.9239e-05.
Epoch [ 480/1000] -> Loss: 28.9780
Epoch [ 485/1000] -> Loss: 28.9776
Epoch [ 490/1000] -> Loss: 28.9779
Epoch   491: reducing learning rate of group 0 to 4.4315e-05.
Epoch [ 495/1000] -> Loss: 28.9777
----------------------------------------------------------------------------------------------------
Model checkpoint saved as _FFNN_500.pth
----------------------------------------------------------------------------------------------------
Epoch [ 500/1000] -> Loss: 28.9766
Epoch   502: reducing learning rate of group 0 to 3.9883e-05.
Epoch [ 505/1000] -> Loss: 28.9764
Epoch [ 510/1000] -> Loss: 28.9769
Epoch   513: reducing learning rate of group 0 to 3.5895e-05.
Epoch [ 515/1000] -> Loss: 28.9761
Epoch [ 520/1000] -> Loss: 28.9757
Epoch   524: reducing learning rate of group 0 to 3.2305e-05.
Epoch [ 525/1000] -> Loss: 28.9756
Epoch [ 530/1000] -> Loss: 28.9757
Epoch   535: reducing learning rate of group 0 to 2.9075e-05.
Epoch [ 535/1000] -> Loss: 28.9759
Epoch [ 540/1000] -> Loss: 28.9749
Epoch [ 545/1000] -> Loss: 28.9757
Epoch   546: reducing learning rate of group 0 to 2.6167e-05.
Epoch [ 550/1000] -> Loss: 28.9750
Epoch [ 555/1000] -> Loss: 28.9746
Epoch   560: reducing learning rate of group 0 to 2.3551e-05.
Epoch [ 560/1000] -> Loss: 28.9750
Epoch [ 565/1000] -> Loss: 28.9745
Epoch [ 570/1000] -> Loss: 28.9745
Epoch   571: reducing learning rate of group 0 to 2.1196e-05.
Epoch [ 575/1000] -> Loss: 28.9742
Epoch [ 580/1000] -> Loss: 28.9742
Epoch   582: reducing learning rate of group 0 to 1.9076e-05.
Epoch [ 585/1000] -> Loss: 28.9736
Epoch [ 590/1000] -> Loss: 28.9742
Epoch   593: reducing learning rate of group 0 to 1.7168e-05.
Epoch [ 595/1000] -> Loss: 28.9737
----------------------------------------------------------------------------------------------------
Model checkpoint saved as _FFNN_600.pth
----------------------------------------------------------------------------------------------------
Epoch [ 600/1000] -> Loss: 28.9738
Epoch   604: reducing learning rate of group 0 to 1.5452e-05.
Epoch [ 605/1000] -> Loss: 28.9732
Epoch [ 610/1000] -> Loss: 28.9734
Epoch   615: reducing learning rate of group 0 to 1.3906e-05.
Epoch [ 615/1000] -> Loss: 28.9735
Epoch [ 620/1000] -> Loss: 28.9731
Epoch [ 625/1000] -> Loss: 28.9733
Epoch   626: reducing learning rate of group 0 to 1.2516e-05.
Epoch [ 630/1000] -> Loss: 28.9730
Epoch [ 635/1000] -> Loss: 28.9732
Epoch   637: reducing learning rate of group 0 to 1.1264e-05.
Epoch [ 640/1000] -> Loss: 28.9729
Epoch [ 645/1000] -> Loss: 28.9731
Epoch   648: reducing learning rate of group 0 to 1.0138e-05.
Epoch [ 650/1000] -> Loss: 28.9728
Epoch [ 655/1000] -> Loss: 28.9729
Epoch   659: reducing learning rate of group 0 to 9.1240e-06.
Epoch [ 660/1000] -> Loss: 28.9726
Epoch [ 665/1000] -> Loss: 28.9726
Epoch   670: reducing learning rate of group 0 to 8.2116e-06.
Epoch [ 670/1000] -> Loss: 28.9729
Epoch [ 675/1000] -> Loss: 28.9725
Epoch [ 680/1000] -> Loss: 28.9725
Epoch   681: reducing learning rate of group 0 to 7.3904e-06.
Epoch [ 685/1000] -> Loss: 28.9725
Epoch [ 690/1000] -> Loss: 28.9724
Epoch   692: reducing learning rate of group 0 to 6.6514e-06.
Epoch [ 695/1000] -> Loss: 28.9723
----------------------------------------------------------------------------------------------------
Model checkpoint saved as _FFNN_700.pth
----------------------------------------------------------------------------------------------------
Epoch [ 700/1000] -> Loss: 28.9724
Epoch   703: reducing learning rate of group 0 to 5.9863e-06.
Epoch [ 705/1000] -> Loss: 28.9724
Epoch [ 710/1000] -> Loss: 28.9723
Epoch   714: reducing learning rate of group 0 to 5.3876e-06.
Epoch [ 715/1000] -> Loss: 28.9722
Epoch [ 720/1000] -> Loss: 28.9721
Epoch   725: reducing learning rate of group 0 to 4.8489e-06.
Epoch [ 725/1000] -> Loss: 28.9722
Epoch [ 730/1000] -> Loss: 28.9721
Epoch [ 735/1000] -> Loss: 28.9721
Epoch   736: reducing learning rate of group 0 to 4.3640e-06.
Epoch [ 740/1000] -> Loss: 28.9721
Epoch [ 745/1000] -> Loss: 28.9721
Epoch   747: reducing learning rate of group 0 to 3.9276e-06.
Epoch [ 750/1000] -> Loss: 28.9721
Epoch [ 755/1000] -> Loss: 28.9721
Epoch   758: reducing learning rate of group 0 to 3.5348e-06.
Epoch [ 760/1000] -> Loss: 28.9720
Epoch [ 765/1000] -> Loss: 28.9720
Epoch   769: reducing learning rate of group 0 to 3.1813e-06.
Epoch [ 770/1000] -> Loss: 28.9719
Epoch [ 775/1000] -> Loss: 28.9719
Epoch   780: reducing learning rate of group 0 to 2.8632e-06.
Epoch [ 780/1000] -> Loss: 28.9719
Epoch [ 785/1000] -> Loss: 28.9719
Epoch [ 790/1000] -> Loss: 28.9719
Epoch   791: reducing learning rate of group 0 to 2.5769e-06.
Epoch [ 795/1000] -> Loss: 28.9718
----------------------------------------------------------------------------------------------------
Model checkpoint saved as _FFNN_800.pth
----------------------------------------------------------------------------------------------------
Epoch [ 800/1000] -> Loss: 28.9718
Epoch   802: reducing learning rate of group 0 to 2.3192e-06.
Epoch [ 805/1000] -> Loss: 28.9718
Epoch [ 810/1000] -> Loss: 28.9718
Epoch   813: reducing learning rate of group 0 to 2.0873e-06.
Epoch [ 815/1000] -> Loss: 28.9718
Epoch [ 820/1000] -> Loss: 28.9718
Epoch   824: reducing learning rate of group 0 to 1.8786e-06.
Epoch [ 825/1000] -> Loss: 28.9718
Epoch [ 830/1000] -> Loss: 28.9717
Epoch   835: reducing learning rate of group 0 to 1.6907e-06.
Epoch [ 835/1000] -> Loss: 28.9717
Epoch [ 840/1000] -> Loss: 28.9717
Epoch [ 845/1000] -> Loss: 28.9718
Epoch [ 850/1000] -> Loss: 28.9717
Epoch [ 855/1000] -> Loss: 28.9717
Epoch   857: reducing learning rate of group 0 to 1.5216e-06.
Epoch [ 860/1000] -> Loss: 28.9717
Epoch [ 865/1000] -> Loss: 28.9717
Epoch   868: reducing learning rate of group 0 to 1.3695e-06.
Epoch [ 870/1000] -> Loss: 28.9717
Epoch [ 875/1000] -> Loss: 28.9717
Epoch   879: reducing learning rate of group 0 to 1.2325e-06.
Epoch [ 880/1000] -> Loss: 28.9717
Epoch [ 885/1000] -> Loss: 28.9717
Epoch   890: reducing learning rate of group 0 to 1.1093e-06.
Epoch [ 890/1000] -> Loss: 28.9717
Epoch [ 895/1000] -> Loss: 28.9717
----------------------------------------------------------------------------------------------------
Model checkpoint saved as _FFNN_900.pth
----------------------------------------------------------------------------------------------------
Epoch [ 900/1000] -> Loss: 28.9717
Epoch   901: reducing learning rate of group 0 to 9.9834e-07.
Epoch [ 905/1000] -> Loss: 28.9716
Epoch [ 910/1000] -> Loss: 28.9717
Epoch   912: reducing learning rate of group 0 to 8.9851e-07.
Epoch [ 915/1000] -> Loss: 28.9716
Epoch [ 920/1000] -> Loss: 28.9716
Epoch   923: reducing learning rate of group 0 to 8.0865e-07.
Epoch [ 925/1000] -> Loss: 28.9716
Epoch [ 930/1000] -> Loss: 28.9716
Epoch   934: reducing learning rate of group 0 to 7.2779e-07.
Epoch [ 935/1000] -> Loss: 28.9716
Epoch [ 940/1000] -> Loss: 28.9716
Epoch   945: reducing learning rate of group 0 to 6.5501e-07.
Epoch [ 945/1000] -> Loss: 28.9716
Epoch [ 950/1000] -> Loss: 28.9716
Epoch [ 955/1000] -> Loss: 28.9716
Epoch   956: reducing learning rate of group 0 to 5.8951e-07.
Epoch [ 960/1000] -> Loss: 28.9716
Epoch [ 965/1000] -> Loss: 28.9716
Epoch   967: reducing learning rate of group 0 to 5.3056e-07.
Epoch [ 970/1000] -> Loss: 28.9716
Epoch [ 975/1000] -> Loss: 28.9716
Epoch   978: reducing learning rate of group 0 to 4.7750e-07.
Epoch [ 980/1000] -> Loss: 28.9716
Epoch [ 985/1000] -> Loss: 28.9716
Epoch   989: reducing learning rate of group 0 to 4.2975e-07.
Epoch [ 990/1000] -> Loss: 28.9716
Epoch [ 995/1000] -> Loss: 28.9716
Epoch  1000: reducing learning rate of group 0 to 3.8678e-07.
----------------------------------------------------------------------------------------------------
Model checkpoint saved as _FFNN_1000.pth
----------------------------------------------------------------------------------------------------
Epoch [1000/1000] -> Loss: 28.9716
----------------------------------------------------------------------------------------------------
Plotting loss data...
----------------------------------------------------------------------------------------------------
Training finished successfully.
        Saved model checkpoints can be found in: /home/extern/Dropbox/Research/scripts/models/
        Saved data/loss graphs can be found in: /home/extern/Dropbox/Research/scripts/graphs/
----------------------------------------------------------------------------------------------------
Validating model for solar cycle 23 data
Step [   1/151] -> Date: 5/1996, Target: 7.6, Prediction: 25.052806854248047
Step [   2/151] -> Date: 6/1996, Target: 16.5, Prediction: 16.800230026245117
Step [   3/151] -> Date: 7/1996, Target: 11.8, Prediction: 14.829710006713867
Step [   4/151] -> Date: 8/1996, Target: 19.7, Prediction: 14.677210807800293
Step [   5/151] -> Date: 9/1996, Target: 3.0, Prediction: 14.258575439453125
Step [   6/151] -> Date: 10/1996, Target: 0.7, Prediction: 17.010351181030273
Step [   7/151] -> Date: 11/1996, Target: 24.9, Prediction: 26.150728225708008
Step [   8/151] -> Date: 12/1996, Target: 14.0, Prediction: 23.160865783691406
Step [   9/151] -> Date: 1/1997, Target: 7.4, Prediction: 13.361931800842285
Step [  10/151] -> Date: 2/1997, Target: 11.0, Prediction: 23.298110961914062
Step [  11/151] -> Date: 3/1997, Target: 12.1, Prediction: 29.301395416259766
Step [  12/151] -> Date: 4/1997, Target: 23.0, Prediction: 29.785585403442383
Step [  13/151] -> Date: 5/1997, Target: 25.4, Prediction: 67.27452087402344
Step [  14/151] -> Date: 6/1997, Target: 20.8, Prediction: 60.76457595825195
Step [  15/151] -> Date: 7/1997, Target: 12.9, Prediction: 50.82545852661133
Step [  16/151] -> Date: 8/1997, Target: 35.7, Prediction: 71.01559448242188
Step [  17/151] -> Date: 9/1997, Target: 59.7, Prediction: 61.019962310791016
Step [  18/151] -> Date: 10/1997, Target: 32.8, Prediction: 80.19273376464844
Step [  19/151] -> Date: 11/1997, Target: 50.4, Prediction: 86.83039855957031
Step [  20/151] -> Date: 12/1997, Target: 55.5, Prediction: 69.73418426513672
Step [  21/151] -> Date: 1/1998, Target: 44.5, Prediction: 89.5018539428711
Step [  22/151] -> Date: 2/1998, Target: 50.2, Prediction: 92.03419494628906
Step [  23/151] -> Date: 3/1998, Target: 82.0, Prediction: 95.49497985839844
Step [  24/151] -> Date: 4/1998, Target: 70.6, Prediction: 97.58007049560547
Step [  25/151] -> Date: 5/1998, Target: 74.0, Prediction: 138.18792724609375
Step [  26/151] -> Date: 6/1998, Target: 90.5, Prediction: 139.22738647460938
Step [  27/151] -> Date: 7/1998, Target: 96.7, Prediction: 171.73648071289062
Step [  28/151] -> Date: 8/1998, Target: 121.1, Prediction: 167.0237274169922
Step [  29/151] -> Date: 9/1998, Target: 132.0, Prediction: 163.699951171875
Step [  30/151] -> Date: 10/1998, Target: 78.5, Prediction: 160.4944610595703
Step [  31/151] -> Date: 11/1998, Target: 97.3, Prediction: 147.1273651123047
Step [  32/151] -> Date: 12/1998, Target: 119.2, Prediction: 155.44786071777344
Step [  33/151] -> Date: 1/1999, Target: 86.0, Prediction: 191.18331909179688
Step [  34/151] -> Date: 2/1999, Target: 98.0, Prediction: 143.47206115722656
Step [  35/151] -> Date: 3/1999, Target: 103.5, Prediction: 170.31997680664062
Step [  36/151] -> Date: 4/1999, Target: 93.6, Prediction: 167.24337768554688
Step [  37/151] -> Date: 5/1999, Target: 149.6, Prediction: 190.95643615722656
Step [  38/151] -> Date: 6/1999, Target: 207.2, Prediction: 203.9571075439453
Step [  39/151] -> Date: 7/1999, Target: 173.5, Prediction: 192.31910705566406
Step [  40/151] -> Date: 8/1999, Target: 142.3, Prediction: 197.80307006835938
Step [  41/151] -> Date: 9/1999, Target: 106.3, Prediction: 178.9766082763672
Step [  42/151] -> Date: 10/1999, Target: 168.7, Prediction: 185.24891662597656
Step [  43/151] -> Date: 11/1999, Target: 188.3, Prediction: 185.0741729736328
Step [  44/151] -> Date: 12/1999, Target: 116.8, Prediction: 173.22293090820312
Step [  45/151] -> Date: 1/2000, Target: 133.1, Prediction: 163.2057647705078
Step [  46/151] -> Date: 2/2000, Target: 165.7, Prediction: 177.22933959960938
Step [  47/151] -> Date: 3/2000, Target: 217.7, Prediction: 204.99058532714844
Step [  48/151] -> Date: 4/2000, Target: 191.5, Prediction: 169.8601837158203
Step [  49/151] -> Date: 5/2000, Target: 165.9, Prediction: 194.2266082763672
Step [  50/151] -> Date: 6/2000, Target: 188.0, Prediction: 183.52574157714844
Step [  51/151] -> Date: 7/2000, Target: 244.3, Prediction: 190.95376586914062
Step [  52/151] -> Date: 8/2000, Target: 180.5, Prediction: 191.57199096679688
Step [  53/151] -> Date: 9/2000, Target: 156.0, Prediction: 209.38668823242188
Step [  54/151] -> Date: 10/2000, Target: 141.6, Prediction: 199.62132263183594
Step [  55/151] -> Date: 11/2000, Target: 158.1, Prediction: 183.9893035888672
Step [  56/151] -> Date: 12/2000, Target: 143.3, Prediction: 171.57229614257812
Step [  57/151] -> Date: 1/2001, Target: 142.6, Prediction: 210.3196563720703
Step [  58/151] -> Date: 2/2001, Target: 121.5, Prediction: 203.98260498046875
Step [  59/151] -> Date: 3/2001, Target: 165.8, Prediction: 214.1191864013672
Step [  60/151] -> Date: 4/2001, Target: 161.7, Prediction: 183.05174255371094
Step [  61/151] -> Date: 5/2001, Target: 142.1, Prediction: 193.05177307128906
Step [  62/151] -> Date: 6/2001, Target: 202.9, Prediction: 180.64218139648438
Step [  63/151] -> Date: 7/2001, Target: 123.0, Prediction: 194.6835479736328
Step [  64/151] -> Date: 8/2001, Target: 161.5, Prediction: 188.38111877441406
Step [  65/151] -> Date: 9/2001, Target: 238.2, Prediction: 210.62066650390625
Step [  66/151] -> Date: 10/2001, Target: 194.1, Prediction: 165.4029998779297
Step [  67/151] -> Date: 11/2001, Target: 176.6, Prediction: 152.50010681152344
Step [  68/151] -> Date: 12/2001, Target: 213.4, Prediction: 139.12403869628906
Step [  69/151] -> Date: 1/2002, Target: 184.6, Prediction: 136.37130737304688
Step [  70/151] -> Date: 2/2002, Target: 170.2, Prediction: 139.89834594726562
Step [  71/151] -> Date: 3/2002, Target: 147.1, Prediction: 140.31179809570312
Step [  72/151] -> Date: 4/2002, Target: 186.9, Prediction: 146.32186889648438
Step [  73/151] -> Date: 5/2002, Target: 187.5, Prediction: 135.55856323242188
Step [  74/151] -> Date: 6/2002, Target: 128.8, Prediction: 134.2146759033203
Step [  75/151] -> Date: 7/2002, Target: 161.0, Prediction: 132.1984405517578
Step [  76/151] -> Date: 8/2002, Target: 175.6, Prediction: 117.90168762207031
Step [  77/151] -> Date: 9/2002, Target: 187.9, Prediction: 135.5198974609375
Step [  78/151] -> Date: 10/2002, Target: 151.2, Prediction: 128.8995361328125
Step [  79/151] -> Date: 11/2002, Target: 147.2, Prediction: 121.3569564819336
Step [  80/151] -> Date: 12/2002, Target: 135.3, Prediction: 111.15123748779297
Step [  81/151] -> Date: 1/2003, Target: 133.5, Prediction: 106.41626739501953
Step [  82/151] -> Date: 2/2003, Target: 75.7, Prediction: 109.04631042480469
Step [  83/151] -> Date: 3/2003, Target: 100.7, Prediction: 101.93266296386719
Step [  84/151] -> Date: 4/2003, Target: 97.9, Prediction: 91.31291961669922
Step [  85/151] -> Date: 5/2003, Target: 86.8, Prediction: 75.90167999267578
Step [  86/151] -> Date: 6/2003, Target: 118.7, Prediction: 67.69412994384766
Step [  87/151] -> Date: 7/2003, Target: 128.3, Prediction: 76.73719787597656
Step [  88/151] -> Date: 8/2003, Target: 115.4, Prediction: 84.53907775878906
Step [  89/151] -> Date: 9/2003, Target: 78.5, Prediction: 78.84752655029297
Step [  90/151] -> Date: 10/2003, Target: 97.8, Prediction: 73.23711395263672
Step [  91/151] -> Date: 11/2003, Target: 82.9, Prediction: 65.14427185058594
Step [  92/151] -> Date: 12/2003, Target: 72.2, Prediction: 65.20864868164062
Step [  93/151] -> Date: 1/2004, Target: 60.6, Prediction: 63.27975845336914
Step [  94/151] -> Date: 2/2004, Target: 74.6, Prediction: 64.71522521972656
Step [  95/151] -> Date: 3/2004, Target: 74.8, Prediction: 56.03602981567383
Step [  96/151] -> Date: 4/2004, Target: 59.2, Prediction: 60.6895751953125
Step [  97/151] -> Date: 5/2004, Target: 72.8, Prediction: 46.58301544189453
Step [  98/151] -> Date: 6/2004, Target: 66.5, Prediction: 28.007781982421875
Step [  99/151] -> Date: 7/2004, Target: 83.8, Prediction: 30.118793487548828
Step [ 100/151] -> Date: 8/2004, Target: 69.7, Prediction: 30.481748580932617
Step [ 101/151] -> Date: 9/2004, Target: 48.8, Prediction: 36.398109436035156
Step [ 102/151] -> Date: 10/2004, Target: 74.2, Prediction: 35.842891693115234
Step [ 103/151] -> Date: 11/2004, Target: 70.1, Prediction: 25.08124351501465
Step [ 104/151] -> Date: 12/2004, Target: 28.9, Prediction: 25.989168167114258
Step [ 105/151] -> Date: 1/2005, Target: 48.1, Prediction: 21.76504135131836
Step [ 106/151] -> Date: 2/2005, Target: 43.5, Prediction: 18.753406524658203
Step [ 107/151] -> Date: 3/2005, Target: 39.6, Prediction: 18.615299224853516
Step [ 108/151] -> Date: 4/2005, Target: 38.7, Prediction: 20.085128784179688
Step [ 109/151] -> Date: 5/2005, Target: 61.9, Prediction: 14.401647567749023
Step [ 110/151] -> Date: 6/2005, Target: 56.8, Prediction: 13.946517944335938
Step [ 111/151] -> Date: 7/2005, Target: 62.4, Prediction: 14.037371635437012
Step [ 112/151] -> Date: 8/2005, Target: 60.5, Prediction: 13.841073036193848
Step [ 113/151] -> Date: 9/2005, Target: 37.2, Prediction: 13.437539100646973
Step [ 114/151] -> Date: 10/2005, Target: 13.2, Prediction: 13.116729736328125
Step [ 115/151] -> Date: 11/2005, Target: 27.5, Prediction: 12.522637367248535
Step [ 116/151] -> Date: 12/2005, Target: 59.3, Prediction: 12.003474235534668
Step [ 117/151] -> Date: 1/2006, Target: 20.9, Prediction: 11.995919227600098
Step [ 118/151] -> Date: 2/2006, Target: 5.7, Prediction: 12.260737419128418
Step [ 119/151] -> Date: 3/2006, Target: 17.3, Prediction: 12.949968338012695
Step [ 120/151] -> Date: 4/2006, Target: 50.3, Prediction: 13.4434814453125
Step [ 121/151] -> Date: 5/2006, Target: 37.2, Prediction: 14.136150360107422
Step [ 122/151] -> Date: 6/2006, Target: 24.5, Prediction: 14.514491081237793
Step [ 123/151] -> Date: 7/2006, Target: 22.2, Prediction: 14.351805686950684
Step [ 124/151] -> Date: 8/2006, Target: 20.8, Prediction: 14.097013473510742
Step [ 125/151] -> Date: 9/2006, Target: 23.7, Prediction: 13.923219680786133
Step [ 126/151] -> Date: 10/2006, Target: 14.9, Prediction: 13.280977249145508
Step [ 127/151] -> Date: 11/2006, Target: 35.7, Prediction: 13.131686210632324
Step [ 128/151] -> Date: 12/2006, Target: 22.3, Prediction: 12.766616821289062
Step [ 129/151] -> Date: 1/2007, Target: 29.3, Prediction: 12.591363906860352
Step [ 130/151] -> Date: 2/2007, Target: 18.4, Prediction: 12.602492332458496
Step [ 131/151] -> Date: 3/2007, Target: 7.2, Prediction: 13.435428619384766
Step [ 132/151] -> Date: 4/2007, Target: 5.4, Prediction: 15.556827545166016
Step [ 133/151] -> Date: 5/2007, Target: 19.5, Prediction: 21.98040199279785
Step [ 134/151] -> Date: 6/2007, Target: 21.3, Prediction: 29.837203979492188
Step [ 135/151] -> Date: 7/2007, Target: 15.1, Prediction: 29.84209442138672
Step [ 136/151] -> Date: 8/2007, Target: 9.8, Prediction: 28.246536254882812
Step [ 137/151] -> Date: 9/2007, Target: 4.0, Prediction: 30.4050350189209
Step [ 138/151] -> Date: 10/2007, Target: 1.5, Prediction: 45.91636276245117
Step [ 139/151] -> Date: 11/2007, Target: 2.8, Prediction: 38.37731170654297
Step [ 140/151] -> Date: 12/2007, Target: 17.3, Prediction: 42.9117546081543
Step [ 141/151] -> Date: 1/2008, Target: 4.1, Prediction: 45.22479248046875
Step [ 142/151] -> Date: 2/2008, Target: 2.9, Prediction: 47.50428009033203
Step [ 143/151] -> Date: 3/2008, Target: 15.5, Prediction: 60.66508483886719
Step [ 144/151] -> Date: 4/2008, Target: 3.6, Prediction: 63.27619171142578
Step [ 145/151] -> Date: 5/2008, Target: 4.6, Prediction: 72.13681030273438
Step [ 146/151] -> Date: 6/2008, Target: 5.2, Prediction: 82.46566772460938
Step [ 147/151] -> Date: 7/2008, Target: 0.6, Prediction: 88.12004089355469
Step [ 148/151] -> Date: 8/2008, Target: 0.3, Prediction: 76.76869201660156
Step [ 149/151] -> Date: 9/2008, Target: 1.2, Prediction: 81.91559600830078
Step [ 150/151] -> Date: 10/2008, Target: 4.2, Prediction: 84.6994400024414
Step [ 151/151] -> Date: 11/2008, Target: 6.6, Prediction: 79.05543518066406
----------------------------------------------------------------------------------------------------
Average Validation Loss: 31.584769391066192
----------------------------------------------------------------------------------------------------
Plotting data...
----------------------------------------------------------------------------------------------------
Plotting loss data...
----------------------------------------------------------------------------------------------------
Validation finished successfully.

        Saved prediction/loss graphs can be found in: /home/extern/Dropbox/Research/scripts/graphs/
----------------------------------------------------------------------------------------------------
Predicting SC 24 using the above trained model
Step [   1/151] -> Date: 12/2008, Prediction: 14.528676986694336
Step [   2/151] -> Date: 1/2009, Prediction: 14.859295845031738
Step [   3/151] -> Date: 2/2009, Prediction: 18.25358772277832
Step [   4/151] -> Date: 3/2009, Prediction: 15.026981353759766
Step [   5/151] -> Date: 4/2009, Prediction: 14.490854263305664
Step [   6/151] -> Date: 5/2009, Prediction: 19.496376037597656
Step [   7/151] -> Date: 6/2009, Prediction: 14.074914932250977
Step [   8/151] -> Date: 7/2009, Prediction: 13.191086769104004
Step [   9/151] -> Date: 8/2009, Prediction: 13.364744186401367
Step [  10/151] -> Date: 9/2009, Prediction: 13.390108108520508
Step [  11/151] -> Date: 10/2009, Prediction: 16.66059112548828
Step [  12/151] -> Date: 11/2009, Prediction: 16.69049644470215
Step [  13/151] -> Date: 12/2009, Prediction: 44.74674606323242
Step [  14/151] -> Date: 1/2010, Prediction: 41.81169509887695
Step [  15/151] -> Date: 2/2010, Prediction: 52.636871337890625
Step [  16/151] -> Date: 3/2010, Prediction: 64.94730377197266
Step [  17/151] -> Date: 4/2010, Prediction: 53.944496154785156
Step [  18/151] -> Date: 5/2010, Prediction: 60.499664306640625
Step [  19/151] -> Date: 6/2010, Prediction: 58.970767974853516
Step [  20/151] -> Date: 7/2010, Prediction: 56.02027130126953
Step [  21/151] -> Date: 8/2010, Prediction: 57.36573791503906
Step [  22/151] -> Date: 9/2010, Prediction: 72.82377624511719
Step [  23/151] -> Date: 10/2010, Prediction: 66.00547790527344
Step [  24/151] -> Date: 11/2010, Prediction: 71.841552734375
Step [  25/151] -> Date: 12/2010, Prediction: 109.11490631103516
Step [  26/151] -> Date: 1/2011, Prediction: 112.74933624267578
Step [  27/151] -> Date: 2/2011, Prediction: 126.72319030761719
Step [  28/151] -> Date: 3/2011, Prediction: 129.3875732421875
Step [  29/151] -> Date: 4/2011, Prediction: 107.73133850097656
Step [  30/151] -> Date: 5/2011, Prediction: 116.75851440429688
Step [  31/151] -> Date: 6/2011, Prediction: 120.87910461425781
Step [  32/151] -> Date: 7/2011, Prediction: 108.1728286743164
Step [  33/151] -> Date: 8/2011, Prediction: 112.5067138671875
Step [  34/151] -> Date: 9/2011, Prediction: 115.23726654052734
Step [  35/151] -> Date: 10/2011, Prediction: 110.31401062011719
Step [  36/151] -> Date: 11/2011, Prediction: 131.71913146972656
Step [  37/151] -> Date: 12/2011, Prediction: 181.6392059326172
Step [  38/151] -> Date: 1/2012, Prediction: 170.0524444580078
Step [  39/151] -> Date: 2/2012, Prediction: 161.6287841796875
Step [  40/151] -> Date: 3/2012, Prediction: 149.26608276367188
Step [  41/151] -> Date: 4/2012, Prediction: 175.09902954101562
Step [  42/151] -> Date: 5/2012, Prediction: 180.30812072753906
Step [  43/151] -> Date: 6/2012, Prediction: 148.07872009277344
Step [  44/151] -> Date: 7/2012, Prediction: 155.47898864746094
Step [  45/151] -> Date: 8/2012, Prediction: 170.24208068847656
Step [  46/151] -> Date: 9/2012, Prediction: 185.7617950439453
Step [  47/151] -> Date: 10/2012, Prediction: 178.7528839111328
Step [  48/151] -> Date: 11/2012, Prediction: 168.49549865722656
Step [  49/151] -> Date: 12/2012, Prediction: 189.37783813476562
Step [  50/151] -> Date: 1/2013, Prediction: 216.1127471923828
Step [  51/151] -> Date: 2/2013, Prediction: 187.7501983642578
Step [  52/151] -> Date: 3/2013, Prediction: 180.46884155273438
Step [  53/151] -> Date: 4/2013, Prediction: 173.70838928222656
Step [  54/151] -> Date: 5/2013, Prediction: 180.45726013183594
Step [  55/151] -> Date: 6/2013, Prediction: 160.1502685546875
Step [  56/151] -> Date: 7/2013, Prediction: 157.0056610107422
Step [  57/151] -> Date: 8/2013, Prediction: 146.97276306152344
Step [  58/151] -> Date: 9/2013, Prediction: 175.53990173339844
Step [  59/151] -> Date: 10/2013, Prediction: 180.60655212402344
Step [  60/151] -> Date: 11/2013, Prediction: 166.82557678222656
Step [  61/151] -> Date: 12/2013, Prediction: 185.08132934570312
Step [  62/151] -> Date: 1/2014, Prediction: 153.1354522705078
Step [  63/151] -> Date: 2/2014, Prediction: 170.28863525390625
Step [  64/151] -> Date: 3/2014, Prediction: 203.59152221679688
Step [  65/151] -> Date: 4/2014, Prediction: 188.8627166748047
Step [  66/151] -> Date: 5/2014, Prediction: 173.7887420654297
Step [  67/151] -> Date: 6/2014, Prediction: 176.1503143310547
Step [  68/151] -> Date: 7/2014, Prediction: 160.3562469482422
Step [  69/151] -> Date: 8/2014, Prediction: 157.09950256347656
Step [  70/151] -> Date: 9/2014, Prediction: 152.53619384765625
Step [  71/151] -> Date: 10/2014, Prediction: 175.82305908203125
Step [  72/151] -> Date: 11/2014, Prediction: 178.6405487060547
Step [  73/151] -> Date: 12/2014, Prediction: 128.55502319335938
Step [  74/151] -> Date: 1/2015, Prediction: 145.09291076660156
Step [  75/151] -> Date: 2/2015, Prediction: 152.95245361328125
Step [  76/151] -> Date: 3/2015, Prediction: 158.06411743164062
Step [  77/151] -> Date: 4/2015, Prediction: 149.6247100830078
Step [  78/151] -> Date: 5/2015, Prediction: 143.9828643798828
Step [  79/151] -> Date: 6/2015, Prediction: 136.34783935546875
Step [  80/151] -> Date: 7/2015, Prediction: 133.79263305664062
Step [  81/151] -> Date: 8/2015, Prediction: 112.78981018066406
Step [  82/151] -> Date: 9/2015, Prediction: 124.23245239257812
Step [  83/151] -> Date: 10/2015, Prediction: 122.95245361328125
Step [  84/151] -> Date: 11/2015, Prediction: 121.66370391845703
Step [  85/151] -> Date: 12/2015, Prediction: 101.86856842041016
Step [  86/151] -> Date: 1/2016, Prediction: 103.5637435913086
Step [  87/151] -> Date: 2/2016, Prediction: 100.67892456054688
Step [  88/151] -> Date: 3/2016, Prediction: 83.5443115234375
Step [  89/151] -> Date: 4/2016, Prediction: 100.22966003417969
Step [  90/151] -> Date: 5/2016, Prediction: 90.60037994384766
Step [  91/151] -> Date: 6/2016, Prediction: 79.71427917480469
Step [  92/151] -> Date: 7/2016, Prediction: 77.09832000732422
Step [  93/151] -> Date: 8/2016, Prediction: 76.44932556152344
Step [  94/151] -> Date: 9/2016, Prediction: 76.54188537597656
Step [  95/151] -> Date: 10/2016, Prediction: 67.99777221679688
Step [  96/151] -> Date: 11/2016, Prediction: 72.68057250976562
Step [  97/151] -> Date: 12/2016, Prediction: 39.32732391357422
Step [  98/151] -> Date: 1/2017, Prediction: 53.00585174560547
Step [  99/151] -> Date: 2/2017, Prediction: 42.4236946105957
Step [ 100/151] -> Date: 3/2017, Prediction: 34.03355407714844
Step [ 101/151] -> Date: 4/2017, Prediction: 44.824737548828125
Step [ 102/151] -> Date: 5/2017, Prediction: 50.86614227294922
Step [ 103/151] -> Date: 6/2017, Prediction: 27.49011993408203
Step [ 104/151] -> Date: 7/2017, Prediction: 41.12834930419922
Step [ 105/151] -> Date: 8/2017, Prediction: 31.435199737548828
Step [ 106/151] -> Date: 9/2017, Prediction: 29.26232147216797
Step [ 107/151] -> Date: 10/2017, Prediction: 27.861061096191406
Step [ 108/151] -> Date: 11/2017, Prediction: 41.69832992553711
Step [ 109/151] -> Date: 12/2017, Prediction: 17.265531539916992
Step [ 110/151] -> Date: 1/2018, Prediction: 22.220949172973633
Step [ 111/151] -> Date: 2/2018, Prediction: 22.22998809814453
Step [ 112/151] -> Date: 3/2018, Prediction: 16.1773738861084
Step [ 113/151] -> Date: 4/2018, Prediction: 13.313983917236328
Step [ 114/151] -> Date: 5/2018, Prediction: 13.154617309570312
Step [ 115/151] -> Date: 6/2018, Prediction: 18.255599975585938
Step [ 116/151] -> Date: 7/2018, Prediction: 12.210339546203613
Step [ 117/151] -> Date: 8/2018, Prediction: 11.91318130493164
Step [ 118/151] -> Date: 9/2018, Prediction: 12.399635314941406
Step [ 119/151] -> Date: 10/2018, Prediction: 13.465081214904785
Step [ 120/151] -> Date: 11/2018, Prediction: 13.503981590270996
Step [ 121/151] -> Date: 12/2018, Prediction: 14.195362091064453
Step [ 122/151] -> Date: 1/2019, Prediction: 14.314001083374023
Step [ 123/151] -> Date: 2/2019, Prediction: 14.551952362060547
Step [ 124/151] -> Date: 3/2019, Prediction: 14.299124717712402
Step [ 125/151] -> Date: 4/2019, Prediction: 13.81108283996582
Step [ 126/151] -> Date: 5/2019, Prediction: 13.703909873962402
Step [ 127/151] -> Date: 6/2019, Prediction: 13.371620178222656
Step [ 128/151] -> Date: 7/2019, Prediction: 13.005298614501953
Step [ 129/151] -> Date: 8/2019, Prediction: 12.5872220993042
Step [ 130/151] -> Date: 9/2019, Prediction: 12.669485092163086
Step [ 131/151] -> Date: 10/2019, Prediction: 13.091029167175293
Step [ 132/151] -> Date: 11/2019, Prediction: 13.68309211730957
Step [ 133/151] -> Date: 12/2019, Prediction: 14.78280258178711
Step [ 134/151] -> Date: 1/2020, Prediction: 14.868080139160156
Step [ 135/151] -> Date: 2/2020, Prediction: 14.811105728149414
Step [ 136/151] -> Date: 3/2020, Prediction: 14.66682243347168
Step [ 137/151] -> Date: 4/2020, Prediction: 14.102849960327148
Step [ 138/151] -> Date: 5/2020, Prediction: 13.667011260986328
Step [ 139/151] -> Date: 6/2020, Prediction: 14.132330894470215
Step [ 140/151] -> Date: 7/2020, Prediction: 13.09990119934082
Step [ 141/151] -> Date: 8/2020, Prediction: 13.28623104095459
Step [ 142/151] -> Date: 9/2020, Prediction: 14.656472206115723
Step [ 143/151] -> Date: 10/2020, Prediction: 13.683392524719238
Step [ 144/151] -> Date: 11/2020, Prediction: 14.005704879760742
Step [ 145/151] -> Date: 12/2020, Prediction: 38.62633514404297
Step [ 146/151] -> Date: 1/2021, Prediction: 36.2818489074707
Step [ 147/151] -> Date: 2/2021, Prediction: 36.3442497253418
Step [ 148/151] -> Date: 3/2021, Prediction: 37.730003356933594
Step [ 149/151] -> Date: 4/2021, Prediction: 39.9086799621582
Step [ 150/151] -> Date: 5/2021, Prediction: 38.99021911621094
Step [ 151/151] -> Date: 6/2021, Prediction: 36.134788513183594
----------------------------------------------------------------------------------------------------
Plotting data...
----------------------------------------------------------------------------------------------------
All newly generated files moved to saved outputs and shared with the cloud(Dropbox) successfully!

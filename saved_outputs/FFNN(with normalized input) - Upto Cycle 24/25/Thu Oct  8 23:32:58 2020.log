----------------------------------------------------------------------------------------------------
Usage: python3 SSN_predictor.py <path_to_ssn_datafile> <path_to_aa_datafile>
----------------------------------------------------------------------------------------------------
Code running on device: cuda
----------------------------------------------------------------------------------------------------
Data loaded from file locations :
    SSN - /home/extern/Dropbox/Research/scripts/data/SILSO/TSN/SN_m_tot_V2.0.txt
    AA - /home/extern/Dropbox/Research/scripts/data/ISGI/aa_1869-01-01_2018-12-31_D.dat
----------------------------------------------------------------------------------------------------
Solar cycle data loaded/saved as: cycle_data.pickle
----------------------------------------------------------------------------------------------------
SC Number     Start Date       End Date      Solar Max   Length(in months)
         0      [1749, 1]      [1755, 1]         154.27                  73
         1      [1755, 2]      [1766, 5]         144.12                 136
         2      [1766, 6]      [1775, 5]         192.98                 108
         3      [1775, 6]      [1784, 8]         264.25                 111
         4      [1784, 9]      [1798, 3]         235.28                 163
         5      [1798, 4]     [1810, 11]          67.93                 152
         6     [1810, 12]      [1823, 4]          81.99                 149
         7      [1823, 5]     [1833, 10]          81.16                 126
         8     [1833, 11]      [1843, 6]         119.24                 116
         9      [1843, 7]     [1855, 11]         244.87                 149
        10     [1855, 12]      [1867, 2]         219.94                 135
        11      [1867, 3]     [1878, 11]         186.15                 141
        12     [1878, 12]      [1890, 2]         234.02                 135
        13      [1890, 3]      [1902, 0]         124.41                 142
        14      [1902, 1]      [1913, 6]         146.55                 138
        15      [1913, 7]      [1923, 7]         107.08                 121
        16      [1923, 8]      [1933, 8]         175.67                 121
        17      [1933, 9]      [1944, 1]         130.23                 125
        18      [1944, 2]      [1954, 3]         198.64                 122
        19      [1954, 4]      [1964, 9]         218.73                 126
        20     [1964, 10]      [1976, 2]          285.0                 137
        21      [1976, 3]      [1986, 8]         156.63                 126
        22      [1986, 9]      [1996, 4]         232.92                 116
        23      [1996, 5]     [2008, 11]         212.48                 151
        24     [2008, 12]     [2019, 11]         180.28                 132
----------------------------------------------------------------------------------------------------
Selected data:
    Training: SC 13 to 22
    Validation: SC 23
    Prediction: SC 24
----------------------------------------------------------------------------------------------------
Selected model: FFNN(
  (model): Sequential(
    (0): Linear(in_features=6, out_features=6, bias=True)
    (1): LeakyReLU(negative_slope=0.01, inplace=True)
    (2): Linear(in_features=6, out_features=3, bias=True)
    (3): LeakyReLU(negative_slope=0.01, inplace=True)
    (4): Linear(in_features=3, out_features=1, bias=True)
  )
)    Training mode: True    Prediction mode: True
----------------------------------------------------------------------------------------------------
Selected optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)
----------------------------------------------------------------------------------------------------
Selected scheduler: ReduceLROnPlateau(
    {'factor': 0.9, 'min_lrs': [0], 'patience': 10, 'verbose': True, 'cooldown': 0, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 0.0001, 'threshold_mode': 'rel', 'best': inf, 'num_bad_epochs': 0, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 0})
----------------------------------------------------------------------------------------------------
No pre-trained models available, initializing model weights
----------------------------------------------------------------------------------------------------
Training model with solar cycle 12 to 22 data with: num_epochs=1000
Epoch [   5/1000] -> Loss: 47.8022
Epoch [  10/1000] -> Loss: 30.4559
Epoch [  15/1000] -> Loss: 29.9169
Epoch [  20/1000] -> Loss: 29.6785
Epoch [  25/1000] -> Loss: 29.5221
Epoch [  30/1000] -> Loss: 29.3691
Epoch [  35/1000] -> Loss: 29.3385
Epoch [  40/1000] -> Loss: 29.2433
Epoch [  45/1000] -> Loss: 29.2311
Epoch [  50/1000] -> Loss: 29.1347
Epoch [  55/1000] -> Loss: 29.2006
Epoch [  60/1000] -> Loss: 29.1496
Epoch    61: reducing learning rate of group 0 to 9.0000e-04.
Epoch [  65/1000] -> Loss: 29.1111
Epoch [  70/1000] -> Loss: 29.1116
Epoch [  75/1000] -> Loss: 29.1014
Epoch [  80/1000] -> Loss: 29.0609
Epoch [  85/1000] -> Loss: 29.0922
Epoch [  90/1000] -> Loss: 29.0933
Epoch    91: reducing learning rate of group 0 to 8.1000e-04.
Epoch [  95/1000] -> Loss: 29.0584
----------------------------------------------------------------------------------------------------
Model checkpoint saved as _FFNN_100.pth
----------------------------------------------------------------------------------------------------
Epoch [ 100/1000] -> Loss: 29.0559
Epoch [ 105/1000] -> Loss: 29.0653
Epoch   109: reducing learning rate of group 0 to 7.2900e-04.
Epoch [ 110/1000] -> Loss: 29.0466
Epoch [ 115/1000] -> Loss: 29.0464
Epoch [ 120/1000] -> Loss: 29.0283
Epoch   122: reducing learning rate of group 0 to 6.5610e-04.
Epoch [ 125/1000] -> Loss: 29.0224
Epoch [ 130/1000] -> Loss: 29.0016
Epoch [ 135/1000] -> Loss: 29.0267
Epoch [ 140/1000] -> Loss: 29.0094
Epoch   141: reducing learning rate of group 0 to 5.9049e-04.
Epoch [ 145/1000] -> Loss: 29.0247
Epoch [ 150/1000] -> Loss: 29.0159
Epoch   152: reducing learning rate of group 0 to 5.3144e-04.
Epoch [ 155/1000] -> Loss: 29.0052
Epoch [ 160/1000] -> Loss: 29.0003
Epoch   163: reducing learning rate of group 0 to 4.7830e-04.
Epoch [ 165/1000] -> Loss: 29.0143
Epoch [ 170/1000] -> Loss: 29.0028
Epoch [ 175/1000] -> Loss: 29.0007
Epoch   178: reducing learning rate of group 0 to 4.3047e-04.
Epoch [ 180/1000] -> Loss: 28.9970
Epoch [ 185/1000] -> Loss: 28.9987
Epoch [ 190/1000] -> Loss: 28.9903
Epoch   192: reducing learning rate of group 0 to 3.8742e-04.
Epoch [ 195/1000] -> Loss: 28.9879
----------------------------------------------------------------------------------------------------
Model checkpoint saved as _FFNN_200.pth
----------------------------------------------------------------------------------------------------
Epoch [ 200/1000] -> Loss: 28.9976
Epoch   203: reducing learning rate of group 0 to 3.4868e-04.
Epoch [ 205/1000] -> Loss: 28.9976
Epoch [ 210/1000] -> Loss: 28.9871
Epoch   214: reducing learning rate of group 0 to 3.1381e-04.
Epoch [ 215/1000] -> Loss: 28.9908
Epoch [ 220/1000] -> Loss: 28.9840
Epoch [ 225/1000] -> Loss: 28.9911
Epoch [ 230/1000] -> Loss: 28.9842
Epoch   234: reducing learning rate of group 0 to 2.8243e-04.
Epoch [ 235/1000] -> Loss: 28.9824
Epoch [ 240/1000] -> Loss: 28.9866
Epoch   245: reducing learning rate of group 0 to 2.5419e-04.
Epoch [ 245/1000] -> Loss: 28.9854
Epoch [ 250/1000] -> Loss: 28.9795
Epoch [ 255/1000] -> Loss: 28.9729
Epoch   256: reducing learning rate of group 0 to 2.2877e-04.
Epoch [ 260/1000] -> Loss: 28.9765
Epoch [ 265/1000] -> Loss: 28.9752
Epoch [ 270/1000] -> Loss: 28.9766
Epoch   275: reducing learning rate of group 0 to 2.0589e-04.
Epoch [ 275/1000] -> Loss: 28.9773
Epoch [ 280/1000] -> Loss: 28.9720
Epoch [ 285/1000] -> Loss: 28.9698
Epoch   286: reducing learning rate of group 0 to 1.8530e-04.
Epoch [ 290/1000] -> Loss: 28.9712
Epoch [ 295/1000] -> Loss: 28.9695
Epoch   297: reducing learning rate of group 0 to 1.6677e-04.
----------------------------------------------------------------------------------------------------
Model checkpoint saved as _FFNN_300.pth
----------------------------------------------------------------------------------------------------
Epoch [ 300/1000] -> Loss: 28.9713
Epoch [ 305/1000] -> Loss: 28.9681
Epoch [ 310/1000] -> Loss: 28.9697
Epoch   312: reducing learning rate of group 0 to 1.5009e-04.
Epoch [ 315/1000] -> Loss: 28.9660
Epoch [ 320/1000] -> Loss: 28.9656
Epoch [ 325/1000] -> Loss: 28.9627
Epoch [ 330/1000] -> Loss: 28.9659
Epoch   332: reducing learning rate of group 0 to 1.3509e-04.
Epoch [ 335/1000] -> Loss: 28.9661
Epoch [ 340/1000] -> Loss: 28.9669
Epoch   343: reducing learning rate of group 0 to 1.2158e-04.
Epoch [ 345/1000] -> Loss: 28.9567
Epoch [ 350/1000] -> Loss: 28.9629
Epoch [ 355/1000] -> Loss: 28.9639
Epoch   356: reducing learning rate of group 0 to 1.0942e-04.
Epoch [ 360/1000] -> Loss: 28.9626
Epoch [ 365/1000] -> Loss: 28.9636
Epoch   367: reducing learning rate of group 0 to 9.8477e-05.
Epoch [ 370/1000] -> Loss: 28.9607
Epoch [ 375/1000] -> Loss: 28.9611
Epoch   378: reducing learning rate of group 0 to 8.8629e-05.
Epoch [ 380/1000] -> Loss: 28.9609
Epoch [ 385/1000] -> Loss: 28.9613
Epoch   389: reducing learning rate of group 0 to 7.9766e-05.
Epoch [ 390/1000] -> Loss: 28.9599
Epoch [ 395/1000] -> Loss: 28.9594
Epoch   400: reducing learning rate of group 0 to 7.1790e-05.
----------------------------------------------------------------------------------------------------
Model checkpoint saved as _FFNN_400.pth
----------------------------------------------------------------------------------------------------
Epoch [ 400/1000] -> Loss: 28.9596
Epoch [ 405/1000] -> Loss: 28.9582
Epoch [ 410/1000] -> Loss: 28.9583
Epoch   411: reducing learning rate of group 0 to 6.4611e-05.
Epoch [ 415/1000] -> Loss: 28.9567
Epoch [ 420/1000] -> Loss: 28.9585
Epoch   422: reducing learning rate of group 0 to 5.8150e-05.
Epoch [ 425/1000] -> Loss: 28.9566
Epoch [ 430/1000] -> Loss: 28.9580
Epoch   433: reducing learning rate of group 0 to 5.2335e-05.
Epoch [ 435/1000] -> Loss: 28.9561
Epoch [ 440/1000] -> Loss: 28.9561
Epoch   444: reducing learning rate of group 0 to 4.7101e-05.
Epoch [ 445/1000] -> Loss: 28.9555
Epoch [ 450/1000] -> Loss: 28.9556
Epoch   455: reducing learning rate of group 0 to 4.2391e-05.
Epoch [ 455/1000] -> Loss: 28.9558
Epoch [ 460/1000] -> Loss: 28.9549
Epoch [ 465/1000] -> Loss: 28.9548
Epoch   466: reducing learning rate of group 0 to 3.8152e-05.
Epoch [ 470/1000] -> Loss: 28.9553
Epoch [ 475/1000] -> Loss: 28.9552
Epoch [ 480/1000] -> Loss: 28.9546
Epoch   485: reducing learning rate of group 0 to 3.4337e-05.
Epoch [ 485/1000] -> Loss: 28.9542
Epoch [ 490/1000] -> Loss: 28.9543
Epoch [ 495/1000] -> Loss: 28.9549
Epoch   496: reducing learning rate of group 0 to 3.0903e-05.
----------------------------------------------------------------------------------------------------
Model checkpoint saved as _FFNN_500.pth
----------------------------------------------------------------------------------------------------
Epoch [ 500/1000] -> Loss: 28.9534
Epoch [ 505/1000] -> Loss: 28.9537
Epoch   507: reducing learning rate of group 0 to 2.7813e-05.
Epoch [ 510/1000] -> Loss: 28.9538
Epoch [ 515/1000] -> Loss: 28.9535
Epoch   518: reducing learning rate of group 0 to 2.5032e-05.
Epoch [ 520/1000] -> Loss: 28.9528
Epoch [ 525/1000] -> Loss: 28.9531
Epoch   529: reducing learning rate of group 0 to 2.2528e-05.
Epoch [ 530/1000] -> Loss: 28.9529
Epoch [ 535/1000] -> Loss: 28.9529
Epoch   540: reducing learning rate of group 0 to 2.0276e-05.
Epoch [ 540/1000] -> Loss: 28.9527
Epoch [ 545/1000] -> Loss: 28.9529
Epoch [ 550/1000] -> Loss: 28.9528
Epoch   551: reducing learning rate of group 0 to 1.8248e-05.
Epoch [ 555/1000] -> Loss: 28.9521
Epoch [ 560/1000] -> Loss: 28.9525
Epoch   562: reducing learning rate of group 0 to 1.6423e-05.
Epoch [ 565/1000] -> Loss: 28.9521
Epoch [ 570/1000] -> Loss: 28.9521
Epoch   573: reducing learning rate of group 0 to 1.4781e-05.
Epoch [ 575/1000] -> Loss: 28.9521
Epoch [ 580/1000] -> Loss: 28.9520
Epoch   584: reducing learning rate of group 0 to 1.3303e-05.
Epoch [ 585/1000] -> Loss: 28.9515
Epoch [ 590/1000] -> Loss: 28.9521
Epoch   595: reducing learning rate of group 0 to 1.1973e-05.
Epoch [ 595/1000] -> Loss: 28.9518
----------------------------------------------------------------------------------------------------
Model checkpoint saved as _FFNN_600.pth
----------------------------------------------------------------------------------------------------
Epoch [ 600/1000] -> Loss: 28.9517
Epoch [ 605/1000] -> Loss: 28.9514
Epoch   606: reducing learning rate of group 0 to 1.0775e-05.
Epoch [ 610/1000] -> Loss: 28.9515
Epoch [ 615/1000] -> Loss: 28.9515
Epoch   617: reducing learning rate of group 0 to 9.6977e-06.
Epoch [ 620/1000] -> Loss: 28.9513
Epoch [ 625/1000] -> Loss: 28.9514
Epoch   628: reducing learning rate of group 0 to 8.7280e-06.
Epoch [ 630/1000] -> Loss: 28.9512
Epoch [ 635/1000] -> Loss: 28.9514
Epoch   639: reducing learning rate of group 0 to 7.8552e-06.
Epoch [ 640/1000] -> Loss: 28.9511
Epoch [ 645/1000] -> Loss: 28.9513
Epoch   650: reducing learning rate of group 0 to 7.0697e-06.
Epoch [ 650/1000] -> Loss: 28.9511
Epoch [ 655/1000] -> Loss: 28.9511
Epoch [ 660/1000] -> Loss: 28.9510
Epoch   661: reducing learning rate of group 0 to 6.3627e-06.
Epoch [ 665/1000] -> Loss: 28.9510
Epoch [ 670/1000] -> Loss: 28.9512
Epoch   672: reducing learning rate of group 0 to 5.7264e-06.
Epoch [ 675/1000] -> Loss: 28.9509
Epoch [ 680/1000] -> Loss: 28.9509
Epoch   683: reducing learning rate of group 0 to 5.1538e-06.
Epoch [ 685/1000] -> Loss: 28.9509
Epoch [ 690/1000] -> Loss: 28.9509
Epoch   694: reducing learning rate of group 0 to 4.6384e-06.
Epoch [ 695/1000] -> Loss: 28.9508
----------------------------------------------------------------------------------------------------
Model checkpoint saved as _FFNN_700.pth
----------------------------------------------------------------------------------------------------
Epoch [ 700/1000] -> Loss: 28.9508
Epoch   705: reducing learning rate of group 0 to 4.1746e-06.
Epoch [ 705/1000] -> Loss: 28.9509
Epoch [ 710/1000] -> Loss: 28.9508
Epoch [ 715/1000] -> Loss: 28.9507
Epoch   717: reducing learning rate of group 0 to 3.7571e-06.
Epoch [ 720/1000] -> Loss: 28.9507
Epoch [ 725/1000] -> Loss: 28.9507
Epoch   728: reducing learning rate of group 0 to 3.3814e-06.
Epoch [ 730/1000] -> Loss: 28.9507
Epoch [ 735/1000] -> Loss: 28.9506
Epoch   739: reducing learning rate of group 0 to 3.0433e-06.
Epoch [ 740/1000] -> Loss: 28.9506
Epoch [ 745/1000] -> Loss: 28.9506
Epoch   750: reducing learning rate of group 0 to 2.7389e-06.
Epoch [ 750/1000] -> Loss: 28.9507
Epoch [ 755/1000] -> Loss: 28.9506
Epoch [ 760/1000] -> Loss: 28.9506
Epoch   761: reducing learning rate of group 0 to 2.4650e-06.
Epoch [ 765/1000] -> Loss: 28.9506
Epoch [ 770/1000] -> Loss: 28.9506
Epoch   772: reducing learning rate of group 0 to 2.2185e-06.
Epoch [ 775/1000] -> Loss: 28.9505
Epoch [ 780/1000] -> Loss: 28.9505
Epoch   783: reducing learning rate of group 0 to 1.9967e-06.
Epoch [ 785/1000] -> Loss: 28.9505
Epoch [ 790/1000] -> Loss: 28.9505
Epoch   794: reducing learning rate of group 0 to 1.7970e-06.
Epoch [ 795/1000] -> Loss: 28.9505
----------------------------------------------------------------------------------------------------
Model checkpoint saved as _FFNN_800.pth
----------------------------------------------------------------------------------------------------
Epoch [ 800/1000] -> Loss: 28.9505
Epoch   805: reducing learning rate of group 0 to 1.6173e-06.
Epoch [ 805/1000] -> Loss: 28.9505
Epoch [ 810/1000] -> Loss: 28.9505
Epoch [ 815/1000] -> Loss: 28.9505
Epoch   816: reducing learning rate of group 0 to 1.4556e-06.
Epoch [ 820/1000] -> Loss: 28.9504
Epoch [ 825/1000] -> Loss: 28.9505
Epoch   827: reducing learning rate of group 0 to 1.3100e-06.
Epoch [ 830/1000] -> Loss: 28.9504
Epoch [ 835/1000] -> Loss: 28.9504
Epoch   838: reducing learning rate of group 0 to 1.1790e-06.
Epoch [ 840/1000] -> Loss: 28.9504
Epoch [ 845/1000] -> Loss: 28.9504
Epoch   849: reducing learning rate of group 0 to 1.0611e-06.
Epoch [ 850/1000] -> Loss: 28.9504
Epoch [ 855/1000] -> Loss: 28.9504
Epoch   860: reducing learning rate of group 0 to 9.5500e-07.
Epoch [ 860/1000] -> Loss: 28.9504
Epoch [ 865/1000] -> Loss: 28.9504
Epoch [ 870/1000] -> Loss: 28.9504
Epoch   871: reducing learning rate of group 0 to 8.5950e-07.
Epoch [ 875/1000] -> Loss: 28.9504
Epoch [ 880/1000] -> Loss: 28.9504
Epoch   882: reducing learning rate of group 0 to 7.7355e-07.
Epoch [ 885/1000] -> Loss: 28.9504
Epoch [ 890/1000] -> Loss: 28.9504
Epoch   893: reducing learning rate of group 0 to 6.9620e-07.
Epoch [ 895/1000] -> Loss: 28.9504
----------------------------------------------------------------------------------------------------
Model checkpoint saved as _FFNN_900.pth
----------------------------------------------------------------------------------------------------
Epoch [ 900/1000] -> Loss: 28.9504
Epoch   904: reducing learning rate of group 0 to 6.2658e-07.
Epoch [ 905/1000] -> Loss: 28.9504
Epoch [ 910/1000] -> Loss: 28.9504
Epoch   915: reducing learning rate of group 0 to 5.6392e-07.
Epoch [ 915/1000] -> Loss: 28.9503
Epoch [ 920/1000] -> Loss: 28.9503
Epoch [ 925/1000] -> Loss: 28.9503
Epoch   926: reducing learning rate of group 0 to 5.0753e-07.
Epoch [ 930/1000] -> Loss: 28.9503
Epoch [ 935/1000] -> Loss: 28.9503
Epoch   937: reducing learning rate of group 0 to 4.5678e-07.
Epoch [ 940/1000] -> Loss: 28.9503
Epoch [ 945/1000] -> Loss: 28.9503
Epoch   948: reducing learning rate of group 0 to 4.1110e-07.
Epoch [ 950/1000] -> Loss: 28.9503
Epoch [ 955/1000] -> Loss: 28.9503
Epoch   959: reducing learning rate of group 0 to 3.6999e-07.
Epoch [ 960/1000] -> Loss: 28.9503
Epoch [ 965/1000] -> Loss: 28.9503
Epoch   970: reducing learning rate of group 0 to 3.3299e-07.
Epoch [ 970/1000] -> Loss: 28.9503
Epoch [ 975/1000] -> Loss: 28.9503
Epoch [ 980/1000] -> Loss: 28.9503
Epoch   981: reducing learning rate of group 0 to 2.9969e-07.
Epoch [ 985/1000] -> Loss: 28.9503
Epoch [ 990/1000] -> Loss: 28.9503
Epoch   992: reducing learning rate of group 0 to 2.6972e-07.
Epoch [ 995/1000] -> Loss: 28.9503
----------------------------------------------------------------------------------------------------
Model checkpoint saved as _FFNN_1000.pth
----------------------------------------------------------------------------------------------------
Epoch [1000/1000] -> Loss: 28.9503
----------------------------------------------------------------------------------------------------
Plotting loss data...
----------------------------------------------------------------------------------------------------
Training finished successfully.
        Saved model checkpoints can be found in: /home/extern/Dropbox/Research/scripts/models/
        Saved data/loss graphs can be found in: /home/extern/Dropbox/Research/scripts/graphs/
----------------------------------------------------------------------------------------------------
Validating model for solar cycle 23 data
Step [   1/151] -> Date: 5/1996, Target: 7.6, Prediction: 24.722312927246094
Step [   2/151] -> Date: 6/1996, Target: 16.5, Prediction: 16.784591674804688
Step [   3/151] -> Date: 7/1996, Target: 11.8, Prediction: 14.980183601379395
Step [   4/151] -> Date: 8/1996, Target: 19.7, Prediction: 14.781669616699219
Step [   5/151] -> Date: 9/1996, Target: 3.0, Prediction: 14.370142936706543
Step [   6/151] -> Date: 10/1996, Target: 0.7, Prediction: 16.902984619140625
Step [   7/151] -> Date: 11/1996, Target: 24.9, Prediction: 25.679119110107422
Step [   8/151] -> Date: 12/1996, Target: 14.0, Prediction: 22.625186920166016
Step [   9/151] -> Date: 1/1997, Target: 7.4, Prediction: 13.428253173828125
Step [  10/151] -> Date: 2/1997, Target: 11.0, Prediction: 22.6951904296875
Step [  11/151] -> Date: 3/1997, Target: 12.1, Prediction: 28.712478637695312
Step [  12/151] -> Date: 4/1997, Target: 23.0, Prediction: 29.380661010742188
Step [  13/151] -> Date: 5/1997, Target: 25.4, Prediction: 67.16513061523438
Step [  14/151] -> Date: 6/1997, Target: 20.8, Prediction: 60.860618591308594
Step [  15/151] -> Date: 7/1997, Target: 12.9, Prediction: 51.1016960144043
Step [  16/151] -> Date: 8/1997, Target: 35.7, Prediction: 71.06111145019531
Step [  17/151] -> Date: 9/1997, Target: 59.7, Prediction: 61.197261810302734
Step [  18/151] -> Date: 10/1997, Target: 32.8, Prediction: 79.95308685302734
Step [  19/151] -> Date: 11/1997, Target: 50.4, Prediction: 86.3361587524414
Step [  20/151] -> Date: 12/1997, Target: 55.5, Prediction: 69.32838439941406
Step [  21/151] -> Date: 1/1998, Target: 44.5, Prediction: 88.65894317626953
Step [  22/151] -> Date: 2/1998, Target: 50.2, Prediction: 91.1236572265625
Step [  23/151] -> Date: 3/1998, Target: 82.0, Prediction: 94.58126831054688
Step [  24/151] -> Date: 4/1998, Target: 70.6, Prediction: 96.7535629272461
Step [  25/151] -> Date: 5/1998, Target: 74.0, Prediction: 137.7941131591797
Step [  26/151] -> Date: 6/1998, Target: 90.5, Prediction: 138.956298828125
Step [  27/151] -> Date: 7/1998, Target: 96.7, Prediction: 171.0408172607422
Step [  28/151] -> Date: 8/1998, Target: 121.1, Prediction: 166.55116271972656
Step [  29/151] -> Date: 9/1998, Target: 132.0, Prediction: 163.14315795898438
Step [  30/151] -> Date: 10/1998, Target: 78.5, Prediction: 160.3076934814453
Step [  31/151] -> Date: 11/1998, Target: 97.3, Prediction: 146.6636962890625
Step [  32/151] -> Date: 12/1998, Target: 119.2, Prediction: 154.6106719970703
Step [  33/151] -> Date: 1/1999, Target: 86.0, Prediction: 189.6326141357422
Step [  34/151] -> Date: 2/1999, Target: 98.0, Prediction: 142.56578063964844
Step [  35/151] -> Date: 3/1999, Target: 103.5, Prediction: 169.19053649902344
Step [  36/151] -> Date: 4/1999, Target: 93.6, Prediction: 166.2578582763672
Step [  37/151] -> Date: 5/1999, Target: 149.6, Prediction: 190.53138732910156
Step [  38/151] -> Date: 6/1999, Target: 207.2, Prediction: 203.49545288085938
Step [  39/151] -> Date: 7/1999, Target: 173.5, Prediction: 192.10711669921875
Step [  40/151] -> Date: 8/1999, Target: 142.3, Prediction: 197.47216796875
Step [  41/151] -> Date: 9/1999, Target: 106.3, Prediction: 179.05152893066406
Step [  42/151] -> Date: 10/1999, Target: 168.7, Prediction: 185.05410766601562
Step [  43/151] -> Date: 11/1999, Target: 188.3, Prediction: 184.7828826904297
Step [  44/151] -> Date: 12/1999, Target: 116.8, Prediction: 172.8303985595703
Step [  45/151] -> Date: 1/2000, Target: 133.1, Prediction: 162.8815155029297
Step [  46/151] -> Date: 2/2000, Target: 165.7, Prediction: 176.6028289794922
Step [  47/151] -> Date: 3/2000, Target: 217.7, Prediction: 204.02645874023438
Step [  48/151] -> Date: 4/2000, Target: 191.5, Prediction: 169.5651092529297
Step [  49/151] -> Date: 5/2000, Target: 165.9, Prediction: 193.98434448242188
Step [  50/151] -> Date: 6/2000, Target: 188.0, Prediction: 183.50393676757812
Step [  51/151] -> Date: 7/2000, Target: 244.3, Prediction: 190.87152099609375
Step [  52/151] -> Date: 8/2000, Target: 180.5, Prediction: 191.53533935546875
Step [  53/151] -> Date: 9/2000, Target: 156.0, Prediction: 210.91790771484375
Step [  54/151] -> Date: 10/2000, Target: 141.6, Prediction: 199.82949829101562
Step [  55/151] -> Date: 11/2000, Target: 158.1, Prediction: 190.67752075195312
Step [  56/151] -> Date: 12/2000, Target: 143.3, Prediction: 179.79931640625
Step [  57/151] -> Date: 1/2001, Target: 142.6, Prediction: 215.99725341796875
Step [  58/151] -> Date: 2/2001, Target: 121.5, Prediction: 213.27284240722656
Step [  59/151] -> Date: 3/2001, Target: 165.8, Prediction: 215.85171508789062
Step [  60/151] -> Date: 4/2001, Target: 161.7, Prediction: 182.92556762695312
Step [  61/151] -> Date: 5/2001, Target: 142.1, Prediction: 192.8612518310547
Step [  62/151] -> Date: 6/2001, Target: 202.9, Prediction: 180.875732421875
Step [  63/151] -> Date: 7/2001, Target: 123.0, Prediction: 194.48910522460938
Step [  64/151] -> Date: 8/2001, Target: 161.5, Prediction: 188.2923126220703
Step [  65/151] -> Date: 9/2001, Target: 238.2, Prediction: 210.39378356933594
Step [  66/151] -> Date: 10/2001, Target: 194.1, Prediction: 167.9588623046875
Step [  67/151] -> Date: 11/2001, Target: 176.6, Prediction: 158.66172790527344
Step [  68/151] -> Date: 12/2001, Target: 213.4, Prediction: 145.11940002441406
Step [  69/151] -> Date: 1/2002, Target: 184.6, Prediction: 143.93373107910156
Step [  70/151] -> Date: 2/2002, Target: 170.2, Prediction: 147.03248596191406
Step [  71/151] -> Date: 3/2002, Target: 147.1, Prediction: 140.4938507080078
Step [  72/151] -> Date: 4/2002, Target: 186.9, Prediction: 146.66957092285156
Step [  73/151] -> Date: 5/2002, Target: 187.5, Prediction: 135.43051147460938
Step [  74/151] -> Date: 6/2002, Target: 128.8, Prediction: 134.22726440429688
Step [  75/151] -> Date: 7/2002, Target: 161.0, Prediction: 132.35252380371094
Step [  76/151] -> Date: 8/2002, Target: 175.6, Prediction: 118.39169311523438
Step [  77/151] -> Date: 9/2002, Target: 187.9, Prediction: 135.60865783691406
Step [  78/151] -> Date: 10/2002, Target: 151.2, Prediction: 129.12918090820312
Step [  79/151] -> Date: 11/2002, Target: 147.2, Prediction: 121.45484924316406
Step [  80/151] -> Date: 12/2002, Target: 135.3, Prediction: 111.1888427734375
Step [  81/151] -> Date: 1/2003, Target: 133.5, Prediction: 106.43346405029297
Step [  82/151] -> Date: 2/2003, Target: 75.7, Prediction: 108.9472427368164
Step [  83/151] -> Date: 3/2003, Target: 100.7, Prediction: 102.01441955566406
Step [  84/151] -> Date: 4/2003, Target: 97.9, Prediction: 91.7502670288086
Step [  85/151] -> Date: 5/2003, Target: 86.8, Prediction: 75.81782531738281
Step [  86/151] -> Date: 6/2003, Target: 118.7, Prediction: 67.90142059326172
Step [  87/151] -> Date: 7/2003, Target: 128.3, Prediction: 76.88383483886719
Step [  88/151] -> Date: 8/2003, Target: 115.4, Prediction: 84.59673309326172
Step [  89/151] -> Date: 9/2003, Target: 78.5, Prediction: 79.17159271240234
Step [  90/151] -> Date: 10/2003, Target: 97.8, Prediction: 73.47377014160156
Step [  91/151] -> Date: 11/2003, Target: 82.9, Prediction: 65.40467834472656
Step [  92/151] -> Date: 12/2003, Target: 72.2, Prediction: 65.3271484375
Step [  93/151] -> Date: 1/2004, Target: 60.6, Prediction: 63.1630744934082
Step [  94/151] -> Date: 2/2004, Target: 74.6, Prediction: 64.46197509765625
Step [  95/151] -> Date: 3/2004, Target: 74.8, Prediction: 55.91712951660156
Step [  96/151] -> Date: 4/2004, Target: 59.2, Prediction: 60.65922164916992
Step [  97/151] -> Date: 5/2004, Target: 72.8, Prediction: 46.222007751464844
Step [  98/151] -> Date: 6/2004, Target: 66.5, Prediction: 27.973243713378906
Step [  99/151] -> Date: 7/2004, Target: 83.8, Prediction: 30.151336669921875
Step [ 100/151] -> Date: 8/2004, Target: 69.7, Prediction: 30.52596664428711
Step [ 101/151] -> Date: 9/2004, Target: 48.8, Prediction: 36.30629348754883
Step [ 102/151] -> Date: 10/2004, Target: 74.2, Prediction: 35.63652038574219
Step [ 103/151] -> Date: 11/2004, Target: 70.1, Prediction: 24.918773651123047
Step [ 104/151] -> Date: 12/2004, Target: 28.9, Prediction: 25.760578155517578
Step [ 105/151] -> Date: 1/2005, Target: 48.1, Prediction: 21.35721206665039
Step [ 106/151] -> Date: 2/2005, Target: 43.5, Prediction: 18.31501007080078
Step [ 107/151] -> Date: 3/2005, Target: 39.6, Prediction: 18.255168914794922
Step [ 108/151] -> Date: 4/2005, Target: 38.7, Prediction: 19.88117218017578
Step [ 109/151] -> Date: 5/2005, Target: 61.9, Prediction: 14.733774185180664
Step [ 110/151] -> Date: 6/2005, Target: 56.8, Prediction: 14.142662048339844
Step [ 111/151] -> Date: 7/2005, Target: 62.4, Prediction: 14.185370445251465
Step [ 112/151] -> Date: 8/2005, Target: 60.5, Prediction: 13.95736312866211
Step [ 113/151] -> Date: 9/2005, Target: 37.2, Prediction: 13.56071662902832
Step [ 114/151] -> Date: 10/2005, Target: 13.2, Prediction: 13.266845703125
Step [ 115/151] -> Date: 11/2005, Target: 27.5, Prediction: 12.704330444335938
Step [ 116/151] -> Date: 12/2005, Target: 59.3, Prediction: 12.186262130737305
Step [ 117/151] -> Date: 1/2006, Target: 20.9, Prediction: 12.20318603515625
Step [ 118/151] -> Date: 2/2006, Target: 5.7, Prediction: 12.540075302124023
Step [ 119/151] -> Date: 3/2006, Target: 17.3, Prediction: 13.271692276000977
Step [ 120/151] -> Date: 4/2006, Target: 50.3, Prediction: 13.823002815246582
Step [ 121/151] -> Date: 5/2006, Target: 37.2, Prediction: 14.459405899047852
Step [ 122/151] -> Date: 6/2006, Target: 24.5, Prediction: 14.703489303588867
Step [ 123/151] -> Date: 7/2006, Target: 22.2, Prediction: 14.489587783813477
Step [ 124/151] -> Date: 8/2006, Target: 20.8, Prediction: 14.21186637878418
Step [ 125/151] -> Date: 9/2006, Target: 23.7, Prediction: 14.053960800170898
Step [ 126/151] -> Date: 10/2006, Target: 14.9, Prediction: 13.388273239135742
Step [ 127/151] -> Date: 11/2006, Target: 35.7, Prediction: 13.29261589050293
Step [ 128/151] -> Date: 12/2006, Target: 22.3, Prediction: 12.95372200012207
Step [ 129/151] -> Date: 1/2007, Target: 29.3, Prediction: 12.824640274047852
Step [ 130/151] -> Date: 2/2007, Target: 18.4, Prediction: 12.86890983581543
Step [ 131/151] -> Date: 3/2007, Target: 7.2, Prediction: 13.711762428283691
Step [ 132/151] -> Date: 4/2007, Target: 5.4, Prediction: 14.784258842468262
Step [ 133/151] -> Date: 5/2007, Target: 19.5, Prediction: 21.7003173828125
Step [ 134/151] -> Date: 6/2007, Target: 21.3, Prediction: 29.553054809570312
Step [ 135/151] -> Date: 7/2007, Target: 15.1, Prediction: 29.55907440185547
Step [ 136/151] -> Date: 8/2007, Target: 9.8, Prediction: 28.098896026611328
Step [ 137/151] -> Date: 9/2007, Target: 4.0, Prediction: 30.163639068603516
Step [ 138/151] -> Date: 10/2007, Target: 1.5, Prediction: 45.390071868896484
Step [ 139/151] -> Date: 11/2007, Target: 2.8, Prediction: 37.765472412109375
Step [ 140/151] -> Date: 12/2007, Target: 17.3, Prediction: 42.215232849121094
Step [ 141/151] -> Date: 1/2008, Target: 4.1, Prediction: 44.27070617675781
Step [ 142/151] -> Date: 2/2008, Target: 2.9, Prediction: 46.49080276489258
Step [ 143/151] -> Date: 3/2008, Target: 15.5, Prediction: 59.579463958740234
Step [ 144/151] -> Date: 4/2008, Target: 3.6, Prediction: 62.182979583740234
Step [ 145/151] -> Date: 5/2008, Target: 4.6, Prediction: 71.89954376220703
Step [ 146/151] -> Date: 6/2008, Target: 5.2, Prediction: 82.24715423583984
Step [ 147/151] -> Date: 7/2008, Target: 0.6, Prediction: 87.76414489746094
Step [ 148/151] -> Date: 8/2008, Target: 0.3, Prediction: 76.69496154785156
Step [ 149/151] -> Date: 9/2008, Target: 1.2, Prediction: 81.70995330810547
Step [ 150/151] -> Date: 10/2008, Target: 4.2, Prediction: 84.36422729492188
Step [ 151/151] -> Date: 11/2008, Target: 6.6, Prediction: 78.64435577392578
----------------------------------------------------------------------------------------------------
Average Validation Loss: 31.412929929644857
----------------------------------------------------------------------------------------------------
Plotting data...
----------------------------------------------------------------------------------------------------
Plotting loss data...
----------------------------------------------------------------------------------------------------
Validation finished successfully.

        Saved prediction/loss graphs can be found in: /home/extern/Dropbox/Research/scripts/graphs/
----------------------------------------------------------------------------------------------------
Predicting SC 24 using the above trained model
Step [   1/151] -> Date: 12/2008, Prediction: 14.747051239013672
Step [   2/151] -> Date: 1/2009, Prediction: 15.05398178100586
Step [   3/151] -> Date: 2/2009, Prediction: 18.27288246154785
Step [   4/151] -> Date: 3/2009, Prediction: 15.23182487487793
Step [   5/151] -> Date: 4/2009, Prediction: 14.661521911621094
Step [   6/151] -> Date: 5/2009, Prediction: 19.326602935791016
Step [   7/151] -> Date: 6/2009, Prediction: 13.846342086791992
Step [   8/151] -> Date: 7/2009, Prediction: 13.42070198059082
Step [   9/151] -> Date: 8/2009, Prediction: 13.678250312805176
Step [  10/151] -> Date: 9/2009, Prediction: 13.702191352844238
Step [  11/151] -> Date: 10/2009, Prediction: 16.209402084350586
Step [  12/151] -> Date: 11/2009, Prediction: 16.306203842163086
Step [  13/151] -> Date: 12/2009, Prediction: 44.85874557495117
Step [  14/151] -> Date: 1/2010, Prediction: 42.09477233886719
Step [  15/151] -> Date: 2/2010, Prediction: 52.852230072021484
Step [  16/151] -> Date: 3/2010, Prediction: 65.04328918457031
Step [  17/151] -> Date: 4/2010, Prediction: 54.180721282958984
Step [  18/151] -> Date: 5/2010, Prediction: 60.50184631347656
Step [  19/151] -> Date: 6/2010, Prediction: 58.7586669921875
Step [  20/151] -> Date: 7/2010, Prediction: 55.80036926269531
Step [  21/151] -> Date: 8/2010, Prediction: 57.01950454711914
Step [  22/151] -> Date: 9/2010, Prediction: 72.27942657470703
Step [  23/151] -> Date: 10/2010, Prediction: 65.55843353271484
Step [  24/151] -> Date: 11/2010, Prediction: 71.53978729248047
Step [  25/151] -> Date: 12/2010, Prediction: 109.15634155273438
Step [  26/151] -> Date: 1/2011, Prediction: 112.87456512451172
Step [  27/151] -> Date: 2/2011, Prediction: 126.80884552001953
Step [  28/151] -> Date: 3/2011, Prediction: 129.37889099121094
Step [  29/151] -> Date: 4/2011, Prediction: 108.05513000488281
Step [  30/151] -> Date: 5/2011, Prediction: 116.87115478515625
Step [  31/151] -> Date: 6/2011, Prediction: 120.63893127441406
Step [  32/151] -> Date: 7/2011, Prediction: 108.07164764404297
Step [  33/151] -> Date: 8/2011, Prediction: 112.24105072021484
Step [  34/151] -> Date: 9/2011, Prediction: 114.9288101196289
Step [  35/151] -> Date: 10/2011, Prediction: 110.11253356933594
Step [  36/151] -> Date: 11/2011, Prediction: 131.19564819335938
Step [  37/151] -> Date: 12/2011, Prediction: 181.1344757080078
Step [  38/151] -> Date: 1/2012, Prediction: 169.93190002441406
Step [  39/151] -> Date: 2/2012, Prediction: 161.8685302734375
Step [  40/151] -> Date: 3/2012, Prediction: 149.80996704101562
Step [  41/151] -> Date: 4/2012, Prediction: 175.1546173095703
Step [  42/151] -> Date: 5/2012, Prediction: 180.08123779296875
Step [  43/151] -> Date: 6/2012, Prediction: 148.19088745117188
Step [  44/151] -> Date: 7/2012, Prediction: 155.37680053710938
Step [  45/151] -> Date: 8/2012, Prediction: 169.86097717285156
Step [  46/151] -> Date: 9/2012, Prediction: 185.50192260742188
Step [  47/151] -> Date: 10/2012, Prediction: 178.19564819335938
Step [  48/151] -> Date: 11/2012, Prediction: 168.22222900390625
Step [  49/151] -> Date: 12/2012, Prediction: 189.2135009765625
Step [  50/151] -> Date: 1/2013, Prediction: 215.71807861328125
Step [  51/151] -> Date: 2/2013, Prediction: 187.8424530029297
Step [  52/151] -> Date: 3/2013, Prediction: 180.78970336914062
Step [  53/151] -> Date: 4/2013, Prediction: 174.06704711914062
Step [  54/151] -> Date: 5/2013, Prediction: 180.59988403320312
Step [  55/151] -> Date: 6/2013, Prediction: 166.14064025878906
Step [  56/151] -> Date: 7/2013, Prediction: 163.95994567871094
Step [  57/151] -> Date: 8/2013, Prediction: 154.5880584716797
Step [  58/151] -> Date: 9/2013, Prediction: 180.91786193847656
Step [  59/151] -> Date: 10/2013, Prediction: 180.44039916992188
Step [  60/151] -> Date: 11/2013, Prediction: 166.80612182617188
Step [  61/151] -> Date: 12/2013, Prediction: 184.6858367919922
Step [  62/151] -> Date: 1/2014, Prediction: 153.42872619628906
Step [  63/151] -> Date: 2/2014, Prediction: 170.40133666992188
Step [  64/151] -> Date: 3/2014, Prediction: 203.20211791992188
Step [  65/151] -> Date: 4/2014, Prediction: 188.7880096435547
Step [  66/151] -> Date: 5/2014, Prediction: 178.27066040039062
Step [  67/151] -> Date: 6/2014, Prediction: 181.35263061523438
Step [  68/151] -> Date: 7/2014, Prediction: 166.08428955078125
Step [  69/151] -> Date: 8/2014, Prediction: 164.5193634033203
Step [  70/151] -> Date: 9/2014, Prediction: 161.30435180664062
Step [  71/151] -> Date: 10/2014, Prediction: 179.92567443847656
Step [  72/151] -> Date: 11/2014, Prediction: 178.23118591308594
Step [  73/151] -> Date: 12/2014, Prediction: 128.37847900390625
Step [  74/151] -> Date: 1/2015, Prediction: 144.85162353515625
Step [  75/151] -> Date: 2/2015, Prediction: 152.70779418945312
Step [  76/151] -> Date: 3/2015, Prediction: 157.74485778808594
Step [  77/151] -> Date: 4/2015, Prediction: 149.61927795410156
Step [  78/151] -> Date: 5/2015, Prediction: 143.84336853027344
Step [  79/151] -> Date: 6/2015, Prediction: 136.1280975341797
Step [  80/151] -> Date: 7/2015, Prediction: 134.34652709960938
Step [  81/151] -> Date: 8/2015, Prediction: 112.82515716552734
Step [  82/151] -> Date: 9/2015, Prediction: 124.09837341308594
Step [  83/151] -> Date: 10/2015, Prediction: 122.88668060302734
Step [  84/151] -> Date: 11/2015, Prediction: 121.82715606689453
Step [  85/151] -> Date: 12/2015, Prediction: 101.5499496459961
Step [  86/151] -> Date: 1/2016, Prediction: 103.25202178955078
Step [  87/151] -> Date: 2/2016, Prediction: 100.56689453125
Step [  88/151] -> Date: 3/2016, Prediction: 83.67304992675781
Step [  89/151] -> Date: 4/2016, Prediction: 100.31013488769531
Step [  90/151] -> Date: 5/2016, Prediction: 90.6315689086914
Step [  91/151] -> Date: 6/2016, Prediction: 79.59744262695312
Step [  92/151] -> Date: 7/2016, Prediction: 76.98710632324219
Step [  93/151] -> Date: 8/2016, Prediction: 76.06758880615234
Step [  94/151] -> Date: 9/2016, Prediction: 76.14749908447266
Step [  95/151] -> Date: 10/2016, Prediction: 67.73039245605469
Step [  96/151] -> Date: 11/2016, Prediction: 72.40176391601562
Step [  97/151] -> Date: 12/2016, Prediction: 38.85956954956055
Step [  98/151] -> Date: 1/2017, Prediction: 52.63030242919922
Step [  99/151] -> Date: 2/2017, Prediction: 42.142173767089844
Step [ 100/151] -> Date: 3/2017, Prediction: 33.914161682128906
Step [ 101/151] -> Date: 4/2017, Prediction: 44.4809455871582
Step [ 102/151] -> Date: 5/2017, Prediction: 50.5746955871582
Step [ 103/151] -> Date: 6/2017, Prediction: 27.26673126220703
Step [ 104/151] -> Date: 7/2017, Prediction: 40.750030517578125
Step [ 105/151] -> Date: 8/2017, Prediction: 30.895530700683594
Step [ 106/151] -> Date: 9/2017, Prediction: 28.729782104492188
Step [ 107/151] -> Date: 10/2017, Prediction: 27.369129180908203
Step [ 108/151] -> Date: 11/2017, Prediction: 41.20968246459961
Step [ 109/151] -> Date: 12/2017, Prediction: 16.660114288330078
Step [ 110/151] -> Date: 1/2018, Prediction: 21.72836685180664
Step [ 111/151] -> Date: 2/2018, Prediction: 21.833614349365234
Step [ 112/151] -> Date: 3/2018, Prediction: 16.012706756591797
Step [ 113/151] -> Date: 4/2018, Prediction: 13.3887939453125
Step [ 114/151] -> Date: 5/2018, Prediction: 13.250467300415039
Step [ 115/151] -> Date: 6/2018, Prediction: 17.553508758544922
Step [ 116/151] -> Date: 7/2018, Prediction: 12.380335807800293
Step [ 117/151] -> Date: 8/2018, Prediction: 12.148397445678711
Step [ 118/151] -> Date: 9/2018, Prediction: 12.684673309326172
Step [ 119/151] -> Date: 10/2018, Prediction: 13.76544189453125
Step [ 120/151] -> Date: 11/2018, Prediction: 13.753488540649414
Step [ 121/151] -> Date: 12/2018, Prediction: 14.431663513183594
Step [ 122/151] -> Date: 1/2019, Prediction: 14.472946166992188
Step [ 123/151] -> Date: 2/2019, Prediction: 14.70263671875
Step [ 124/151] -> Date: 3/2019, Prediction: 14.38770866394043
Step [ 125/151] -> Date: 4/2019, Prediction: 13.902475357055664
Step [ 126/151] -> Date: 5/2019, Prediction: 13.80001449584961
Step [ 127/151] -> Date: 6/2019, Prediction: 13.584896087646484
Step [ 128/151] -> Date: 7/2019, Prediction: 13.225326538085938
Step [ 129/151] -> Date: 8/2019, Prediction: 12.829645156860352
Step [ 130/151] -> Date: 9/2019, Prediction: 12.973450660705566
Step [ 131/151] -> Date: 10/2019, Prediction: 13.42264461517334
Step [ 132/151] -> Date: 11/2019, Prediction: 13.964492797851562
Step [ 133/151] -> Date: 12/2019, Prediction: 14.903303146362305
Step [ 134/151] -> Date: 1/2020, Prediction: 15.050826072692871
Step [ 135/151] -> Date: 2/2020, Prediction: 14.941082954406738
Step [ 136/151] -> Date: 3/2020, Prediction: 14.793304443359375
Step [ 137/151] -> Date: 4/2020, Prediction: 14.190252304077148
Step [ 138/151] -> Date: 5/2020, Prediction: 13.77265453338623
Step [ 139/151] -> Date: 6/2020, Prediction: 13.859888076782227
Step [ 140/151] -> Date: 7/2020, Prediction: 13.324478149414062
Step [ 141/151] -> Date: 8/2020, Prediction: 13.617305755615234
Step [ 142/151] -> Date: 9/2020, Prediction: 14.224746704101562
Step [ 143/151] -> Date: 10/2020, Prediction: 14.024617195129395
Step [ 144/151] -> Date: 11/2020, Prediction: 14.295719146728516
Step [ 145/151] -> Date: 12/2020, Prediction: 38.853111267089844
Step [ 146/151] -> Date: 1/2021, Prediction: 36.64427947998047
Step [ 147/151] -> Date: 2/2021, Prediction: 36.78200149536133
Step [ 148/151] -> Date: 3/2021, Prediction: 38.18886184692383
Step [ 149/151] -> Date: 4/2021, Prediction: 40.310752868652344
Step [ 150/151] -> Date: 5/2021, Prediction: 39.24618148803711
Step [ 151/151] -> Date: 6/2021, Prediction: 36.300689697265625
----------------------------------------------------------------------------------------------------
Plotting data...
----------------------------------------------------------------------------------------------------
All newly generated files moved to saved outputs and shared with the cloud(Dropbox) successfully!

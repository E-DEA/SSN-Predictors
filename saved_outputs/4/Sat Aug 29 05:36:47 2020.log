----------------------------------------------------------------------------------------------------
Usage: python3 SSN_predictor.py <path_to_ssn_datafile> <path_to_aa_datafile>
----------------------------------------------------------------------------------------------------
Code running on device: cuda
----------------------------------------------------------------------------------------------------
Data loaded from file locations :
    SSN - /home/extern/Dropbox/Research/scripts/data/SILSO/TSN/SN_m_tot_V2.0.txt
    AA - /home/extern/Dropbox/Research/scripts/data/ISGI/aa_1869-01-01_2018-12-31_D.dat
----------------------------------------------------------------------------------------------------
Solar cycle data loaded/saved as: cycle_data.pickle
----------------------------------------------------------------------------------------------------
SC Number     Start Date       End Date      Solar Max   Length(in months)
         0      [1749, 1]      [1755, 1]         154.27                  73
         1      [1755, 2]      [1766, 5]         144.12                 136
         2      [1766, 6]      [1775, 5]         192.98                 108
         3      [1775, 6]      [1784, 8]         264.25                 111
         4      [1784, 9]      [1798, 3]         235.28                 163
         5      [1798, 4]     [1810, 11]          67.93                 152
         6     [1810, 12]      [1823, 4]          81.99                 149
         7      [1823, 5]     [1833, 10]          81.16                 126
         8     [1833, 11]      [1843, 6]         119.24                 116
         9      [1843, 7]     [1855, 11]         244.87                 149
        10     [1855, 12]      [1867, 2]         219.94                 135
        11      [1867, 3]     [1878, 11]         186.15                 141
        12     [1878, 12]      [1890, 2]         234.02                 135
        13      [1890, 3]      [1902, 0]         124.41                 142
        14      [1902, 1]      [1913, 6]         146.55                 138
        15      [1913, 7]      [1923, 7]         107.08                 121
        16      [1923, 8]      [1933, 8]         175.67                 121
        17      [1933, 9]      [1944, 1]         130.23                 125
        18      [1944, 2]      [1954, 3]         198.64                 122
        19      [1954, 4]      [1964, 9]         218.73                 126
        20     [1964, 10]      [1976, 2]          285.0                 137
        21      [1976, 3]      [1986, 8]         156.63                 126
        22      [1986, 9]      [1996, 4]         232.92                 116
        23      [1996, 5]     [2008, 11]         212.48                 151
        24     [2008, 12]     [2019, 11]         180.28                 132
----------------------------------------------------------------------------------------------------
Selected model: FFNN(
  (model): Sequential(
    (0): Linear(in_features=6, out_features=6, bias=True)
    (1): LeakyReLU(negative_slope=0.01, inplace=True)
    (2): Linear(in_features=6, out_features=3, bias=True)
    (3): LeakyReLU(negative_slope=0.01, inplace=True)
    (4): Linear(in_features=3, out_features=1, bias=True)
  )
)    Training mode: True    Prediction mode: True
----------------------------------------------------------------------------------------------------
Selected optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0
)
----------------------------------------------------------------------------------------------------
Selected scheduler: ReduceLROnPlateau(
    {'factor': 0.9, 'min_lrs': [0], 'patience': 10, 'verbose': True, 'cooldown': 0, 'cooldown_counter': 0, 'mode': 'min', 'threshold': 0.0001, 'threshold_mode': 'rel', 'best': inf, 'num_bad_epochs': 0, 'mode_worse': inf, 'eps': 1e-08, 'last_epoch': 0})
----------------------------------------------------------------------------------------------------
No pre-trained models available, initializing model weights
----------------------------------------------------------------------------------------------------
Training model with solar cycle 12 to 22 data with: num_epochs=1400
Epoch [   5/1400] -> Loss: 38.0573
Epoch [  10/1400] -> Loss: 34.7436
Epoch [  15/1400] -> Loss: 34.4403
Epoch [  20/1400] -> Loss: 34.2276
Epoch [  25/1400] -> Loss: 34.0685
Epoch [  30/1400] -> Loss: 33.9457
Epoch [  35/1400] -> Loss: 33.8305
Epoch [  40/1400] -> Loss: 33.7343
Epoch [  45/1400] -> Loss: 33.6662
Epoch [  50/1400] -> Loss: 33.6016
Epoch [  55/1400] -> Loss: 33.5513
Epoch [  60/1400] -> Loss: 33.4885
Epoch [  65/1400] -> Loss: 33.4451
Epoch [  70/1400] -> Loss: 33.4168
Epoch [  75/1400] -> Loss: 33.3752
Epoch [  80/1400] -> Loss: 33.3391
Epoch [  85/1400] -> Loss: 33.3066
Epoch [  90/1400] -> Loss: 33.2788
Epoch [  95/1400] -> Loss: 33.2364
----------------------------------------------------------------------------------------------------
Model checkpoint saved as _FFNN_100.pth
----------------------------------------------------------------------------------------------------
Epoch [ 100/1400] -> Loss: 33.2003
Epoch [ 105/1400] -> Loss: 33.1741
Epoch [ 110/1400] -> Loss: 33.1415
Epoch [ 115/1400] -> Loss: 33.1067
Epoch [ 120/1400] -> Loss: 33.0713
Epoch [ 125/1400] -> Loss: 33.0300
Epoch [ 130/1400] -> Loss: 32.9900
Epoch [ 135/1400] -> Loss: 32.9652
Epoch [ 140/1400] -> Loss: 32.9307
Epoch [ 145/1400] -> Loss: 32.8890
Epoch [ 150/1400] -> Loss: 32.8583
Epoch [ 155/1400] -> Loss: 32.8184
Epoch [ 160/1400] -> Loss: 32.7827
Epoch [ 165/1400] -> Loss: 32.7449
Epoch [ 170/1400] -> Loss: 32.7045
Epoch [ 175/1400] -> Loss: 32.6731
Epoch [ 180/1400] -> Loss: 32.6295
Epoch [ 185/1400] -> Loss: 32.5991
Epoch [ 190/1400] -> Loss: 32.5553
Epoch [ 195/1400] -> Loss: 32.5151
----------------------------------------------------------------------------------------------------
Model checkpoint saved as _FFNN_200.pth
----------------------------------------------------------------------------------------------------
Epoch [ 200/1400] -> Loss: 32.4887
Epoch [ 205/1400] -> Loss: 32.4485
Epoch [ 210/1400] -> Loss: 32.4158
Epoch [ 215/1400] -> Loss: 32.3761
Epoch [ 220/1400] -> Loss: 32.3370
Epoch [ 225/1400] -> Loss: 32.3019
Epoch [ 230/1400] -> Loss: 32.2624
Epoch [ 235/1400] -> Loss: 32.2193
Epoch [ 240/1400] -> Loss: 32.1801
Epoch [ 245/1400] -> Loss: 32.1402
Epoch [ 250/1400] -> Loss: 32.1041
Epoch [ 255/1400] -> Loss: 32.0576
Epoch [ 260/1400] -> Loss: 32.0092
Epoch [ 265/1400] -> Loss: 31.9708
Epoch [ 270/1400] -> Loss: 31.9256
Epoch [ 275/1400] -> Loss: 31.8836
Epoch [ 280/1400] -> Loss: 31.8352
Epoch [ 285/1400] -> Loss: 31.7907
Epoch [ 290/1400] -> Loss: 31.7414
Epoch [ 295/1400] -> Loss: 31.6903
----------------------------------------------------------------------------------------------------
Model checkpoint saved as _FFNN_300.pth
----------------------------------------------------------------------------------------------------
Epoch [ 300/1400] -> Loss: 31.6436
Epoch [ 305/1400] -> Loss: 31.5952
Epoch [ 310/1400] -> Loss: 31.5514
Epoch [ 315/1400] -> Loss: 31.4927
Epoch [ 320/1400] -> Loss: 31.4423
Epoch [ 325/1400] -> Loss: 31.3769
Epoch [ 330/1400] -> Loss: 31.3296
Epoch [ 335/1400] -> Loss: 31.2761
Epoch [ 340/1400] -> Loss: 31.2149
Epoch [ 345/1400] -> Loss: 31.1565
Epoch [ 350/1400] -> Loss: 31.1000
Epoch [ 355/1400] -> Loss: 31.0265
Epoch [ 360/1400] -> Loss: 30.9704
Epoch [ 365/1400] -> Loss: 30.9099
Epoch [ 370/1400] -> Loss: 30.8414
Epoch [ 375/1400] -> Loss: 30.7742
Epoch [ 380/1400] -> Loss: 30.7123
Epoch [ 385/1400] -> Loss: 30.6653
Epoch [ 390/1400] -> Loss: 30.5974
Epoch [ 395/1400] -> Loss: 30.5256
----------------------------------------------------------------------------------------------------
Model checkpoint saved as _FFNN_400.pth
----------------------------------------------------------------------------------------------------
Epoch [ 400/1400] -> Loss: 30.4669
Epoch [ 405/1400] -> Loss: 30.4057
Epoch [ 410/1400] -> Loss: 30.3424
Epoch [ 415/1400] -> Loss: 30.2811
Epoch [ 420/1400] -> Loss: 30.2265
Epoch [ 425/1400] -> Loss: 30.1549
Epoch [ 430/1400] -> Loss: 30.0978
Epoch [ 435/1400] -> Loss: 30.0372
Epoch [ 440/1400] -> Loss: 29.9780
Epoch [ 445/1400] -> Loss: 29.9093
Epoch [ 450/1400] -> Loss: 29.8467
Epoch [ 455/1400] -> Loss: 29.7787
Epoch [ 460/1400] -> Loss: 29.7207
Epoch [ 465/1400] -> Loss: 29.6722
Epoch [ 470/1400] -> Loss: 29.6054
Epoch [ 475/1400] -> Loss: 29.5461
Epoch [ 480/1400] -> Loss: 29.4862
Epoch [ 485/1400] -> Loss: 29.4320
Epoch [ 490/1400] -> Loss: 29.3862
Epoch [ 495/1400] -> Loss: 29.3119
----------------------------------------------------------------------------------------------------
Model checkpoint saved as _FFNN_500.pth
----------------------------------------------------------------------------------------------------
Epoch [ 500/1400] -> Loss: 29.2711
Epoch [ 505/1400] -> Loss: 29.2389
Epoch [ 510/1400] -> Loss: 29.1910
Epoch [ 515/1400] -> Loss: 29.1491
Epoch [ 520/1400] -> Loss: 29.1003
Epoch [ 525/1400] -> Loss: 29.0761
Epoch [ 530/1400] -> Loss: 29.0392
Epoch [ 535/1400] -> Loss: 29.0037
Epoch [ 540/1400] -> Loss: 28.9692
Epoch [ 545/1400] -> Loss: 28.9491
Epoch [ 550/1400] -> Loss: 28.9146
Epoch [ 555/1400] -> Loss: 28.8901
Epoch [ 560/1400] -> Loss: 28.8761
Epoch [ 565/1400] -> Loss: 28.8499
Epoch [ 570/1400] -> Loss: 28.7915
Epoch [ 575/1400] -> Loss: 28.7863
Epoch [ 580/1400] -> Loss: 28.7875
Epoch [ 585/1400] -> Loss: 28.7566
Epoch [ 590/1400] -> Loss: 28.7416
Epoch [ 595/1400] -> Loss: 28.7212
----------------------------------------------------------------------------------------------------
Model checkpoint saved as _FFNN_600.pth
----------------------------------------------------------------------------------------------------
Epoch [ 600/1400] -> Loss: 28.7130
Epoch [ 605/1400] -> Loss: 28.6744
Epoch [ 610/1400] -> Loss: 28.6468
Epoch [ 615/1400] -> Loss: 28.6235
Epoch [ 620/1400] -> Loss: 28.5979
Epoch [ 625/1400] -> Loss: 28.5715
Epoch [ 630/1400] -> Loss: 28.5356
Epoch [ 635/1400] -> Loss: 28.5513
Epoch [ 640/1400] -> Loss: 28.5117
Epoch [ 645/1400] -> Loss: 28.4897
Epoch [ 650/1400] -> Loss: 28.4750
Epoch   653: reducing learning rate of group 0 to 9.0000e-05.
Epoch [ 655/1400] -> Loss: 28.4680
Epoch [ 660/1400] -> Loss: 28.4487
Epoch [ 665/1400] -> Loss: 28.4399
Epoch [ 670/1400] -> Loss: 28.4288
Epoch [ 675/1400] -> Loss: 28.4230
Epoch [ 680/1400] -> Loss: 28.4131
Epoch [ 685/1400] -> Loss: 28.3972
Epoch [ 690/1400] -> Loss: 28.3760
Epoch [ 695/1400] -> Loss: 28.3696
----------------------------------------------------------------------------------------------------
Model checkpoint saved as _FFNN_700.pth
----------------------------------------------------------------------------------------------------
Epoch [ 700/1400] -> Loss: 28.3656
Epoch [ 705/1400] -> Loss: 28.3610
Epoch   709: reducing learning rate of group 0 to 8.1000e-05.
Epoch [ 710/1400] -> Loss: 28.3376
Epoch [ 715/1400] -> Loss: 28.3030
Epoch [ 720/1400] -> Loss: 28.3135
Epoch [ 725/1400] -> Loss: 28.3159
Epoch [ 730/1400] -> Loss: 28.3074
Epoch [ 735/1400] -> Loss: 28.3013
Epoch [ 740/1400] -> Loss: 28.3033
Epoch [ 745/1400] -> Loss: 28.2846
Epoch   750: reducing learning rate of group 0 to 7.2900e-05.
Epoch [ 750/1400] -> Loss: 28.2942
Epoch [ 755/1400] -> Loss: 28.2682
Epoch [ 760/1400] -> Loss: 28.2707
Epoch [ 765/1400] -> Loss: 28.2730
Epoch [ 770/1400] -> Loss: 28.2623
Epoch [ 775/1400] -> Loss: 28.2588
Epoch [ 780/1400] -> Loss: 28.2599
Epoch   784: reducing learning rate of group 0 to 6.5610e-05.
Epoch [ 785/1400] -> Loss: 28.2449
Epoch [ 790/1400] -> Loss: 28.2373
Epoch [ 795/1400] -> Loss: 28.2320
Epoch   798: reducing learning rate of group 0 to 5.9049e-05.
----------------------------------------------------------------------------------------------------
Model checkpoint saved as _FFNN_800.pth
----------------------------------------------------------------------------------------------------
Epoch [ 800/1400] -> Loss: 28.2255
Epoch [ 805/1400] -> Loss: 28.2271
Epoch [ 810/1400] -> Loss: 28.1862
Epoch [ 815/1400] -> Loss: 28.2218
Epoch [ 820/1400] -> Loss: 28.2090
Epoch   821: reducing learning rate of group 0 to 5.3144e-05.
Epoch [ 825/1400] -> Loss: 28.2135
Epoch [ 830/1400] -> Loss: 28.2000
Epoch   832: reducing learning rate of group 0 to 4.7830e-05.
Epoch [ 835/1400] -> Loss: 28.1921
Epoch [ 840/1400] -> Loss: 28.1833
Epoch [ 845/1400] -> Loss: 28.1897
Epoch [ 850/1400] -> Loss: 28.1708
Epoch [ 855/1400] -> Loss: 28.1830
Epoch [ 860/1400] -> Loss: 28.1754
Epoch [ 865/1400] -> Loss: 28.1717
Epoch [ 870/1400] -> Loss: 28.1804
Epoch [ 875/1400] -> Loss: 28.1754
Epoch [ 880/1400] -> Loss: 28.1586
Epoch [ 885/1400] -> Loss: 28.1592
Epoch [ 890/1400] -> Loss: 28.1436
Epoch   893: reducing learning rate of group 0 to 4.3047e-05.
Epoch [ 895/1400] -> Loss: 28.1506
----------------------------------------------------------------------------------------------------
Model checkpoint saved as _FFNN_900.pth
----------------------------------------------------------------------------------------------------
Epoch [ 900/1400] -> Loss: 28.1475
Epoch [ 905/1400] -> Loss: 28.1487
Epoch [ 910/1400] -> Loss: 28.1469
Epoch [ 915/1400] -> Loss: 28.1322
Epoch   919: reducing learning rate of group 0 to 3.8742e-05.
Epoch [ 920/1400] -> Loss: 28.1331
Epoch [ 925/1400] -> Loss: 28.1304
Epoch   930: reducing learning rate of group 0 to 3.4868e-05.
Epoch [ 930/1400] -> Loss: 28.1342
Epoch [ 935/1400] -> Loss: 28.1191
Epoch [ 940/1400] -> Loss: 28.1115
Epoch [ 945/1400] -> Loss: 28.1209
Epoch [ 950/1400] -> Loss: 28.1219
Epoch   951: reducing learning rate of group 0 to 3.1381e-05.
Epoch [ 955/1400] -> Loss: 28.1162
Epoch [ 960/1400] -> Loss: 28.1123
Epoch   962: reducing learning rate of group 0 to 2.8243e-05.
Epoch [ 965/1400] -> Loss: 28.1044
Epoch [ 970/1400] -> Loss: 28.1047
Epoch [ 975/1400] -> Loss: 28.1087
Epoch   976: reducing learning rate of group 0 to 2.5419e-05.
Epoch [ 980/1400] -> Loss: 28.1078
Epoch [ 985/1400] -> Loss: 28.1020
Epoch [ 990/1400] -> Loss: 28.1004
Epoch [ 995/1400] -> Loss: 28.1011
Epoch   999: reducing learning rate of group 0 to 2.2877e-05.
----------------------------------------------------------------------------------------------------
Model checkpoint saved as _FFNN_1000.pth
----------------------------------------------------------------------------------------------------
Epoch [1000/1400] -> Loss: 28.0974
Epoch [1005/1400] -> Loss: 28.0956
Epoch [1010/1400] -> Loss: 28.0982
Epoch [1015/1400] -> Loss: 28.0945
Epoch [1020/1400] -> Loss: 28.0941
Epoch [1025/1400] -> Loss: 28.0897
Epoch  1028: reducing learning rate of group 0 to 2.0589e-05.
Epoch [1030/1400] -> Loss: 28.0893
Epoch [1035/1400] -> Loss: 28.0841
Epoch [1040/1400] -> Loss: 28.0848
Epoch  1045: reducing learning rate of group 0 to 1.8530e-05.
Epoch [1045/1400] -> Loss: 28.0839
Epoch [1050/1400] -> Loss: 28.0774
Epoch [1055/1400] -> Loss: 28.0807
Epoch [1060/1400] -> Loss: 28.0792
Epoch  1061: reducing learning rate of group 0 to 1.6677e-05.
Epoch [1065/1400] -> Loss: 28.0760
Epoch [1070/1400] -> Loss: 28.0775
Epoch  1072: reducing learning rate of group 0 to 1.5009e-05.
Epoch [1075/1400] -> Loss: 28.0756
Epoch [1080/1400] -> Loss: 28.0744
Epoch [1085/1400] -> Loss: 28.0729
Epoch  1087: reducing learning rate of group 0 to 1.3509e-05.
Epoch [1090/1400] -> Loss: 28.0712
Epoch [1095/1400] -> Loss: 28.0695
Epoch  1098: reducing learning rate of group 0 to 1.2158e-05.
----------------------------------------------------------------------------------------------------
Model checkpoint saved as _FFNN_1100.pth
----------------------------------------------------------------------------------------------------
Epoch [1100/1400] -> Loss: 28.0688
Epoch [1105/1400] -> Loss: 28.0680
Epoch [1110/1400] -> Loss: 28.0669
Epoch  1112: reducing learning rate of group 0 to 1.0942e-05.
Epoch [1115/1400] -> Loss: 28.0653
Epoch [1120/1400] -> Loss: 28.0649
Epoch  1125: reducing learning rate of group 0 to 9.8477e-06.
Epoch [1125/1400] -> Loss: 28.0643
Epoch [1130/1400] -> Loss: 28.0631
Epoch [1135/1400] -> Loss: 28.0643
Epoch  1136: reducing learning rate of group 0 to 8.8629e-06.
Epoch [1140/1400] -> Loss: 28.0616
Epoch [1145/1400] -> Loss: 28.0598
Epoch [1150/1400] -> Loss: 28.0605
Epoch  1151: reducing learning rate of group 0 to 7.9766e-06.
Epoch [1155/1400] -> Loss: 28.0599
Epoch [1160/1400] -> Loss: 28.0584
Epoch [1165/1400] -> Loss: 28.0585
Epoch [1170/1400] -> Loss: 28.0590
Epoch  1171: reducing learning rate of group 0 to 7.1790e-06.
Epoch [1175/1400] -> Loss: 28.0567
Epoch [1180/1400] -> Loss: 28.0573
Epoch  1182: reducing learning rate of group 0 to 6.4611e-06.
Epoch [1185/1400] -> Loss: 28.0558
Epoch [1190/1400] -> Loss: 28.0550
Epoch [1195/1400] -> Loss: 28.0554
----------------------------------------------------------------------------------------------------
Model checkpoint saved as _FFNN_1200.pth
----------------------------------------------------------------------------------------------------
Epoch [1200/1400] -> Loss: 28.0556
Epoch  1201: reducing learning rate of group 0 to 5.8150e-06.
Epoch [1205/1400] -> Loss: 28.0539
Epoch [1210/1400] -> Loss: 28.0541
Epoch  1212: reducing learning rate of group 0 to 5.2335e-06.
Epoch [1215/1400] -> Loss: 28.0535
Epoch [1220/1400] -> Loss: 28.0528
Epoch  1223: reducing learning rate of group 0 to 4.7101e-06.
Epoch [1225/1400] -> Loss: 28.0523
Epoch [1230/1400] -> Loss: 28.0522
Epoch [1235/1400] -> Loss: 28.0523
Epoch  1237: reducing learning rate of group 0 to 4.2391e-06.
Epoch [1240/1400] -> Loss: 28.0512
Epoch [1245/1400] -> Loss: 28.0517
Epoch  1248: reducing learning rate of group 0 to 3.8152e-06.
Epoch [1250/1400] -> Loss: 28.0503
Epoch [1255/1400] -> Loss: 28.0499
Epoch  1259: reducing learning rate of group 0 to 3.4337e-06.
Epoch [1260/1400] -> Loss: 28.0501
Epoch [1265/1400] -> Loss: 28.0501
Epoch  1270: reducing learning rate of group 0 to 3.0903e-06.
Epoch [1270/1400] -> Loss: 28.0496
Epoch [1275/1400] -> Loss: 28.0487
Epoch [1280/1400] -> Loss: 28.0492
Epoch [1285/1400] -> Loss: 28.0489
Epoch  1286: reducing learning rate of group 0 to 2.7813e-06.
Epoch [1290/1400] -> Loss: 28.0484
Epoch [1295/1400] -> Loss: 28.0483
Epoch  1297: reducing learning rate of group 0 to 2.5032e-06.
----------------------------------------------------------------------------------------------------
Model checkpoint saved as _FFNN_1300.pth
----------------------------------------------------------------------------------------------------
Epoch [1300/1400] -> Loss: 28.0482
Epoch [1305/1400] -> Loss: 28.0477
Epoch  1308: reducing learning rate of group 0 to 2.2528e-06.
Epoch [1310/1400] -> Loss: 28.0474
Epoch [1315/1400] -> Loss: 28.0473
Epoch  1319: reducing learning rate of group 0 to 2.0276e-06.
Epoch [1320/1400] -> Loss: 28.0475
Epoch [1325/1400] -> Loss: 28.0470
Epoch  1330: reducing learning rate of group 0 to 1.8248e-06.
Epoch [1330/1400] -> Loss: 28.0470
Epoch [1335/1400] -> Loss: 28.0468
Epoch [1340/1400] -> Loss: 28.0465
Epoch  1341: reducing learning rate of group 0 to 1.6423e-06.
Epoch [1345/1400] -> Loss: 28.0463
Epoch [1350/1400] -> Loss: 28.0462
Epoch  1352: reducing learning rate of group 0 to 1.4781e-06.
Epoch [1355/1400] -> Loss: 28.0459
Epoch [1360/1400] -> Loss: 28.0461
Epoch [1365/1400] -> Loss: 28.0460
Epoch  1370: reducing learning rate of group 0 to 1.3303e-06.
Epoch [1370/1400] -> Loss: 28.0458
Epoch [1375/1400] -> Loss: 28.0456
Epoch [1380/1400] -> Loss: 28.0456
Epoch  1381: reducing learning rate of group 0 to 1.1973e-06.
Epoch [1385/1400] -> Loss: 28.0454
Epoch [1390/1400] -> Loss: 28.0453
Epoch  1392: reducing learning rate of group 0 to 1.0775e-06.
Epoch [1395/1400] -> Loss: 28.0452
----------------------------------------------------------------------------------------------------
Model checkpoint saved as _FFNN_1400.pth
----------------------------------------------------------------------------------------------------
Epoch [1400/1400] -> Loss: 28.0452
----------------------------------------------------------------------------------------------------
Plotting loss data...
----------------------------------------------------------------------------------------------------
Training finished successfully.
        Saved model checkpoints can be found in: /home/extern/Dropbox/Research/scripts/models/
        Saved data/loss graphs can be found in: /home/extern/Dropbox/Research/scripts/graphs/
----------------------------------------------------------------------------------------------------
Validating model for solar cycle 23 data
Step [   1/151] -> Date: 5/1996, Target: 7.6, Prediction: 26.126373291015625
Step [   2/151] -> Date: 6/1996, Target: 16.5, Prediction: 24.12671661376953
Step [   3/151] -> Date: 7/1996, Target: 11.8, Prediction: 16.065462112426758
Step [   4/151] -> Date: 8/1996, Target: 19.7, Prediction: 15.243061065673828
Step [   5/151] -> Date: 9/1996, Target: 3.0, Prediction: 15.716970443725586
Step [   6/151] -> Date: 10/1996, Target: 0.7, Prediction: 18.797937393188477
Step [   7/151] -> Date: 11/1996, Target: 24.9, Prediction: 20.08294677734375
Step [   8/151] -> Date: 12/1996, Target: 14.0, Prediction: 20.586711883544922
Step [   9/151] -> Date: 1/1997, Target: 7.4, Prediction: 16.67336654663086
Step [  10/151] -> Date: 2/1997, Target: 11.0, Prediction: 23.504091262817383
Step [  11/151] -> Date: 3/1997, Target: 12.1, Prediction: 29.059757232666016
Step [  12/151] -> Date: 4/1997, Target: 23.0, Prediction: 35.63555145263672
Step [  13/151] -> Date: 5/1997, Target: 25.4, Prediction: 59.24177932739258
Step [  14/151] -> Date: 6/1997, Target: 20.8, Prediction: 53.758949279785156
Step [  15/151] -> Date: 7/1997, Target: 12.9, Prediction: 46.586570739746094
Step [  16/151] -> Date: 8/1997, Target: 35.7, Prediction: 61.38142395019531
Step [  17/151] -> Date: 9/1997, Target: 59.7, Prediction: 54.41291427612305
Step [  18/151] -> Date: 10/1997, Target: 32.8, Prediction: 67.98686218261719
Step [  19/151] -> Date: 11/1997, Target: 50.4, Prediction: 72.0262680053711
Step [  20/151] -> Date: 12/1997, Target: 55.5, Prediction: 59.06541061401367
Step [  21/151] -> Date: 1/1998, Target: 44.5, Prediction: 72.33379364013672
Step [  22/151] -> Date: 2/1998, Target: 50.2, Prediction: 73.21168518066406
Step [  23/151] -> Date: 3/1998, Target: 82.0, Prediction: 75.2353744506836
Step [  24/151] -> Date: 4/1998, Target: 70.6, Prediction: 76.84111022949219
Step [  25/151] -> Date: 5/1998, Target: 74.0, Prediction: 127.29763793945312
Step [  26/151] -> Date: 6/1998, Target: 90.5, Prediction: 129.17958068847656
Step [  27/151] -> Date: 7/1998, Target: 96.7, Prediction: 153.76181030273438
Step [  28/151] -> Date: 8/1998, Target: 121.1, Prediction: 150.08282470703125
Step [  29/151] -> Date: 9/1998, Target: 132.0, Prediction: 149.02906799316406
Step [  30/151] -> Date: 10/1998, Target: 78.5, Prediction: 142.12464904785156
Step [  31/151] -> Date: 11/1998, Target: 97.3, Prediction: 135.28041076660156
Step [  32/151] -> Date: 12/1998, Target: 119.2, Prediction: 141.16217041015625
Step [  33/151] -> Date: 1/1999, Target: 86.0, Prediction: 166.1267547607422
Step [  34/151] -> Date: 2/1999, Target: 98.0, Prediction: 131.81394958496094
Step [  35/151] -> Date: 3/1999, Target: 103.5, Prediction: 149.0779266357422
Step [  36/151] -> Date: 4/1999, Target: 93.6, Prediction: 147.2368621826172
Step [  37/151] -> Date: 5/1999, Target: 149.6, Prediction: 177.23992919921875
Step [  38/151] -> Date: 6/1999, Target: 207.2, Prediction: 187.3955535888672
Step [  39/151] -> Date: 7/1999, Target: 173.5, Prediction: 180.56008911132812
Step [  40/151] -> Date: 8/1999, Target: 142.3, Prediction: 186.04275512695312
Step [  41/151] -> Date: 9/1999, Target: 106.3, Prediction: 171.3660888671875
Step [  42/151] -> Date: 10/1999, Target: 168.7, Prediction: 176.2689971923828
Step [  43/151] -> Date: 11/1999, Target: 188.3, Prediction: 174.90737915039062
Step [  44/151] -> Date: 12/1999, Target: 116.8, Prediction: 166.80018615722656
Step [  45/151] -> Date: 1/2000, Target: 133.1, Prediction: 158.3551025390625
Step [  46/151] -> Date: 2/2000, Target: 165.7, Prediction: 168.01576232910156
Step [  47/151] -> Date: 3/2000, Target: 217.7, Prediction: 186.9577178955078
Step [  48/151] -> Date: 4/2000, Target: 191.5, Prediction: 161.94129943847656
Step [  49/151] -> Date: 5/2000, Target: 165.9, Prediction: 181.2884521484375
Step [  50/151] -> Date: 6/2000, Target: 188.0, Prediction: 175.64981079101562
Step [  51/151] -> Date: 7/2000, Target: 244.3, Prediction: 182.57640075683594
Step [  52/151] -> Date: 8/2000, Target: 180.5, Prediction: 183.67384338378906
Step [  53/151] -> Date: 9/2000, Target: 156.0, Prediction: 198.13229370117188
Step [  54/151] -> Date: 10/2000, Target: 141.6, Prediction: 187.31072998046875
Step [  55/151] -> Date: 11/2000, Target: 158.1, Prediction: 184.1028289794922
Step [  56/151] -> Date: 12/2000, Target: 143.3, Prediction: 173.54119873046875
Step [  57/151] -> Date: 1/2001, Target: 142.6, Prediction: 193.7702178955078
Step [  58/151] -> Date: 2/2001, Target: 121.5, Prediction: 193.84808349609375
Step [  59/151] -> Date: 3/2001, Target: 165.8, Prediction: 194.46542358398438
Step [  60/151] -> Date: 4/2001, Target: 161.7, Prediction: 171.64268493652344
Step [  61/151] -> Date: 5/2001, Target: 142.1, Prediction: 166.69541931152344
Step [  62/151] -> Date: 6/2001, Target: 202.9, Prediction: 158.02487182617188
Step [  63/151] -> Date: 7/2001, Target: 123.0, Prediction: 172.38385009765625
Step [  64/151] -> Date: 8/2001, Target: 161.5, Prediction: 169.02310180664062
Step [  65/151] -> Date: 9/2001, Target: 238.2, Prediction: 182.7196807861328
Step [  66/151] -> Date: 10/2001, Target: 194.1, Prediction: 154.51222229003906
Step [  67/151] -> Date: 11/2001, Target: 176.6, Prediction: 149.80215454101562
Step [  68/151] -> Date: 12/2001, Target: 213.4, Prediction: 135.1404266357422
Step [  69/151] -> Date: 1/2002, Target: 184.6, Prediction: 133.84963989257812
Step [  70/151] -> Date: 2/2002, Target: 170.2, Prediction: 136.21197509765625
Step [  71/151] -> Date: 3/2002, Target: 147.1, Prediction: 129.99874877929688
Step [  72/151] -> Date: 4/2002, Target: 186.9, Prediction: 132.9823760986328
Step [  73/151] -> Date: 5/2002, Target: 187.5, Prediction: 112.50787353515625
Step [  74/151] -> Date: 6/2002, Target: 128.8, Prediction: 111.03364562988281
Step [  75/151] -> Date: 7/2002, Target: 161.0, Prediction: 109.9718017578125
Step [  76/151] -> Date: 8/2002, Target: 175.6, Prediction: 104.55311584472656
Step [  77/151] -> Date: 9/2002, Target: 187.9, Prediction: 111.10961151123047
Step [  78/151] -> Date: 10/2002, Target: 151.2, Prediction: 111.37279510498047
Step [  79/151] -> Date: 11/2002, Target: 147.2, Prediction: 99.70240783691406
Step [  80/151] -> Date: 12/2002, Target: 135.3, Prediction: 91.9459228515625
Step [  81/151] -> Date: 1/2003, Target: 133.5, Prediction: 87.34207153320312
Step [  82/151] -> Date: 2/2003, Target: 75.7, Prediction: 88.7719497680664
Step [  83/151] -> Date: 3/2003, Target: 100.7, Prediction: 85.69332885742188
Step [  84/151] -> Date: 4/2003, Target: 97.9, Prediction: 85.44011688232422
Step [  85/151] -> Date: 5/2003, Target: 86.8, Prediction: 72.16465759277344
Step [  86/151] -> Date: 6/2003, Target: 118.7, Prediction: 68.92242431640625
Step [  87/151] -> Date: 7/2003, Target: 128.3, Prediction: 72.93761444091797
Step [  88/151] -> Date: 8/2003, Target: 115.4, Prediction: 76.50285339355469
Step [  89/151] -> Date: 9/2003, Target: 78.5, Prediction: 83.60982513427734
Step [  90/151] -> Date: 10/2003, Target: 97.8, Prediction: 74.84105682373047
Step [  91/151] -> Date: 11/2003, Target: 82.9, Prediction: 70.94361114501953
Step [  92/151] -> Date: 12/2003, Target: 72.2, Prediction: 70.47024536132812
Step [  93/151] -> Date: 1/2004, Target: 60.6, Prediction: 60.57201385498047
Step [  94/151] -> Date: 2/2004, Target: 74.6, Prediction: 58.117149353027344
Step [  95/151] -> Date: 3/2004, Target: 74.8, Prediction: 52.03351974487305
Step [  96/151] -> Date: 4/2004, Target: 59.2, Prediction: 59.46042251586914
Step [  97/151] -> Date: 5/2004, Target: 72.8, Prediction: 55.166316986083984
Step [  98/151] -> Date: 6/2004, Target: 66.5, Prediction: 38.65629577636719
Step [  99/151] -> Date: 7/2004, Target: 83.8, Prediction: 39.54514694213867
Step [ 100/151] -> Date: 8/2004, Target: 69.7, Prediction: 37.748756408691406
Step [ 101/151] -> Date: 9/2004, Target: 48.8, Prediction: 39.68459701538086
Step [ 102/151] -> Date: 10/2004, Target: 74.2, Prediction: 36.836631774902344
Step [ 103/151] -> Date: 11/2004, Target: 70.1, Prediction: 30.430025100708008
Step [ 104/151] -> Date: 12/2004, Target: 28.9, Prediction: 35.081581115722656
Step [ 105/151] -> Date: 1/2005, Target: 48.1, Prediction: 27.54952049255371
Step [ 106/151] -> Date: 2/2005, Target: 43.5, Prediction: 24.381925582885742
Step [ 107/151] -> Date: 3/2005, Target: 39.6, Prediction: 25.210391998291016
Step [ 108/151] -> Date: 4/2005, Target: 38.7, Prediction: 31.612619400024414
Step [ 109/151] -> Date: 5/2005, Target: 61.9, Prediction: 26.35441780090332
Step [ 110/151] -> Date: 6/2005, Target: 56.8, Prediction: 16.29840087890625
Step [ 111/151] -> Date: 7/2005, Target: 62.4, Prediction: 16.931642532348633
Step [ 112/151] -> Date: 8/2005, Target: 60.5, Prediction: 17.25901222229004
Step [ 113/151] -> Date: 9/2005, Target: 37.2, Prediction: 17.907041549682617
Step [ 114/151] -> Date: 10/2005, Target: 13.2, Prediction: 19.986896514892578
Step [ 115/151] -> Date: 11/2005, Target: 27.5, Prediction: 18.246143341064453
Step [ 116/151] -> Date: 12/2005, Target: 59.3, Prediction: 14.187141418457031
Step [ 117/151] -> Date: 1/2006, Target: 20.9, Prediction: 13.626260757446289
Step [ 118/151] -> Date: 2/2006, Target: 5.7, Prediction: 15.286628723144531
Step [ 119/151] -> Date: 3/2006, Target: 17.3, Prediction: 19.090892791748047
Step [ 120/151] -> Date: 4/2006, Target: 50.3, Prediction: 21.47344398498535
Step [ 121/151] -> Date: 5/2006, Target: 37.2, Prediction: 16.32758903503418
Step [ 122/151] -> Date: 6/2006, Target: 24.5, Prediction: 14.921041488647461
Step [ 123/151] -> Date: 7/2006, Target: 22.2, Prediction: 12.913433074951172
Step [ 124/151] -> Date: 8/2006, Target: 20.8, Prediction: 12.937353134155273
Step [ 125/151] -> Date: 9/2006, Target: 23.7, Prediction: 16.178707122802734
Step [ 126/151] -> Date: 10/2006, Target: 14.9, Prediction: 13.412168502807617
Step [ 127/151] -> Date: 11/2006, Target: 35.7, Prediction: 16.841684341430664
Step [ 128/151] -> Date: 12/2006, Target: 22.3, Prediction: 15.135805130004883
Step [ 129/151] -> Date: 1/2007, Target: 29.3, Prediction: 13.592851638793945
Step [ 130/151] -> Date: 2/2007, Target: 18.4, Prediction: 11.455192565917969
Step [ 131/151] -> Date: 3/2007, Target: 7.2, Prediction: 15.653688430786133
Step [ 132/151] -> Date: 4/2007, Target: 5.4, Prediction: 22.116437911987305
Step [ 133/151] -> Date: 5/2007, Target: 19.5, Prediction: 24.39902687072754
Step [ 134/151] -> Date: 6/2007, Target: 21.3, Prediction: 28.442602157592773
Step [ 135/151] -> Date: 7/2007, Target: 15.1, Prediction: 22.60256576538086
Step [ 136/151] -> Date: 8/2007, Target: 9.8, Prediction: 24.7574520111084
Step [ 137/151] -> Date: 9/2007, Target: 4.0, Prediction: 23.51072120666504
Step [ 138/151] -> Date: 10/2007, Target: 1.5, Prediction: 34.84331512451172
Step [ 139/151] -> Date: 11/2007, Target: 2.8, Prediction: 27.16693115234375
Step [ 140/151] -> Date: 12/2007, Target: 17.3, Prediction: 34.97196578979492
Step [ 141/151] -> Date: 1/2008, Target: 4.1, Prediction: 30.970243453979492
Step [ 142/151] -> Date: 2/2008, Target: 2.9, Prediction: 33.104942321777344
Step [ 143/151] -> Date: 3/2008, Target: 15.5, Prediction: 47.68121337890625
Step [ 144/151] -> Date: 4/2008, Target: 3.6, Prediction: 46.80592727661133
Step [ 145/151] -> Date: 5/2008, Target: 4.6, Prediction: 59.31904220581055
Step [ 146/151] -> Date: 6/2008, Target: 5.2, Prediction: 68.25227355957031
Step [ 147/151] -> Date: 7/2008, Target: 0.6, Prediction: 73.76724243164062
Step [ 148/151] -> Date: 8/2008, Target: 0.3, Prediction: 65.79656982421875
Step [ 149/151] -> Date: 9/2008, Target: 1.2, Prediction: 69.93585968017578
Step [ 150/151] -> Date: 10/2008, Target: 4.2, Prediction: 71.46741485595703
Step [ 151/151] -> Date: 11/2008, Target: 6.6, Prediction: 66.857177734375
----------------------------------------------------------------------------------------------------
Average Validation Loss: 28.350955817873114
----------------------------------------------------------------------------------------------------
Plotting data...
----------------------------------------------------------------------------------------------------
Plotting loss data...
----------------------------------------------------------------------------------------------------
Validation finished successfully.        Saved prediction/loss graphs can be found in: /home/extern/Dropbox/Research/scripts/graphs/
----------------------------------------------------------------------------------------------------
Predicting SC 24 using the above trained model
Step [   1/151] -> Date: 12/2008, Prediction: 13.914644241333008
Step [   2/151] -> Date: 1/2009, Prediction: 16.79752540588379
Step [   3/151] -> Date: 2/2009, Prediction: 22.277400970458984
Step [   4/151] -> Date: 3/2009, Prediction: 24.52571678161621
Step [   5/151] -> Date: 4/2009, Prediction: 19.476192474365234
Step [   6/151] -> Date: 5/2009, Prediction: 18.868030548095703
Step [   7/151] -> Date: 6/2009, Prediction: 17.311826705932617
Step [   8/151] -> Date: 7/2009, Prediction: 17.55552101135254
Step [   9/151] -> Date: 8/2009, Prediction: 20.72612953186035
Step [  10/151] -> Date: 9/2009, Prediction: 17.61728858947754
Step [  11/151] -> Date: 10/2009, Prediction: 20.524658203125
Step [  12/151] -> Date: 11/2009, Prediction: 18.256698608398438
Step [  13/151] -> Date: 12/2009, Prediction: 40.14763641357422
Step [  14/151] -> Date: 1/2010, Prediction: 39.32748794555664
Step [  15/151] -> Date: 2/2010, Prediction: 48.21540832519531
Step [  16/151] -> Date: 3/2010, Prediction: 57.49460220336914
Step [  17/151] -> Date: 4/2010, Prediction: 49.87992858886719
Step [  18/151] -> Date: 5/2010, Prediction: 54.57489776611328
Step [  19/151] -> Date: 6/2010, Prediction: 53.66586685180664
Step [  20/151] -> Date: 7/2010, Prediction: 49.54684829711914
Step [  21/151] -> Date: 8/2010, Prediction: 49.40367889404297
Step [  22/151] -> Date: 9/2010, Prediction: 58.79600524902344
Step [  23/151] -> Date: 10/2010, Prediction: 54.082298278808594
Step [  24/151] -> Date: 11/2010, Prediction: 61.9974365234375
Step [  25/151] -> Date: 12/2010, Prediction: 106.69707489013672
Step [  26/151] -> Date: 1/2011, Prediction: 110.41899871826172
Step [  27/151] -> Date: 2/2011, Prediction: 120.76798248291016
Step [  28/151] -> Date: 3/2011, Prediction: 124.43328857421875
Step [  29/151] -> Date: 4/2011, Prediction: 108.93460083007812
Step [  30/151] -> Date: 5/2011, Prediction: 114.76885223388672
Step [  31/151] -> Date: 6/2011, Prediction: 118.41461181640625
Step [  32/151] -> Date: 7/2011, Prediction: 107.3755111694336
Step [  33/151] -> Date: 8/2011, Prediction: 109.28265380859375
Step [  34/151] -> Date: 9/2011, Prediction: 110.01646423339844
Step [  35/151] -> Date: 10/2011, Prediction: 106.25665283203125
Step [  36/151] -> Date: 11/2011, Prediction: 122.77925872802734
Step [  37/151] -> Date: 12/2011, Prediction: 172.87966918945312
Step [  38/151] -> Date: 1/2012, Prediction: 165.07421875
Step [  39/151] -> Date: 2/2012, Prediction: 158.8928985595703
Step [  40/151] -> Date: 3/2012, Prediction: 150.13558959960938
Step [  41/151] -> Date: 4/2012, Prediction: 169.41001892089844
Step [  42/151] -> Date: 5/2012, Prediction: 173.8529052734375
Step [  43/151] -> Date: 6/2012, Prediction: 150.231689453125
Step [  44/151] -> Date: 7/2012, Prediction: 153.97476196289062
Step [  45/151] -> Date: 8/2012, Prediction: 162.8449249267578
Step [  46/151] -> Date: 9/2012, Prediction: 175.29470825195312
Step [  47/151] -> Date: 10/2012, Prediction: 168.22232055664062
Step [  48/151] -> Date: 11/2012, Prediction: 160.96018981933594
Step [  49/151] -> Date: 12/2012, Prediction: 177.79823303222656
Step [  50/151] -> Date: 1/2013, Prediction: 197.56370544433594
Step [  51/151] -> Date: 2/2013, Prediction: 179.0117950439453
Step [  52/151] -> Date: 3/2013, Prediction: 173.85015869140625
Step [  53/151] -> Date: 4/2013, Prediction: 169.6398162841797
Step [  54/151] -> Date: 5/2013, Prediction: 174.25830078125
Step [  55/151] -> Date: 6/2013, Prediction: 166.43438720703125
Step [  56/151] -> Date: 7/2013, Prediction: 164.74932861328125
Step [  57/151] -> Date: 8/2013, Prediction: 156.0951385498047
Step [  58/151] -> Date: 9/2013, Prediction: 170.5976104736328
Step [  59/151] -> Date: 10/2013, Prediction: 169.3539581298828
Step [  60/151] -> Date: 11/2013, Prediction: 161.53807067871094
Step [  61/151] -> Date: 12/2013, Prediction: 164.3640899658203
Step [  62/151] -> Date: 1/2014, Prediction: 142.13510131835938
Step [  63/151] -> Date: 2/2014, Prediction: 155.69215393066406
Step [  64/151] -> Date: 3/2014, Prediction: 180.5462646484375
Step [  65/151] -> Date: 4/2014, Prediction: 169.0781707763672
Step [  66/151] -> Date: 5/2014, Prediction: 162.19435119628906
Step [  67/151] -> Date: 6/2014, Prediction: 171.2423553466797
Step [  68/151] -> Date: 7/2014, Prediction: 160.3429412841797
Step [  69/151] -> Date: 8/2014, Prediction: 154.73936462402344
Step [  70/151] -> Date: 9/2014, Prediction: 146.5071563720703
Step [  71/151] -> Date: 10/2014, Prediction: 158.95799255371094
Step [  72/151] -> Date: 11/2014, Prediction: 158.67697143554688
Step [  73/151] -> Date: 12/2014, Prediction: 104.06026458740234
Step [  74/151] -> Date: 1/2015, Prediction: 116.46829986572266
Step [  75/151] -> Date: 2/2015, Prediction: 123.05116271972656
Step [  76/151] -> Date: 3/2015, Prediction: 127.87374877929688
Step [  77/151] -> Date: 4/2015, Prediction: 124.52985382080078
Step [  78/151] -> Date: 5/2015, Prediction: 116.80511474609375
Step [  79/151] -> Date: 6/2015, Prediction: 111.13385009765625
Step [  80/151] -> Date: 7/2015, Prediction: 108.79593658447266
Step [  81/151] -> Date: 8/2015, Prediction: 96.85149383544922
Step [  82/151] -> Date: 9/2015, Prediction: 107.2696533203125
Step [  83/151] -> Date: 10/2015, Prediction: 108.40169525146484
Step [  84/151] -> Date: 11/2015, Prediction: 114.87005615234375
Step [  85/151] -> Date: 12/2015, Prediction: 97.32056427001953
Step [  86/151] -> Date: 1/2016, Prediction: 92.92742156982422
Step [  87/151] -> Date: 2/2016, Prediction: 93.80084991455078
Step [  88/151] -> Date: 3/2016, Prediction: 78.96637725830078
Step [  89/151] -> Date: 4/2016, Prediction: 101.55004119873047
Step [  90/151] -> Date: 5/2016, Prediction: 88.98751068115234
Step [  91/151] -> Date: 6/2016, Prediction: 71.51016998291016
Step [  92/151] -> Date: 7/2016, Prediction: 75.24495697021484
Step [  93/151] -> Date: 8/2016, Prediction: 65.27326965332031
Step [  94/151] -> Date: 9/2016, Prediction: 67.6868667602539
Step [  95/151] -> Date: 10/2016, Prediction: 61.395362854003906
Step [  96/151] -> Date: 11/2016, Prediction: 63.34907913208008
Step [  97/151] -> Date: 12/2016, Prediction: 38.62619400024414
Step [  98/151] -> Date: 1/2017, Prediction: 56.52620315551758
Step [  99/151] -> Date: 2/2017, Prediction: 40.27463912963867
Step [ 100/151] -> Date: 3/2017, Prediction: 33.933650970458984
Step [ 101/151] -> Date: 4/2017, Prediction: 38.14777374267578
Step [ 102/151] -> Date: 5/2017, Prediction: 54.19084930419922
Step [ 103/151] -> Date: 6/2017, Prediction: 30.47998809814453
Step [ 104/151] -> Date: 7/2017, Prediction: 49.037784576416016
Step [ 105/151] -> Date: 8/2017, Prediction: 32.305667877197266
Step [ 106/151] -> Date: 9/2017, Prediction: 31.99738311767578
Step [ 107/151] -> Date: 10/2017, Prediction: 31.422618865966797
Step [ 108/151] -> Date: 11/2017, Prediction: 47.622650146484375
Step [ 109/151] -> Date: 12/2017, Prediction: 24.53250503540039
Step [ 110/151] -> Date: 1/2018, Prediction: 29.643169403076172
Step [ 111/151] -> Date: 2/2018, Prediction: 29.05499839782715
Step [ 112/151] -> Date: 3/2018, Prediction: 29.98470115661621
Step [ 113/151] -> Date: 4/2018, Prediction: 15.109548568725586
Step [ 114/151] -> Date: 5/2018, Prediction: 18.61772918701172
Step [ 115/151] -> Date: 6/2018, Prediction: 23.62084197998047
Step [ 116/151] -> Date: 7/2018, Prediction: 15.848777770996094
Step [ 117/151] -> Date: 8/2018, Prediction: 13.697534561157227
Step [ 118/151] -> Date: 9/2018, Prediction: 16.862871170043945
Step [ 119/151] -> Date: 10/2018, Prediction: 23.566600799560547
Step [ 120/151] -> Date: 11/2018, Prediction: 17.889760971069336
Step [ 121/151] -> Date: 12/2018, Prediction: 14.356697082519531
Step [ 122/151] -> Date: 1/2019, Prediction: 11.942420959472656
Step [ 123/151] -> Date: 2/2019, Prediction: 15.335838317871094
Step [ 124/151] -> Date: 3/2019, Prediction: 14.11697006225586
Step [ 125/151] -> Date: 4/2019, Prediction: 13.786336898803711
Step [ 126/151] -> Date: 5/2019, Prediction: 17.29157066345215
Step [ 127/151] -> Date: 6/2019, Prediction: 20.934141159057617
Step [ 128/151] -> Date: 7/2019, Prediction: 18.58977508544922
Step [ 129/151] -> Date: 8/2019, Prediction: 13.84608268737793
Step [ 130/151] -> Date: 9/2019, Prediction: 13.336938858032227
Step [ 131/151] -> Date: 10/2019, Prediction: 13.982606887817383
Step [ 132/151] -> Date: 11/2019, Prediction: 13.872064590454102
Step [ 133/151] -> Date: 12/2019, Prediction: 16.157651901245117
Step [ 134/151] -> Date: 1/2020, Prediction: 16.431825637817383
Step [ 135/151] -> Date: 2/2020, Prediction: 14.94400405883789
Step [ 136/151] -> Date: 3/2020, Prediction: 16.002878189086914
Step [ 137/151] -> Date: 4/2020, Prediction: 13.251466751098633
Step [ 138/151] -> Date: 5/2020, Prediction: 14.023221969604492
Step [ 139/151] -> Date: 6/2020, Prediction: 15.598306655883789
Step [ 140/151] -> Date: 7/2020, Prediction: 16.478992462158203
Step [ 141/151] -> Date: 8/2020, Prediction: 20.50526237487793
Step [ 142/151] -> Date: 9/2020, Prediction: 21.411468505859375
Step [ 143/151] -> Date: 10/2020, Prediction: 17.02512550354004
Step [ 144/151] -> Date: 11/2020, Prediction: 14.178129196166992
Step [ 145/151] -> Date: 12/2020, Prediction: 35.74566650390625
Step [ 146/151] -> Date: 1/2021, Prediction: 34.165287017822266
Step [ 147/151] -> Date: 2/2021, Prediction: 35.52984619140625
Step [ 148/151] -> Date: 3/2021, Prediction: 38.00761795043945
Step [ 149/151] -> Date: 4/2021, Prediction: 40.38737487792969
Step [ 150/151] -> Date: 5/2021, Prediction: 40.03181838989258
Step [ 151/151] -> Date: 6/2021, Prediction: 36.50835418701172
----------------------------------------------------------------------------------------------------
Plotting data...
